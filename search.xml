<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SSH 配置管理]]></title>
    <url>%2F2017%2F06%2F16%2F37634%2F</url>
    <content type="text"><![CDATA[SSH 配置 生成 ssh key, 开启 ssh-agent 1234# 生成 ssh keyssh-keygen -t rsa -b 4096 -C "your_email@example.com"# 开启 ssh-agenteval "$(ssh-agent -s)" 若系统为 macOS Sierra 10.12.2 之后的版本, 需要配置 ~/.ssh/config 12345678910Host *AddKeysToAgent yesUseKeychain yesIdentityFile ~/.ssh/id_rsa# 若为多个 key, 继续添加Host * AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/id_rsa_dokku 添加 ssh private key 到 ssh-agent 1234567ssh-add -K ~/.ssh/id_rsa# 查看添加过的 keyssh-add -l# 删除 keyshh-add -D# 测试 keyssh -T git@github.com SSH 配置为密钥登陆, 并禁止密码登陆 12345678910111213# 复制密钥到服务器ssh-copy-id -i ~/.ssh/id_rsa.pub root@125.126.127.128# 直接使用密钥登陆ssh root@125.126.127.128# 修改配置文件，禁止密码登陆vim /etc/ssh/sshd_config设置 PasswordAuthentication no# 重启sshservice sshd restart //（ Centos 6）systemctl restart sshd //（Centos 7）/etc/init.d/ssh restart // (Ubuntu) 参考 Generating a new SSH key and adding it to the ssh-agent git生成ssh key及本地解决多个ssh key的问题]]></content>
      <categories>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>SSH KEY</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dokku 详解]]></title>
    <url>%2F2017%2F06%2F15%2F36906%2F</url>
    <content type="text"><![CDATA[Dokku 安装Github: https://github.com/dokku/dokkuDocument: http://dokku.viewdocs.io/dokku/getting-started/installation/ 1234# 脚本下载wget https://raw.githubusercontent.com/dokku/dokku/v0.9.4/bootstrap.sh# 脚本安装sudo DOKKU_TAG=v0.9.4 bash bootstrap.sh]]></content>
      <categories>
        <category>Dokku</category>
      </categories>
      <tags>
        <tag>Dokku</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN 详解]]></title>
    <url>%2F2017%2F06%2F15%2F22235%2F</url>
    <content type="text"><![CDATA[UbuntuSVN 管理软件http://svnadmin.insanefactory.com/]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>SVN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 日常使用]]></title>
    <url>%2F2017%2F06%2F15%2F28537%2F</url>
    <content type="text"><![CDATA[制作 U 盘安装盘制作工具: Rufus https://tutorials.ubuntu.com/tutorial/tutorial-create-a-usb-stick-on-windows#6 Ubuntu 设置(基于16.04)1234567# 设置 root 密码, 启用 root 用户sudo passwd root# 切换到 root 用户su root# 修改 /etc/ssh/sshd_config, 允许 root SHH 远程登陆(PermitRootLogin yes)# 重启 SSH 服务sudo service ssh restart 1234567# 更新源apt udpate# 更新包apt --upgrade# 全局查找 nginx 相关文件sudo find / -name nginx* 参考资料https://tutorials.ubuntu.com/]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用前端优秀框架(持续更新)]]></title>
    <url>%2F2017%2F06%2F01%2F5880%2F</url>
    <content type="text"><![CDATA[CSSBulma基于 Flexbox 的现代 CSS 框架 Autoprefixer解析 CSS 并根据 Can I Use 规则增加各浏览器 CSS 实验性前缀 JavaScriptVue.jsVue.js（读音 /vjuː/，类似于 view） 是一套构建用户界面的渐进式框架。与其他重量级框架不同的是，Vue 采用自底向上增量开发的设计。Vue 的核心库只关注视图层，它不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与单文件组件和 Vue 生态系统支持的库结合使用时，Vue 也完全能够为复杂的单页应用程序提供驱动。 vue-cliVue 脚手架 vuexVuex 是一个专为 Vue.js 应用程序开发的状态管理模式。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。 文档地址: https://vuex.vuejs.org/zh-cn/ vue-routervue-router 是 Vue.js 的官方路由. 它与 Vue.js 深度整合, 用于创建单页应用. 文档地址: https://router.vuejs.org/zh-cn/ vue-resource 非 Vue 官方插件(官方推荐 Axios)The plugin for Vue.js provides services for making web requests and handle responses using a XMLHttpRequest or JSONP.CDN: &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue-resource@1.3.3&quot;&gt;&lt;/script&gt; ESLint - 英文站可组装的JavaScript和JSX检查工具 Mock.js生成随机数据，拦截 Ajax 请求 官网: http://mockjs.com]]></content>
      <categories>
        <category>JavaScript</category>
        <category>CSS</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[饿了么 UI 框架 Element 学习]]></title>
    <url>%2F2017%2F05%2F30%2F33430%2F</url>
    <content type="text"><![CDATA[项目初始化Github: https://github.com/ElemeFE/element 1234567# 创建项目目录mkdir elem# 初始化项目cd elemnpm init# 安装 element-uinpm install element-ui -S 注意点 直接 npm install element-ui -S 出现异常 1) npm WARN saveError ENOENT: no such file or directory, open ‘/Users/arcticfox/Develop/element/test/package.json’ 12# npm init 进行项目初始化, 创建 package.json 文件npm init 2) UNMET PEER DEPENDENCY vue@^2.3.0 12# 升级 npm 版本npm update -g npm]]></content>
      <categories>
        <category>UI</category>
        <category>Element</category>
      </categories>
      <tags>
        <tag>UI</tag>
        <tag>Element</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 升级到 HTTPS]]></title>
    <url>%2F2017%2F05%2F30%2F20181%2F</url>
    <content type="text"><![CDATA[升级注意点 HTTP 直接通过 301 跳转到 HTTPS]]></content>
      <categories>
        <category>HTTPS</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
        <tag>Nginx</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高 PV 网站优化]]></title>
    <url>%2F2017%2F05%2F29%2F41423%2F</url>
    <content type="text"><![CDATA[CDN缓存负载均衡 DNS解析的负载均衡1) 防止运营商劫持2) 保证请求链路最优化 反向代理的负载均衡1) 基于各服务提供服务器的权重进行请求分发和负载均衡(例如, 通过 nginx) 后台服务的负载均衡1)一个虚拟ip和端口对应后面多台机器，这样对业务来说就是透明的(例如, 腾讯 L5 方案或 LB 方案) 动静态资源分离 减少不必要的cookie传输 接入CDN需要区分域名 防止遍历攻击 静态资源单独配置压缩和编码 独立部署，团队职责划分清晰 运维支撑 数据监控与告警平台 数据上报与统计平台 日志上报与分析平台 发布系统（可回滚，可追溯，可前后置脚本，可独立文件发布，四可准则） 机器监控平台 服务发布、监控与重启平台 配置维护与发布平台 CDN 项目管理系统 用户反馈系统 压测 wrk 压测工具 运营与 SEOSEO专项优化，十分重要，基本思路就是按照百度的站长平台撸一遍。 设计清晰的网站架构 在每个页面进行单独的SEO内容埋入 主动推送sitemap 持续的产出高质量的内容 与百度进行商务合作 尽量规避死链的出现 与其他高权重网站合作 域名切换的时候，尤其要注意SEO的权重转移 首先将新网站上线，进行自然流量和自然权重的积累 排名攀升之后，将老站进行301跳转 在搜索引擎后台进行改版配置，保证权重的最大化转移 参考资料 从头替换一个2000万pv的站点，需要注意些什么？]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 多线程]]></title>
    <url>%2F2017%2F05%2F29%2F5593%2F</url>
    <content type="text"><![CDATA[变量可见性在多线程程序中，当一个线程对共享变量所做的修改对于其它线程并不可见，导致其它的线程仍然使用错误的值，就会造成可见性问题。 在代码被运行时，对于一条代码语句，可能对应着虚拟机中多条的指令序列，由于CPU在调用线程时不可预知，那么就可能出现在执行某一条语句时，执行到其所对应的指令的间隙就切换到了其它线程执行，引发错误。 现在的CPU一般采用多级缓存，多级缓存的引入是为了提高读取效率，增加CPU运算的性能，但是这样也会引发一些问题：由于线程在读取数据的时候是从主存时读取的，当一个线程对一个共享变量进行了修改的时候，这个变量没有及时地写入到主存中，而是暂时保存在了缓存中，那么CPU此时切换另一个线程运行时，读取到的时主存的原来的值。 另一个可能的原因是编译器出于对性能的考虑，可能会对生成的字节吗进行指令重排，优化指令的执行顺序，这也可能会引发多线程可见性问题。]]></content>
      <categories>
        <category>Java</category>
        <category>Multithreading</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Multithreading</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Hexo 搭配 Next 主题搭建博客]]></title>
    <url>%2F2017%2F05%2F29%2F29846%2F</url>
    <content type="text"><![CDATA[Hexo 下载及安装官方网址: http://hexo.ioGithub: https://github.com/hexojs/hexo 123456789101112131415# 安装npm install hexo-cli -g# 初始化hexo init blogcd blog# DEBUG 模式hexo s --debug# 新建文章hexo new "Hello Hexo"# 生成静态文件hexo generate# 部署(需要配置部署方式)hexo deploy# &gt;&gt;&gt;&gt;&gt;&gt; 升级 hexonpm update Algolia 插件安装12# 生成搜索索引hexo algolia Next 主题插件安装官方网址: http://theme-next.iissnan.comGithub: https://github.com/iissnan/hexo-theme-next 安装 Next 1234567891011# 在站点根目录下git clone https://github.com/iissnan/hexo-theme-next themes/next# 站点配置文件 _config.yml 启用主题theme: next# &gt;&gt;&gt;&gt;&gt;&gt; 升级 nextgit clone https://github.com/theme-next/hexo-theme-next themes/next-reloaded# 站点配置文件 _config.yml 启用主题theme: next-reloaded# 语言改为 zh-CNlanguage: zh-CN# 其他细节：https://github.com/theme-next/hexo-theme-next/blob/master/docs/zh-CN/UPDATE-FROM-5.1.X.md SEO 蜘蛛协议 在网站 source 目录增加蜘蛛协议 robots.txt 1234567891011121314# hexo robots.txtUser-agent: *Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: http://blog.longgen.me/sitemap.xmlSitemap: http://blog.longgen.me/baidusitemap.xml nofollow 为网站非友情链接的出站链接增加 nofollow 标签 标题关键字优化 百度 SEO12345# 生成百度 sitemap.xmlnpm install hexo-generator-baidu-sitemap --save# 站点配置文件 _config.yml 中添加百度 sitemap 配置baidusitemap: path: baidusitemap.xml 主动提交链接至百度Github 屏蔽百度爬虫导致在 Github Pages 上托管的博客, 网站都无法被百度索引到. 所以需要针对性的进行一些特殊处理 使用 hexo-baidu-url-submit 插件(注意: 站点配置文件 _config.yml 中的 URL 必须是百度站长平台注册的域名) 注册百度站长工具, 然后在工具-&gt;网页抓取-&gt;链接提交里找到你的密匙 Token12345678910111213# Hexo 博客根目录下安装插件npm install hexo-baidu-url-submit --save# 配置以下内容到站点配置文件 _config.ymlbaidu_url_submit: count: 1 ## 提交最新的一个链接 host: blog.longgen.me ## 在百度站长平台中注册的域名 token: your_token ## 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里# 站点配置文件 _config.yml 加入新的 deployer- type: baidu_url_submitter# 推送包含以下两个步骤hexo generate # 生成链接文件hexo deploy # 读取链接, 提交至百度搜索引擎 智能 DNS 解析方式 通过百度 CDN 智能 DNS 分线路解析, 百度爬虫线路直接解析至非 Github 空间http://blog.csdn.net/xiaoyufu007/article/details/50732955 Google SEO12345# 生成 Google sitemap.xmlnpm install hexo-generator-sitemap --save# 站点配置文件 _config.yml 中添加 sitemap 配置sitemap: path: sitemap.xml 问题集锦 Node 旧版本升级到新版本后, Hexo 命令执行失败. node_modules 缓存问题 12345Error: The module '/Users/guojunbing23/gitresource/blong/node_modules/hexo/node_modules/hexo-log/node_modules/bunyan/node_modules/dtrace-provider/build/Release/DTraceProviderBindings.node'was compiled against a different Node.js version usingNODE_MODULE_VERSION 46. This version of Node.js requiresNODE_MODULE_VERSION 51. Please try re-compiling or re-installingthe module (for instance, using npm rebuild ornpm install). 解决办法: https://github.com/hexojs/hexo/issues/2534]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Blog</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>SEO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F05%2F26%2F16107%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[JavaScript 模块化开发]]></title>
    <url>%2F2014%2F10%2F09%2F24576%2F</url>
    <content type="text"><![CDATA[目录结构 common：相对业务要底层一些，属于基础组件，它可以在各业务模块中使用，组成业务相关的功能 conf：项目的配置 general：一般的针对业务的一些功能，比如这里的picView就是一个图片查看功能，该目录的定位是与业务紧密相关 lib：第三方的一些库，比如jquery,requirejs page：这里的每一个js文件对应于一个页面，这就是页面js的入口文件，所有的功能模块通过对应的js去加载 util：其实就是一个函数库，也跟业务没关系，只是实现一般常用小颗粒功能的封装]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache Storm 详解]]></title>
    <url>%2F2014%2F10%2F09%2F15320%2F</url>
    <content type="text"><![CDATA[Apache Storm 是一个免费、开源的分布式实时计算系统，相对于 Hadoop 适用于批处理而言，Storm 可以用于实时处理流式数据。 发展历史 最早由做分析平台的创业公司 BackType 开发 2011 年 7 月，BackType 被 Twitter 收购，Storm 于同年 9 月 开源于 GitHub 上 2013 年 9 月，Storm 成为了 Apache 软件基金会的孵化项目 2014 年 9 月，Storm 孵化完毕，升级为 Apache 顶级项目 特点 使用 Clojure 编写，Clojure 是一个在 JVM 平台运行的动态函数式编程语言 支持多种编程语言 适用场景mark 实时分析 在线机器学习 持续计算 分布式远程调用 ETL 领域 参考资料 Storm 升级成为 Apache 顶级项目]]></content>
      <categories>
        <category>Apache Storm</category>
      </categories>
      <tags>
        <tag>Apache Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 详解]]></title>
    <url>%2F2014%2F10%2F08%2F21334%2F</url>
    <content type="text"><![CDATA[相关工具Pandoc OS X 123# 安装 pandoc，可以使用 pandoc 将 markdown 文件转为 docx，之后使用 office 软件转为 pdf 文件brew install pandoc Prince 收费，价格非常高 GitBookSublime Text 插件 SmartMarkdown：除了在写 Markdown 文件更方便外，更能和 Pandoc 配合，提供命令，方便生成文件。 在线编辑作业部落stackedit.io参考资料 用 Markdown 来写自由书籍 - 开源技术的方案]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 超文本传输协议详解]]></title>
    <url>%2F2014%2F09%2F22%2F8342%2F</url>
    <content type="text"><![CDATA[HTTP（HyperText Transfer Protocol，超文本传输协议）是互联网上应用最为广泛的一种网络协议。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。通过 HTTP 或者 HTTPS 协议请求的资源由统一资源标示符（Uniform Resource Identifiers，URI）来标识。 版本HTTP 0.9已过时。只接受 GET 一种请求办法，没有在通讯中制定版本号，且不支持请求头。由于该版本不支持 POST 方法，因此客户端无法向服务器传递太多信息。 HTTP 1.0这是第一个在通讯中指定版本号的 HTTP 协议版本，至今仍被广泛采用，特别是在代理服务器中。 HTTP 1.1持久连接被默认采用，并能很好地配合代理服务器工作。还支持以管道方式同时发送多个请求，以便降低线路负载，提高传输速度。HTTP/1.1 相较于 HTTP/1.0 协议的区别主要体现在： 缓存处理 带宽优化及网络连接的使用 错误通知的管理 消息在网络中的发送 互联网地址的维护 安全性及完整性 HTTP 2参考资料 超文本传输协议]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用加密算法详解]]></title>
    <url>%2F2014%2F09%2F09%2F11712%2F</url>
    <content type="text"></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图片格式详解]]></title>
    <url>%2F2014%2F09%2F08%2F5505%2F</url>
    <content type="text"><![CDATA[JPEGJPEG 格式是一种大小与质量相平衡的压缩图片格式。通俗一点讲，就是：高的压缩比 = 低的图片质量 = 小的文件大小。反之，低的压缩比 = 高的图片质量 = 大的文件大小。由于 JPEG 文件无法保持 100％ 的原始图像的像素数据，所以它不被认为是一种无损图像格式。 用途由于这种极其敏感的平衡特性，JPEG 非常适合被应用在那些允许轻微失真的像素色彩丰富的图片（照片）场合。反之，JPEG 格式图片并不适合做简单色彩（色调少）的图片，比如 LOGO，各种小图标（ICONS）。 GIFGIF 格式，是为使图片能够应用在在线（online）应用程序上所特别开发的图片格式。Gif，有时也被成为“Giff”，是一种无损，8位图片格式。“无损”是指 100% 的保持原始图片的像素数据信息。专业名词“8位”是指，所能表现的颜色深度——一个 8 位图像仅最多只能支持 256 种不同颜色（一个多余 256 种颜色的图片若用gif图片保存会出现失真）。 用途由于 8 位颜色深度的限制，Gif 不适合应用于各种色彩过于丰富的照片存储场合。但它却非常适合应用在以下场合：Logo、小图标（Icon）、用于布局的图片（例如某个布局角落，边框等等）、仅包含不超过 256 种色彩的简单，小型图片场合 透明特性：GIF 支持基本的透明特性，这意味着你能够使图片的某些像素“不可见”。在其被放置到网页中时，我们就可以看到通过这些不可见区域看到此图片后面的背景颜色（图片）。此特性非常有用：如果你需要将某个 gif 图片的内容置于所有图片的上层，你可以将其设置为透明。 压缩特性：GIF 格式采用 LZW 算法进行压缩，此算法是 Unisys 申请的一项专利。在很久很久之前，如果你想使用 GIF 格式，那么就意味着你需要向 Unisys 付费申请专利许可。不过值得高兴的是，此项专利技术已于2003年6月20日过期，我们现在可以免费的使用 GIF 了！ 隔行扫描：GIF 同时也支持隔行扫描。隔行扫描能够令图片在浏览器中更快的加载和显示。此特性对于那些慢网速的浏览者来说尤其实用。 动画 GIF：一个动态的 GIF 文件，是由若干帧图片所联结而成的动态图片。在显示时，这些动态帧被反复的绘制读取出来从而形成了简单的动画效果。合理的运用 GIF 动画能够为网页增添动静结合的效果，而过度的使用则会使网页杂乱无章。 PNGPNG，读“ping”，初始时被作为 GIF 的免费替代格式所开发，采用公共专利压缩算法。PNG 格式也是一种无损压缩，但与 GIF 格式不同的是，PNG 同时支持 8 位和 24 位的图像。 8位PNG图像：一个 8 位 PNG 图片，支持透明背景且像素颜色不能超过 256 种。除了压缩算法不同之外，此 8 位 PNG 格式与 GIF 格式极其相似； 用途：8 位 PNG 图片的用途与 GIF 格式基本相同，Logo、小图标（Icon）、用于布局的图片（例如某个布局角落，边框等等）、仅包含不超过256种色彩的简单，小型图片场合 24 位 PNG 图像：24 位 PNG，支持 160 万种不同的像素颜色且支持 Alpha 透明效果，这就意味着，无论透明度设置为多少，PNG 图片均能够与背景很好的融合在一起。 对 PNG 的支持：由于 PNG 格式的广泛使用和开发者更加重视网页的 WEB 标准，不同浏览器对 PNG 的支持就显得相当重要了。不过，幸运的是，目前市场上主流的浏览器对 PNG 格式都有很好的支持，这包括：IE*, Firefox, Safari, Opera, and Konqueror。但不幸的是，IE6 及 IE6 以下的浏览器对 PNG 透明背景的支持并不好。不过我们仍可以通过其他方法来解决这个问题，详情请查看如何在 IE6 中正常显示透明 PNG。]]></content>
      <categories>
        <category>Picture</category>
      </categories>
      <tags>
        <tag>Picture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 详解]]></title>
    <url>%2F2014%2F09%2F05%2F3604%2F</url>
    <content type="text"><![CDATA[下载安装及配置OS X 环境 Windows 环境Windows 下有可采用两种方式安装 MySQL 服务。 ZIP Archive 下载 ZIP 压缩包，解压至对应目录下 配置环境变量 MYSQL_HOME，以及增加 MySQL 的 bin 目录到 path 变量中 MSI Installer 下载 MSI 安装包，按提示进行安装 MySQL 常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# mysqld，数据库启动命令mysqld# mysql，数据库链接命令mysql# status，查看数据库状态mysql&gt; status--------------mysql Ver 14.14 Distrib 5.6.20, for Win64 (x86_64)Connection id: 13Current database:Current user: ODBC@localhostSSL: Not in useUsing delimiter: ;Server version: 5.6.20 MySQL Community Server (GPL)Protocol version: 10Connection: localhost via TCP/IPServer characterset: latin1Db characterset: latin1Client characterset: gbkConn. characterset: gbkTCP port: 3306Uptime: 14 min 32 secThreads: 5 Questions: 348 Slow queries: 0 Opens: 68 Flush tables: 1 Open tables: 61 Queries per second avg: 0.399--------------# 查看数据库列表mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)# 数据库切换（切换至 mysql 数据库）mysql&gt; use mysql;# 查看库中数据表列表mysql&gt; show tables;# 查看 mysql 数据库用户mysql&gt; select * from mysql.user;#]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模板引擎资源]]></title>
    <url>%2F2014%2F09%2F03%2F49109%2F</url>
    <content type="text"><![CDATA[Java 模板引擎 Rythm 专为 Java 程序员设计的模板引擎 参考资料 维基百科：AngularJS]]></content>
      <categories>
        <category>Template</category>
      </categories>
      <tags>
        <tag>Template</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS 详解]]></title>
    <url>%2F2014%2F09%2F03%2F8050%2F</url>
    <content type="text"><![CDATA[AngularJS 是一款开源 JavaScript 函数库，由 Google 维护，用来协助单一页面应用程序运行的。它的目标是通过 MVC 模式功能增强基于浏览器的应用，使开发和测试变得更加容易。 AngularJS 理念 声明式编程用于构建用户界面以及编写软件构建，指令式编程用来表示业务逻辑 双向数据绑定来适应动态内容，双向的数据绑定允许模型和视图之间的自动同步 AngularJS 设计目标 将应用逻辑与对 DOM 的操作解耦，提高代码可测试性 将应用程序的测试与应用程序的编写放在同等重要的位置 应用程序的客户端与服务器端解耦，允许客户端和服务端的开发并行，并提高可复用性 指导开发者完成构建应用程序的整个历程：用户界面设计、业务逻辑编写、测试 AngularJS 特点 MIT 许可证 遵循软件工程的 MVC 模式，展现、数据和逻辑组件之间松耦合（依赖注入） 双向数据绑定 浏览器支持 AngularJS 1.2 继续支持 IE8，但不会再继续花时间维护；AngularJS 1.3 开始，将不再支持 IE8 相关资源 http://angular-ui.github.io/ 参考资料 维基百科：AngularJS]]></content>
      <categories>
        <category>Javascript</category>
        <category>AngularJS</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
        <tag>AngularJS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 详解]]></title>
    <url>%2F2014%2F09%2F03%2F26252%2F</url>
    <content type="text"><![CDATA[Docker 是 PaaS 供应商 docCloud 使用 Apache 2.0 协议开源的一个基于 LXC 的高级容器引擎。 Docker 特点 轻量级 操作系统级的虚拟化技术 Docker 使用 Go 语言开发 提供了安全、可重复的环境中自动部署软件的方式 常用命令123456# 启动 redis 容器, 在 redis 容器非 0 异常退出时自动重启sudo docker run --restart=on-failure redis# 启动 redis 容器, 在 redis 容器非 0 异常退出时自动重启, 限制自动重启次数为 10 次sudo docker run --restart=on-failure:10 redis# 启动 redis 容器, 在 redis 容器退出时, 自动重启sudo docker run --restart=always redis]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中小企业建站方案及相关资源]]></title>
    <url>%2F2014%2F08%2F31%2F11218%2F</url>
    <content type="text"><![CDATA[域名注册 新网 万网 Godaddy 企业邮箱 Google Apps：可绑定 Gtalk 账号，国内屏蔽，无法使用 Windows Live Domain 腾讯 QQ 企业邮箱 网易免费企业邮箱 建站工具第三方机构提供模板建站特点：简单易用，搭建快速，但无法定制开发，有各种限制 淘宝 阿里巴巴 百度有啊 Google Sites 万网建站平台 自建平台特点：可以使用自己的域名，可定制开发，但需要建站知识丰富 电子商务管理系统 123456789101112131415161718192021osCommerce * 免费开源 * 在线商店解决方案 * 有没落的趋势Zen Cart * 免费开源 * 在线商店解决方案 * 支持多语言、多货币ECShop * 开源 * 在线商店解决方案 * 插件和二次开发有一定优势 * 与 Discuz 系列整合较好 * 已被 ShopEx 收购ShopEx * 国内最早网店软件提供商之一 * 功能全面，收购了 ECShopHiShopPHPB2BMagentoOpenChart CMS（内容管理系统） 1234567891011121314151617181920212223242526272829SupeSiteDedeCMSKingCMSDrupal * 开源 * PHP * 支持多语言 * 使用广泛，安全性好 * 强大的定制能力和灵活性 * 扩展能力强大，有丰富的第三方扩展支持 * 站内搜索系统能对站内所有内容进行索引和搜索 * 提供完善的站点管理和分析工具 * 功能丰富，包括 Blog、协同协作平台、论坛、电子报、相册、文件的上传与下载、全文搜索、多角色权限管理、模块化、主题引擎、多语言支持等WordPress * 免费开源 * PHP * 功能强大，可用于博客搭建、信息发布平台搭建phpBB * 开源 * 可以在数分钟内建立一个论坛，功能可配置Pligg * 类似 Digg 的 Web 2.0 CMS 系统 * PHP 开发Gallery * 免费开源 * 图库相册软件 * 基于 PHP、MySQL、PostgreSQL等 * 功能强大 * 扩展丰富 财务管理 123Intuit * 一条龙企业建站服务 * 适合港台和外企使用 CRM（客户关系管理） 12345SalesForce * Saas 类型的客户关系管理 * 主要功能模块包括销售、Call Center（呼叫中心）、市场营销、社区等 * 支持 App 应用 * 可以安装第三方为 SalesForce 开发的应用程序 广告管理 123OpenX（原名 phpAdsNew） * PHP 开发 * 广告管理与跟踪系统，能够管理每个广告主拥有的多种任何尺寸横幅广告 微博搭建 123StatusNet（原名 Laconia） * 免费开源，授权协议 AGPL * 微型博客系统，类似 Twitter Wiki 1234MediaWiki * 免费开源 * PHP * 维基百科使用 MediaWiki 引擎 RSS 1234Gregarius * 免费开源 * RSS 聚合程序 * 不错的用户体验，易于操作和管理，可当成 RSS 阅读器使用 应用托管平台 12345Google App Engine * 只能使用 App Engine 提供的 API * 已被国内屏蔽Sina App Engine * 数据库访问、文件操作、网页抓取等都需要使用新浪提供的 API 虚拟主机管理系统 123456789101112131415161718192021222324252627282930313233VHCS * 支持中文 * 支持服务管理员、代理商、最终客户三级管理 * 具有用户管理、群发邮件、IP 地址管理、流量管理、服务状态查询、统计分析等功能 * 内置客户服务系统ISPConfig * 三级管理 * 反垃圾邮件 * IPTable * 防火墙管理 * 邮件扫描 * Shell * 服务管理 * 回收站SysCP * 三级管理 * 内置客户服务 * 其他功能比较少DTC * 支持中文 * 主要用 PHP（或 perl），用 SH 控制 Apache 重新启动ZPanel * 支持Windows 下的 IIS 和 ApacheISPMan * 适合大型 IDC 使用 * 分布式 ISP 实现方案 * 实施该系统较为复杂 * 功能较为强大，用户结构完善，有管理员、ISP 客户、销售商、ISP 管理员等GNU Hosting Helper * 适合大型 IDC 使用 * 支持分布式管理，多台服务器只需要一个管理员控制面板和一个客户控制面板 * 使用 Perl 编写 * 功能非常强大，具有服务器、防火墙、邮件、域名、服务监控、客户支持等功能 网络营销推广搜索引擎网站联盟电子邮件免费产品社会化营销 博客营销 微博营销 SNS营销 定投广告参考资料 中小企业建站方案和资源]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>Domain</tag>
        <tag>Email</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[企业 Spring 最佳实践]]></title>
    <url>%2F2014%2F08%2F28%2F38090%2F</url>
    <content type="text"><![CDATA[项目配置 参考资料 Enterprise Spring Best Practices – Part 1 – Project Config Enterprise Spring Best Practices – Part 2 – Application Architecture Enterprise Spring Framework Best Practices – Part 3 – XML Config Enterprise Spring Best Practices - Part 4 - Source Code]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sonar 代码质量管理平台]]></title>
    <url>%2F2014%2F08%2F05%2F45706%2F</url>
    <content type="text"><![CDATA[Sonar (SonarQube)是一个开源平台，用于管理源代码的质量。Sonar 不只是一个质量数据报告工具，更是代码质量管理平台。支持的语言包括：Java、PHP、C#、C、Cobol、PL/SQL、Flex 等。 主要特点： 代码覆盖：通过单元测试，将会显示哪行代码被选中 改善编码规则 搜寻编码规则：按照名字，插件，激活级别和类别进行查询 项目搜寻：按照项目的名字进行查询 对比数据：比较同一张表中的任何测量的趋势]]></content>
      <categories>
        <category>Tools</category>
        <category>Sonar</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Sonar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homebrew 命令详解]]></title>
    <url>%2F2014%2F07%2F20%2F18122%2F</url>
    <content type="text"><![CDATA[Homebrew 是 OS X 上的 package 管理工具，用于添加 OS X 中缺失的 package。 获取 Homebrew1234# 打开终端窗口, 执行以下脚本。$ ruby -e "$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)"# 脚本会解释它的作用，然后在您的确认下执行安装。高级安装选项请看 [这里][2]（需要10.5）。 使用命令12# Homebrew installs [the stuff you need][1] that Apple didn’t.$ brew install wget 安装目录Homebrew 会将 packages 安装到独立目录，然后 symlinks 其中文件到目录 /usr/local. 12345678$ cd /usr/local$ find CellarCellar/wget/1.15Cellar/wget/1.15/bin/wgetCellar/wget/1.15/share/man/man1/wget.1$ ls -l binbin/wget -&gt; ../Cellar/wget/1.15/bin/wget Homebrew 的所有文件均会被安装到预定义目录下，另外，你可以将 Homebrew 的安装目录设置在你喜欢的任何地方。 创建自己的 Homebrew 上的 packages12$ brew create http://foo.com/bar-1.0.tgzCreated /usr/local/Library/Formula/bar.rb 维护自己的 packagesHomebrew 基于 git、ruby，所以依据掌握的知识，你可以便捷的撤回你的修改或者合并上游的更新。 12# 打开编辑$ brew edit wget # opens in $EDITOR! Homebrew 的 formulae 都是简单的 Ruby 脚本。 123456789101112require "formula"class Wget &lt; Formula homepage "http://www.gnu.org/software/wget/" url "http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz" sha1 "f3c925f19dfe5ed386daae4f339175c108c50574" def install system "./configure", "--prefix=#&#123;prefix&#125;" system "make", "install" endend Homebrew 使 OS X 更完美。使用 gem 来安装 gems、用 brew 来搞定那些依赖包。 参考资料 Homebrew – The missing package manager for OS X]]></content>
      <categories>
        <category>Tools</category>
        <category>Homebrew</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Npm 命令详解]]></title>
    <url>%2F2014%2F07%2F20%2F20536%2F</url>
    <content type="text"><![CDATA[NPM（Node Packaged Modules），是一个用于管理基于 node.js 编写的 package 的命令行工具。类似于 gem 与 ruby 的关系。 npm 获取配置信息的 6 种方式，优先级由高到低。1# 命令行参数，将 proxy npm 常用命令1234567891011121314151617181920212223242526272829303132333435363738# 查看用户本身配置文件路径npm config get userconfig # defaults to ~/.npmrc# 查看全局用户配置文件路径npm config get globalconfig # defaults to /usr/local/etc/npmrc# 内置配置文件，在 npm 安装目录下的 npmrc 文件夹中# 设置 npm 配置npm config set &lt;key&gt; &lt;value&gt; [--global]npm config get &lt;key&gt;npm config delete &lt;key&gt;npm config listnpm config editnpm get &lt;key&gt;npm set &lt;key&gt; &lt;value&gt; [--global]# 在设置配置属性时属性值默认是被存储于用户配置文件中，如果加上 --global，则被存储在全局配置文件中。# 查看 npm 的所有配置属性（包括默认配置）npm config ls -l# 查看 npm 的各种配置的含义npm help config# 为 npm 设置代理npm config set proxy http://server:portnpm config set https-proxy http://server:port# 如果代理需要认证的话可以这样来设置npm config set proxy http://username:password@server:portnpm config set https-proxy http://username:pawword@server:port# 如果代理不支持 https 的话需要修改 npm 存放 package 的网站地址npm config set registry "http://registry.npmjs.org/"# 卸载sudo npm uninstall npm -g# 或者，如果上面的命令失败了sudo make uninstall 注意事项~/.npm 为 cache 目录，用于避免重复下载相同的 package。若不需要，可以执行以下命令清空 1npm cache clean 参考资料 npm – node package manager npm-index]]></content>
      <categories>
        <category>Tools</category>
        <category>Npm</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSGI 详解]]></title>
    <url>%2F2014%2F07%2F17%2F13631%2F</url>
    <content type="text"><![CDATA[OSGI（Open Service Gateway Initiative，开放服务网关协议），根据上下文的不同，通常可能指的是 OSGI 联盟、OSGI 标准或 OSGI 框架。在 OSGI 联盟官方网站的介绍中，OSGI 现在只是作为一种技术名称了。因为 OSGI 已经逐渐扩展到了企业应用领域，并且在 JAVA 企业级开发中扮演越来越重要的角色。 OSGI 联盟现在将 OSGI 定义为 OSGI 技术是指一系列用于定义 Java 动态化组件系统的标准。这些标准通过为大型分布式系统以及嵌入式系统提供一种模块化架构减少了软件的复杂度。 这一系列的标准由 OSGI 联盟维护，标准的实现通常则称为 OSGI 容器或者 OSGI 服务平台。下面我们就分别简单介绍 OSGI 标准、OSGI 的特点、业务主流的 OSGI 实现与扩展和 OSGI 联盟。 OSGI 标准既然 OSGI 技术是指一系列标准，那么我们从对 OSGI 标准的了解开始。OSGI R1 于 2000 年发布，现在最新的标准版本是 R5，到现在为止应用最广泛的当属是 2005 年发布的 R4。2003 年 Eclipse 开始基于 OSGI 对 Eclipse 进行了重构，IBM 的加入也影响了 R4 的制定，作为 Eclipse 内核的 Equinox 也成为 OSGI 标准的参考实现。OSGI 各个版本的标准可以从 OSGI.org 中下载。最新标准分为两个部分，OSGI Core 和 OSGI Enterpise。 OSGI Core 顾名思义，就是 OSGI 的核心标准，正是这个标准定义了一种动态化模块化的应用架构，其中主要定义了 OSGI 框架。OSGI 框架提供了一个通用安全可管理的 Java 框架，能够支持可扩展可下载的应用（即 bundles）的部署。OSGI 框架是 OSGI 技术最基础也是最核心的部分。OSGI 框架分为以下几层，如下图所示： 安全层 模块层 生命周期层 服务层 服务 安全层基于 Java2 的安全机制增加了一些限制，并且弥补了 Java 标准的一些不足。 模块层定义了一个模块化 Java 模型，对 Java 部署模式的一些缺点进行了改进，并对 bundle（bundle 为 OSGI 中的组件模型，可以简单认为是增加了元数据的 Jar 包） 之间包的共享有严格的规定。模块层独立于生命周期层和服务层，使用时可以不需要生命周期层和服务层。生命周期层提供了对模块层的 bundle 进行管理的 API，而服务层提供了 bundle 之间的通信模型。 生命周期层为 bundle 提供了生命周期管理 API，为 bundle 提供了一个运行时模型，定义了一个 bundle 如何启动、停止、安装和卸载。另外，生命周期层也提供全面的事件 API，允许 bundle 去控制和操作服务平台。 服务层为 bundle 开发者提供了一个动态、简明且并且统一的编程模型，通过解耦服务标准（即 Java 接口）和它的实现，能够简化服务 bundle 的开发和部署。这个模型允许 bundle 开发者只使用他们自己的接口规范来绑定服务。这样接口的实现可以根据实际情况延迟到运行时来选择。框架通过使用服务层，为系统提供了一种扩展机制，成为 hooks。Hooks 是一种框架用来扩展功能的服务。 OSGI 中统一的编程模型可以帮助 bundle 开发者应对很多情况下的扩展的问题，这一点非常重要，因为框架需要运行在各种硬件设备上，设备的不同硬件特性可能影响服务实现的许多方面。统一的接口使得软件组件能够匹配和组合，同时保证稳定的运行。 OSGI 框架中 bundle 可以在运行时通过服务注册中心选择一个可用的实现，bundle 可以注册新服务、接收关于服务状态的通知或者查找服务区以适配当前的设备。这使得一个 bundle 在部署后仍然具有可扩展性，新的 bundle 可被安装，已存在的 bundle 可修改和更新，而无需重新启动系统。 OSGI Enterprise 由 OSGI 联盟的 EEG(Enterprise Expert Group )制定，主要通过裁剪或者扩展 OSGI 框架（即 OSGI Core）来定义技术需求与标准，以满足企业环境下 IT 软件基础设施的用况。OSGI Enterprise 主要包括组件模型、分布式服务、Web 应用于 HTTP Servlet、事件模型、管理与配置服务、名称与目录服务、数据访问、事务支持以及其它一些支持服务。OSGI Enterprise 在这里不详细展开，后面我们将会有详细的介绍。 OSGI 特点OSGI 已经被用于构建很多非常复杂的系统，比如 IDE（Eclipse），应用服务器（GlassFish, IBM Websphere, Oracle/BEA Weblogic, Jonas, JBoss），应用框架（Spring，Guice），工业自动化等等。是什么特点使得 OSGI 称为这些系统的选择呢？ 不妨从几个角度来说一说 OSGI 的特点。从开发的角度来说，OSGI 具有以下特点： 复杂性的降低：基于 OSGI 的组件模型 bundle 能够隐藏内部实现，bundle 基于服务进行交互。 复用：很多第三方的组件可以以 bundle 的形式进行复用。 简单：核心的 API 总共包括不超过 30 个类和接口。 小巧：OSGI R4 框架的实现仅需要 300KB 的 JAR file 就足够。在系统中引入 OSGI 几乎没有什么开销。 非侵入式：服务可以以 POJO 的形式实现，不需要关注特定的接口。 从部署和运行的角度来说，OSGI 的特点就更多了，OSGI 的动态化很大程度体现在系统的部署和运行时。这些特点包括： 切合真实运行环境：OSGI 框架是动态的，bundle 能够进行即时的更新，服务可以根据需要动态增加或者删除。比如一个服务可以是一个网络中的设备，如果一个设备被监测到，则服务可以动态注册；如果设备被移除，则服务能够动态注销。在这样的运行环境中编程将需要耗费大量的开销来处理动态性，但是 OSGI 帮助开发者处理了绝大多数动态性方面的工作。 易于部署：OSGI 定义了组件是如何安装和管理的，标准化的管理 API 使得 OSGI 能够和现有和将来的各种系统有机的集成。 动态更新：这是 OSGI 被最经常提起的一个特性，即所谓的“热插拔”特性，bundle 能够动态的安装、启动、停止、更新和卸载，而整个系统无需重启。 适配性：这主要得益于 OSGI 提供的服务机制、组件可以动态的注册、获取和监听服务，使得系统能够在 OSGI 环境调整自己的功能。 透明：提供了管理 API 来访问内部状态，因此通常无需去查看日志，能够通过命令行进行调试。 版本化：bundle 可以版本化，多版本能够共存而不会影响系统功能，解决了 JAR hell 的问题。（这在开发时也提供了很大的帮助） 快速：这得益于 OSGI 的类加载机制，和 JAR 包的线性加载不同，bundle 委托式的类加载机制，使得类的加载无需进行搜索，这又能有效的加快系统的启动速度。 懒加载：OSGI 技术采用了很多懒加载机制。比如服务可以被注册，但是直到被使用时才创建。 此外 OSGI 还有一些其他的优势，比如： 安全：OSGI 提供了一个安全层，基于 Java 的安全模型增加了可用性。 大公司的支持：OSGI 联盟的成员里包含了很多业界有名的 IT 公司，比如 Oracle, IBM, Samsung, Nokia, Progress, Motorola, NTT, Siemens, Hitachi, Deutsche Telekom, Redhat, Ericsson等。 OSGI 的实现与扩展OSGI 框架最著名的三个实现包括 Apache Felix, Equinox 和 Knopflerfish，这三个实现也是 R4 的认证实现。伴随 OSGI 框架的实现，通常会有相关的扩展，以进一步提供 OSGI 开发的工具或平台。 Apache Felix Felix 项目包含了一个 OSGI R4 服务平台（Service Platform）标准的实现，以及大量相关的 OSGI 功能与技术的实现。Felix 下的子项目有二十多个。除了核心框架的实现，也对主要的 OSGI 服务进行了实现，同时还提供了 iPojo 这样的 OSGI 编程模型（后面我们将会详细介绍）。Felix 还提供了一个强大的 Shell，名叫 Gogo, 用以与 OSGI 的交互。还记得 OSGI 易于部署的特点吗？基于 OSGI 提供的管理 API，你也可以实现一个于 OSGI 平台的交互控制台，甚至是图形化或者 Web 形式的交互方式。Gogo 也被接下来要介绍的 Virgo 所采用。当然，Felix 也提供了支持 OSGI 开发的 SDK，同时还提供了一个 bundle 的中央仓库。 Apache 还有另外一个项目 Aries，这个项目里主要基于 Felix，对 OSGI 企业标准进行了实现。 Equinox Equinox 是 Eclipse 社区开发的 OSGI 框架，也是 Eclipse 强大的插件体系的基础，是 Eclipse 著名的 PDE 开发环境的底层。在 Equinox 的基础上，Eclipse 社区还有其它一些针对企业级开发的扩展项目。2008 年开始 Spring 社区开始将 Spring 的编程模型引入到 OSGI 中，那时项目叫做 Spring-OSGI，后来改名变成 Spring DM，之后成为 OSGI 企业应用的标准，即 Blueprint。可见，Gemini Blueprint 是从 Spring DM 发展而来。使用 Gemini Blueprint 编写的代码更易于测试，同时与 OSGI API 是松耦合的。Gemini Web 是 OSGI Web Application Specification 的一个参考实现，目的在于在 OSGI 环境下更好的支持 Java EE 中的 Servlet 模型。Virgo 项目 EclipseRT 项目的一部分，是一个完全模块化的 Java 运行时。Virgo 自身就是设计为在 Equinox 之上的一个 OSGI bundle 集合。Virgo 可以运行企业级 Java 应用以及基于 Spring 的应用。 值得一提的是，Spring 社区的 OSGI 相关项目大多捐献给了 Eclipse 社区，这些项目也很大程度上影响了 OSGI 在企业级应用上的发展，从标准和工具支持上，都为 OSGI 走向企业级应用做出了很大的贡献。Spring Source 现在也维护着最大也是最全面的一个 bundle 仓库，叫做 Enterprise Bundle Respository，将绝大多数 Java 企业级开发的 Package 转换为了 OSGI bundle。当你真正将 OSGI 应用到实际开发中时，你就能体会到这样一个仓库给我们带来了多大的方便。 Knopflerfish Knopflerfish 也是一个大名鼎鼎的开源 OSGI 服务平台实现，由 Markwave 公司实现，目前最新的版本支持 OSGI R4 V4.2。除了提供运行环境外，Knopflerfish 也提供了一套 Eclipse 的 SDK，帮助开发者开发 OSGI 应用。 参考资料 OSGI 是什么]]></content>
      <categories>
        <category>OSGI</category>
      </categories>
      <tags>
        <tag>OSGI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradle 安装配置及使用]]></title>
    <url>%2F2014%2F07%2F17%2F56514%2F</url>
    <content type="text"><![CDATA[简介Gradle 版本：2.0，支持新特性如下： 更新至 Groovy 2.3.2 支持 Java 8 解决 source 和 javadoc artifacts 的新 API 可以通过 component metadata rules 使用 Ivy extra info 可以通过 plugins.withId() 来整合插件 支持 Ivy 以及 Maven repositories 使用 SFTP scheme Apache Maven POM profile 现在可以基于系统本身属性信息使用 良好的细粒度控制 native 工具的参数传递 简化了跨平台编译及个性化设置（GCC based toolchains） 为 Ivy repositories 提供新的 ‘ivy’ layout 支持 代码质量工具的默认版本更新，以便与当前版本 Gradle 相匹配 Checkstyle：5.7 CodeNarc：0.21 PMD：5.1.1(note that some rulesets were renamed in PMD 5, e.g. basic -&gt; java-basic) Findbugs：2.0.3 JaCoCo：0.7.1.201405082137 Tooling API 改善 更详细的信息，请参考 http://www.gradle.org/docs/ 对应版本的 Release Notes。 与 Eclipse Luna 整合eclipse 版本：4.4.0（Luna） 环境配置 GRADLE_HOME：Gradle 安装目录 path：加入 Gradle bin 目录 GRADLE_OPTS：Gradle 参数选项 JAVA_OPTS：Java 参数选项 eclipse 插件安装Eclipse 插件能自动生成 Eclipse IDE 相关的文件，以便该项目能导入 Eclipse 中。自动生成的文件包括 external dependencies（包含 associated source 以及 javadoc files），project dependencies 等。 参考资料 Gradle 主页 Gradle 下载页 Eclipse 下载页]]></content>
      <categories>
        <category>Gradle</category>
      </categories>
      <tags>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Icon Fonts 详解]]></title>
    <url>%2F2014%2F07%2F14%2F57471%2F</url>
    <content type="text"><![CDATA[像素完美（Pixel Perfection）、分辨率无关（Resolution Independent）和多平台体验一致性是设计师们的追求。 可访问性（Accessability）、加载性能和重构灵活性是前端工程师们关心的主题。 当下互联网设备越来越多，显示分辨率各种各样，为 Web 创建者们带来越来越多的难题。 1）需要为高PPI（aka Retina）显示设备准备@1.5x、@2x、@3x的图片素材。 2）需要针对不同显示屏分辨率来调整优化排版。 3）需要考虑多个分辨率版本的图片的加载性能问题。 4）设备版本碎片化（Version Segmentation）带来的语义和可访问性的问题。 …… 响应式设计响应式设计（Responsive Design）作为解决以上问题的方案，已经发展了很多年。其核心是：针对不同的设备和应用场景，做出合理性的适应。狭义地看，就是 Web page 在不同分辨率下借助 media qurey 来调整页面布局和内容显示，三个关键词是：Fluid grids，Flexible images，Media queries。 其中 Flexible images 是最为棘手的地方。因为前面提到，现在的设备多样化，不同分辨率和不同 PPI 给图片自适应带来了空前复杂度。目前还没有一套完美的解决方案来应对，W3C 那边还在拟定 Responsive Images 和 Picture Element 的相关标准。但在这之前你需要采取多管齐下的方式，针对媒体元素不同的使用场景，制定不同的自适应策略。目前主要有三种主流方式： 1）max-width: 100% 来自适应容器：同一张图片，在不同容器里，自动适应到容器的大小。存在的问题是，大尺寸图片在小尺寸屏幕下的带宽浪费和加载速度慢。 2）多版本图片更换：针对写在 CSS 里的 background-image，可以借助 media query 来适应显示 @1x 或 @2x 的版本。针对 HTML 里的图片可以利用 Piturefill.js 来做自适应。 3）使用矢量化图形，包括：icon fonts，SVG。 什么是 icon fonts利用字体工具把我们平时 Web 上用的图形图标（icons）转换成 web fonts，就成了 icon fonts，它可以借助 CSS 的 @font-face 嵌入到网页里，用以显示 icons。因为字体是矢量化图形，它天生具有分辨率无关的特性，在任何分辨率和 PPI 下面，都可以做到完美缩放，不会像传统位图，如：png，jpeg，放大后有锯齿或模糊现象。 为什么要用 icon fonts icon fonts 优点 1）分辨率无关。 2）文件小：相比图片几十几百KB的容量，icon fonts 几乎是羽翼级轻量。 3）加载性能好：因为图标都被打包进一套字体内，http request 减少。这如同我们常用的 css sprites 技术。 4）支持 CSS 样式：和普通字体一样，你可以利用 CSS 来定义大小、颜色、阴影、hover 状态、透明度、渐变等等。 5）兼容性好：web fonts 起源很早，别说主流浏览器，连 IE6/7 都能良好支持。除了一些老的移动端浏览器，如 Android 2.1 以下的初代浏览器，Opera mini 这类自限型浏览器。 icon fonts 缺点 1）样式单一，无法针对不同分辨率来调整 icon 的细节，比如降低大尺寸 icon 的线条粗细。 2）颜色单一，CSS 无法方便的去定义彩色的 icon，倒是有通过叠加组合的方式来达到彩色图标的目的。 3）移动端浏览器兼容性还不够完善，像 Opera mini、Windows phone 7.0-7.8 都不能正常显示 icon fonts。 4）有少量的移动设备有可能会和 icon fonts 的字符编码冲突，导致 icon 显示不正常。 icon fonts 适用场景 1）你的网站是扁平化或简约风格，图标样式单一，颜色为纯色。 2）你的目标用户使用桌面浏览器为主，或者 3）你愿意为非兼容设备做兼容 hack。 如何制作 icon fonts 利用字体工具手动制作 在 icon fonts 自动生成器没有诞生之初，大家只能依靠字体编辑软件来完成 icon fonts 的制作，简单介绍一下手动制作的流程。 1）在 illustrator 或 Sketch 这类矢量图形软件里创建你的 icon。 2）然后把 icon 一个一个导入到字体编辑工具，转换成 glyphs 进行编辑，设置对应的 unicode 编码。常用字体工具有：Glyphs，FontForge，FontCreator。 3）完成glyphs 编辑后，从字体工具导出 OTF 字体文件，然后利用 Font Squirrel 生成器来生成 web fonts 支持的格式。 利用在线工具自动生成 利用在线工具生成 icon fonts，比如：阿里巴巴提供的免费在线工具 iconfont.cn 1）参照 iconfont.cn 提供的图标制作模版，在 Illustrator 画布的 16x16 网格内，参考基线、上升部、下降部来调整图标大小和位置。 12345调整矢量图标需要注意：1. 图形需要闭合，不要用 stroke，否则会显示不出来。2. 图形合并并扩展。3. 用单色。4. 在 16x16 画布中进行排版，这样制作好的 icon fonts 16px 大小的时候和其它字体保持一致。 2）然后从 Illustrator 保存为 SVG 文件，使用默认的 SVG 设置即可。 3）你可以拖动一个或多个 SVG 图标到 iconfont.cn 的上传表单，完成上传后会提示设置名称和 tag，点击完成上传开始生成 icon fonts。生成完成后，你可以点击要下载的图标加入购物车，然后下载至本地。 4）解压刚下载的文件包，除了 EOT、SVG、TTF、WOFF 四种 web fonts 字体外，还有个 demo.html 展示所有 icons 及其对应的字体编码。之所以有 4 种字体格式，是考虑到不同浏览器不同平台对字体格式的支持不一样，具体看下面 CSS 里的注解。 12345678910111213141516171819202122232425262728293031/*复制 4 个字体文件到 assets 或 fonts 目录下，然后在 CSS 文件加入 @font-face 声明(注意更改字体所在的文件路径)。*/@font-face &#123;font-family: 'iconfont'; src: url('iconfont.eot'); /* IE9*/ src: url('iconfont.eot?#iefix') format('embedded-opentype'), /* IE6-IE8 */ url('iconfont.woff') format('woff'), /* chrome、firefox */ url('iconfont.ttf') format('truetype'), /* chrome、firefox、opera、Safari, Android, iOS 4.2+*/ url('iconfont.svg#uxiconfont') format('svg'); /* iOS 4.1- */&#125;/*再定义一个 icon-* 通配我们所有图标的共有 CSS 样式*/[class^="icon-"], [class*=" icon-"] &#123; display: inline-block; speak: none font-family: "iconfont"; font-size: 16px; line-height: 1; font-style: normal; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale;&#125;/*最后是利用 :before 来注入每个 icon 对应的字体编码*/.icon-bell:before &#123; content: "\003432";&#125;.icon-search:before &#123; content: "\003433";&#125; 12&lt;!--现在你可以这样显示一个铃铛图标--&gt;&lt;i class="icon-bell"&gt;&lt;/i&gt; icon fonts 移动端应用icon fonts 在移动端的兼容性稍微差一点： 1）浏览器根本不支持：举例 Opera mini，在移动设备和带宽比较落后的地方，用户量还是很大的，如果你的网站访问数据里这类浏览器流量不可忽视，那么你就需要额外处理 icon fonts 的向下兼容，比如 js 嗅探后用 CSS spirtes 替代。各平台 icon fonts 的兼容情况，参见这张网友测试汇集的表格。 2）unicode 冲突问题：一般情况下，icon fonts 生成器会使用 PUA（Private Unicode Area）这个安全区域的字符编码（code point）。PUA 是专门预留私用的 unicode 区间, 一般会用 U+E000..U+F8FF 这个 BMP 区间里预留的 PUA code point。比如： 这个 Apple 平台特有的字符，就是用 U+F8FF 这个 code point 来对应的，在其它平台就看不到那个字符。 阿里巴巴的 iconfont.cn 没有遵循这个最佳实践，用得的是 CJK 编码区间（U+3432），所以当你浏览器加载字体出问题时，会还原成一些奇怪的中文文字，这对读屏软件也非常不友好。好在它的管理后台，可以手动的编辑这个 code point。 另外，如果发现有 icon 显示不出来，或被替换成了其它字符，那么更换一下 code point 可能可以快速的解决。 关于如何应用 icon fonts 到原生的 iOS/Android App 中去，iconfont.cn 上面有具体的教程，可以查看一下。 其它 icon fonts 工具类似 iconfont.cn 这类在线生成工具有很多，就不再一一详细介绍，最著名的还有：icomoon，fontfello。 这些工具基本功能类似，但有少许功能差别，像 icomoon 还支持字体的连字（Ligatures）功能。通过设置 bell为铃铛图标的连字，当你在文本中写 bell时自动转换成铃铛图标。像 fontfello 是开源软件，意味着更加灵活和定制的可能性。 如果你对使用英文软件完全没有障碍，我强烈建议使用 icomoon，体验和功能都非常强大。当然作为国内的同行，还是要支持一下 iconfont.cn。 icon fonts 作为 web fonts 的一种特殊应用，很好的解决了响应式设计中图形无损自适应的难题。设计师不再需要维护不同大小、不同颜色的多版本素材，图形矢量化之后，交给那些在线生成器就可以了。对于前端工程师，利用 HTML+CSS 就可以灵活的使用成百上千种图标，无需担心切图、定位、优化等传统位图要应付的情况。而用户，简洁、清晰的图标带给他们赏心悦目的感觉之外，浏览网站的速度体验也将大大提升。 参考资料 响应式Web图形篇 —— icon fonts 的探析及应用]]></content>
      <categories>
        <category>Icon Fonts</category>
      </categories>
      <tags>
        <tag>Icon Fonts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NodeJS 安装、配置及使用]]></title>
    <url>%2F2014%2F07%2F14%2F47281%2F</url>
    <content type="text"><![CDATA[Windows 下安装及配置 NodeJS直接通过 NodeJS 主页 中的 INSTALL 按钮下载并安装。当前 NodeJS 最新版本为 v0.10.29。配置环境变量NODEJS_HOME，并加入path。 Windows 下安装 PostgreSQL 的 pg Module，可用于 NodeJS 连接 PostgreSQL 数据库 1）安装 node-gyp Module 12# nodejs 目录下执行npm install node-gyp 2）node-gyp（0.13.1）的执行需要依赖 Python 以及 vc++。根据 node-gyp 的 README.md 文件选择合适的 Python（v2.7.3）版本安装。。根据操作系统版本及 README.md 说明，选择合适的 vc++ （Win7 下，选择 vc++ 2012）版本安装。 3）安装 pg Module。安装 PostgreSQL 的 Module 之前，请确认 PostgreSQL 的环境变量已经配置好。否则会出现 pg_config 命令无法执行的错误。 12# nodejs 目录下执行npm install pg Windows 下安装 PostgreSQL 的 pg.js Module，可用于 NodeJS 连接 PostgreSQL 数据库 1）安装 pg.js Module 仅需执行以下操作 12# nodejs 目录下执行npm install pg.js 使用参考资料 NodeJS 主页]]></content>
      <categories>
        <category>NodeJS</category>
      </categories>
      <tags>
        <tag>NodeJS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】RESTful API 设计指南]]></title>
    <url>%2F2014%2F07%2F09%2F2836%2F</url>
    <content type="text"><![CDATA[网络应用程序，分为前端和后端两个部分。当前的发展趋势，就是前端设备层出不穷（手机、平板、桌面电脑、其他专用设备……）。因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信。这导致 API 构架的流行，甚至出现“API First”的设计思想。RESTful API是目前比较成熟的一套互联网应用程序的 API 设计理论。我以前写过一篇《理解 RESTful 架构》，探讨如何理解这个概念。 今天，我将介绍 RESTful API 的设计细节，探讨如何设计一套合理、好用的 API。我的主要参考资料是这篇《Principles of good RESTful API Design》。 协议API 与用户的通信协议，总是使用 HTTPs 协议。 域名应该尽量将 API 部署在专用域名之下。 1https://api.example.com 如果确定 API 很简单，不会有进一步扩展，可以考虑放在主域名下。 1https://example.org/api/ 版本（Versioning）应该将 API 的版本号放入URL。 1https://api.example.com/v1/ 另一种做法是，将版本号放在 HTTP 头信息中，但不如放入 URL 方便和直观。 路径（Endpoint）路径又称”终点”（endpoint），表示API的具体网址。 在 RESTful 架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以 API 中的名词也应该使用复数。举例来说，有一个 API 提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。 123https://api.example.com/v1/zooshttps://api.example.com/v1/animalshttps://api.example.com/v1/employees HTTP 动词对于资源的具体操作类型，由 HTTP 动词表示。 1234567891011121314151617181920# 常用的 HTTP 动词有下面五个（括号里是对应的 SQL 命令）。GET（SELECT）：从服务器取出资源（一项或多项）。POST（CREATE）：在服务器新建一个资源。PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。DELETE（DELETE）：从服务器删除资源。# 还有两个不常用的HTTP动词。HEAD：获取资源的元数据。OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。# 下面是一些例子。GET /zoos：列出所有动物园POST /zoos：新建一个动物园GET /zoos/ID：获取某个指定动物园的信息PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息）PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息）DELETE /zoos/ID：删除某个动物园GET /zoos/ID/animals：列出某个指定动物园的所有动物DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物 过滤信息（Filtering）如果记录数量很多，服务器不可能都将它们返回给用户。API 应该提供参数，过滤返回结果。 1234567# 下面是一些常见的参数。?limit=10：指定返回记录的数量?offset=10：指定返回记录的开始位置。?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。?animal_type_id=1：指定筛选条件# 参数的设计允许存在冗余，即允许 API 路径和 URL 参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。 状态码（Status Codes）服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的 HTTP 动词）。 200 OK – [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。 201 CREATED – [POST/PUT/PATCH]：用户新建或修改数据成功。 204 NO CONTENT – [DELETE]：用户删除数据成功。 400 INVALID REQUEST – [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。。 404 NOT FOUND – [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。 500 INTERNAL SERVER ERROR – [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 状态码的完全列表参见这里。 错误处理（Error handling）如果状态码是 4xx，就应该向用户返回出错信息。一般来说，返回的信息中将 error 作为键名，出错信息作为键值即可。 1234&#123; error: "Invalid API key"&#125; 返回结果针对不同操作，服务器向用户返回的结果应该符合以下规范。 GET /collection：返回资源对象的列表（数组） GET /collection/resource：返回单个资源对象 POST /collection：返回新生成的资源对象 PUT /collection/resource：返回完整的资源对象 PATCH /collection/resource：返回完整的资源对象 DELETE /collection/resource：返回一个空文档 Hypermedia APIRESTful API最好做到 Hypermedia，即返回结果中提供链接，连向其他 API 方法，使得用户不查文档，也知道下一步应该做什么。 比如，当用户向 api.example.com 的根目录发出请求，会得到这样一个文档。 1234567&#123;"link": &#123; "rel": "collection https://www.example.com/zoos", "href": "https://api.example.com/zoos", "title": "List of zoos", "type": "application/vnd.yourformat+json"&#125;&#125; 上面代码表示，文档中有一个 link 属性，用户读取这个属性就知道下一步该调用什么 API 了。rel 表示这个 API 与当前网址的关系（collection 关系，并给出该 collection 的网址），href 表示 API 的路径，title 表示 API 的标题，type 表示返回类型。 Hypermedia API 的设计被称为 HATEOAS。Github 的 API 就是这种设计，访问 https://api.github.com/ 会得到一个所有可用 API 的网址列表。 123456&#123; "current_user_url": "https://api.github.com/user", "authorizations_url": "https://api.github.com/authorizations", // ...&#125; 从上面可以看到，如果想获取当前用户的信息，应该去访问https://api.github.com/user，然后就得到了下面结果。 12345&#123; "message": "Requires authentication", "documentation_url": "https://developer.github.com/v3"&#125; 上面代码表示，服务器给出了提示信息，以及文档的网址。 其他 API 的身份认证应该使用 OAuth 2.0 框架。 服务器返回的数据格式，应该尽量使用 JSON，避免使用 XML。 参考资料 RESTful API 设计指南]]></content>
      <categories>
        <category>Restful</category>
      </categories>
      <tags>
        <tag>Restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostGIS 安装、配置及使用]]></title>
    <url>%2F2014%2F07%2F09%2F28994%2F</url>
    <content type="text"><![CDATA[本文主要介绍目前为止最新版本 PostGIS 及 PostgreSQL 的安装、配置及使用。 Windows 下安装及配置Windows 下 Postgresql 安装包提供 Application Stack Builder 方式安装插件（包括 PostGIS 插件），所以 Windows 下安装仅需下载 Postgresql 并进行相关操作 Postgresql 下载地址：http://www.postgresql.org/download Linux 下安装及配置从 shape 文件中将数据导入 PostGIS。需要注意，shape 文件目录不能包含中文名，shape 文件的编码一般设置为 GBK。]]></content>
      <categories>
        <category>Database</category>
        <category>PostGIS</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>PostGIS</tag>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】图片服务架构演进]]></title>
    <url>%2F2014%2F07%2F07%2F27783%2F</url>
    <content type="text"><![CDATA[现在几乎任何一个网站、Web App 以及移动 APP 等应用都需要有图片展示的功能，对于图片功能从下至上都是很重要的。必须要具有前瞻性的规划好图片服务器，图片的上传和下载速度至关重要，当然这并不是说一上来就搞很NB的架构，至少具备一定扩展性和稳定性。虽然各种架构设计都有，在这里我只是谈谈我的一些个人想法。 对于图片服务器来说IO无疑是消耗资源最为严重的，对于web应用来说需要将图片服务器做一定的分离，否则很可能因为图片服务器的 IO 负载导致应用崩溃。因此尤其对于大型网站和应用来说，非常有必要将图片服务器和应用服务器分离，构建独立的图片服务器集群，构建独立的图片服务器其主要优势： 分担 Web 服务器的 I/O 负载-将耗费资源的图片服务分离出来，提高服务器的性能和稳定性。 能够专门对图片服务器进行优化-为图片服务设置有针对性的缓存方案，减少带宽网络成本，提高访问速度。 提高网站的可扩展性-通过增加图片服务器，提高图片服务吞吐能力。 从传统互联网的 web1.0，历经 web2.0 时代以及发展到现在的 web3.0，随着图片存储规模的增加，图片服务器的架构也在逐渐发生变化，以下主要论述三个阶段的图片服务器架构演进。 初始阶段 在介绍初始阶段的早期的小型图片服务器架构之前，首先让我们了解一下 NFS 技术，NFS 是 Network File System 的缩写，即网络文件系统。NFS 是由 Sun 开发并发展起来的一项用于在不同机器，不同操作系统之间通过网络互相分享各自的文件。NFS server 也可以看作是一个 FILE SERVER,用于在 UNIX 类系统之间共享文件，可以轻松的挂载(mount)到一个目录上，操作起来就像本地文件一样的方便。 如果不想在每台图片服务器同步所有图片，那么 NFS 是最简单的文件共享方式。NFS 是个分布式的客户机/服务器文件系统，NFS 的实质在于用户间计算机的共享，用户可以联结到共享计算机并象访问本地硬盘一样访问共享计算机上的文件。具体实现思路是： 所有前端 web 服务器都通过 nfs 挂载 3 台图片服务器 export 出来的目录，以接收 web 服务器写入的图片。然后[图片1]服务器挂载另外两台图片服务器的 export 目录到本地给 apache 对外提供访问。 用户上传图片：用户通过 Internet 访问页面提交上传请求 post 到 web 服务器，web 服务器处理完图片后由 web 服务器拷贝到对应的 mount 本地目录。 用户访问图片：用户访问图片时，通过[图片1]这台图片服务器来读取相应 mount 目录里边的图片。 以上架构存在的问题： 性能：现有结构过度依赖 nfs,当图片服务器的 nfs 服务器有问题时，可能影响到前端 web 服务器。NFS 的问题主要是锁的问题. 很容易造成死锁, 只有硬件重启才能解决。尤其当图片达到一定的量级后，nfs 会有严重的性能问题。 高可用：对外提供下载的图片服务器只有一台，容易出现单点故障。 扩展性：图片服务器之间的依赖过多，而且横向扩展余地不够。 存储：web 服务器上传热点不可控，造成现有图片服务器空间占用不均衡。 安全性：nfs 方式对于拥有 web 服务器的密码的人来说，可以随意修改 nfs 里边的内容，安全级别不高。 当然图片服务器的图片同步可以不采用 NFS,也可以采用 ftp 或 rsync，采用 ftp 这样的话每个图片服务器就都保存一份图片的副本，也起到了备份的作用。但是缺点是将图片 ftp 到服务器比较耗时，如果使用异步方式去同步图片的话又会有延时，不过一般的小图片文件也还好了。使用 rsync 同步，当数据文件达到一定的量级后，每次 rsync 扫描会耗时很久也会带来一定的延时性。 发展阶段 当网站达到一定的规模后，对图片服务器的性能和稳定性有一定的要求后，上述 NFS 图片服务架构面临着挑战，严重的依赖 NFS,而且系统存在单点机器容易出现故障，需要对整体架构进行升级。于是出现了上图图片服务器架构，出现了分布式的图片存储。 其实现的具体思路如下： 用户上传图片到 web 服务器后，web 服务器处理完图片，然后再由前端 web 服务器把图片 post 到到[图片1]、[图片2]…[图片N]其中的一个，图片服务器接收到 post 过来的图片，然后把图片写入到本地磁盘并返回对应成功状态码。前端web服务器根据返回状态码决定对应操作，如果成功的话，处理生成各尺寸的缩略图、打水印，把图片服务器对应的 ID 和对应图片路径写入 DB 数据库。 上传控制：我们需要调节上传时，只需要修改 web 服务器 post 到的目的图片服务器的 ID，就可以控制上传到哪台图片存储服务器,对应的图片存储服务器只需要安装 nginx 同时提供一个 python 或者 php 服务接收并保存图片，如果不想开启 python 或者 php 服务，也可以编写一个 nginx 扩展模块。 用户访问流程：用户访问页面的时候，根据请求图片的 URL 到对应图片服务器去访问图片。如： http://imgN.xxx.com/image1.jpg 此阶段的图片服务器架构，增加了负载均衡和分布式图片存储，能够在一定程度上解决并发访问量高和存储量大的问题。负载均衡在有一定财力的情况下可以考虑 F5 硬负载，当然也可以考虑使用开源的 LVS 软负载(同时还可开启缓存功能)。此时将极大提升访问的并发量，可以根据情况随时调配服务器。当然此时也存在一定的瑕疵，那就是可能在多台 Squid 上存在同一张图片，因为访问图片时可能第一次分到 squid1，在 LVS 过期后第二次访问到 squid2 或者别的，当然相对并发问题的解决，此种少量的冗余完全在我们的允许范围之内。在该系统架构中二级缓存可以使用 squid 也可以考虑使用 varnish 或者 traffic server，对于 cache 的开源软件选型要考率以下几点 1）性能：varnish 本身的技术上优势要高于 squid，它采用了“Visual Page Cache”技术，在内存的利用上，Varnish 比 Squid 具有优势，它避免了 Squid 频繁在内存、磁盘中交换文件，性能要比 Squid 高。varnish 是不能 cache 到本地硬盘上的。还有强大的通过 Varnish 管理端口，可以使用正则表达式快速、批量地清除部分缓存。nginx 是用第三方模块 ncache 做的缓冲，其性能基本达到 varnish，但在架构中 nginx 一般作为反向（静态文件现在用 nginx 的很多，并发能支持到2万+）。在静态架构中，如果前端直接面对的是 cdn 活着前端了 4 层负载的话，完全用 nginx 的 cache 就够了。 2）避免文件系统式的缓存，在文件数据量非常大的情况下，文件系统的性能很差，像 squid,nginx的proxy_store,proxy_cache 之类的方式缓存，当缓存的量级上来后，性能将不能满足要求。开源的 traffic server 直接用裸盘缓存，是一个不错的选择，国内大规模应用并公布出来的主要是淘宝，并不是因为它做的差，而是开源时间晚。Traffic Server 在 Yahoo 内部使用了超过 4 年，主要用于 CDN 服务，CDN 用于分发特定的 HTTP 内容，通常是静态的内容如图片、JavaScript、CSS。当然使用 leveldb 之类的做缓存，我估计也能达到很好的效果。 3）稳定性：squid 作为老牌劲旅缓存，其稳定性更可靠一些，从我身边一些使用者反馈来看 varnish 偶尔会出现 crash 的情况。Traffic Server 在雅虎目前使用期间也没有出现已知的数据损坏情况，其稳定性相对也比较可靠，对于未来我其实更期待 Traffic Server 在国内能够拥有更多的用户。 以上图片服务架构设计消除了早期的 NFS 依赖以及单点问题，时能够均衡图片服务器的空间，提高了图片服务器的安全性等问题，但是又带来一个问题是图片服务器的横向扩展冗余问题。只想在普通的硬盘上存储，首先还是要考虑一下物理硬盘的实际处理能力。是 7200 转的还是 15000 转的，实际表现差别就很大。至于文件系统选择 xfs、ext3、ext4 还是 reiserFs，需要做一些性能方面的测试，从官方的一些测试数据来看，reiserFs 更适合存储一些小图片文件。创建文件系统的时候 Inode 问题也要加以考虑，选择合适大小的 inode size，因为 Linux 为每个文件分配一个称为索引节点的号码 inode，可以将 inode 简单理解成一个指针，它永远指向本文件的具体存储位置。一个文件系统允许的 inode 节点数是有限的，如果文件数量太多，即使每个文件都是 0 字节的空文件，系统最终也会因为节点空间耗尽而不能再创建文件，因此需要在空间和速度上做取舍，构造合理的文件目录索引。 云存储阶段 2011 年李彦宏在百度联盟峰会上就提到过互联网的读图时代已经到来，图片服务早已成为一个互联网应用中占比很大的部分，对图片的处理能力也相应地变成企业和开发者的一项基本技能,图片的下载和上传速度显得更加重要，要想处理好图片，需要面对的三个主要问题是：大流量、高并发、海量存储。 阿里云存储服务(OpenStorageService，简称OSS)，是阿里云对外提供的海量，安全，低成本，高可靠的云存储服务。用户可以通过简单的 REST 接口，在任何时间、任何地点上传和下载数据，也可以使用 WEB 页面对数据进行管理。同时，OSS 提供 Java、Python、PHP SDK，简化用户的编程。基于 OSS，用户可以搭建出各种多媒体分享网站、网盘、个人企业数据备份等基于大规模数据的服务。在以下图片云存储主要以阿里云的云存储 OSS 为切入点介绍，上图为 OSS 云存储的简单架构示意图。 真正意义上的“云存储”，不是存储而是提供云服务，使用云存储服务的主要优势有以下几点： 用户无需了解存储设备的类型、接口、存储介质等。 无需关心数据的存储路径。 无需对存储设备进行管理、维护。 无需考虑数据备份和容灾 简单接入云存储，尽情享受存储服务。 架构模块组成 1）KV Engine：OSS 中的 Object 源信息和数据文件都是存放在 KV Engine 上。在 6.15 的版本，V Engine 将使用 0.8.6 版本，并使用为 OSS 提供的 OSSFileClient。 2）Quota：此模块记录了 Bucket 和用户的对应关系，和以分钟为单位的 Bucket 资源使用情况。Quota 还将提供 HTTP 接口供 Boss 系统查询。 3）安全模块：安全模块主要记录 User 对应的 ID 和 Key，并提供 OSS 访问的用户验证功能。 OSS 术语名词汇 Access Key ID &amp; Access Key Secret （API 密钥）：用户注册 OSS 时，系统会给用户分配一对 Access Key ID &amp; Access Key Secret，称为 ID 对，用于标识用户，为访问 OSS 做签名验证。 Service：OSS 提供给用户的虚拟存储空间，在这个虚拟空间中，每个用户可拥有一个到多个 Bucket。 Bucket：Bucket 是 OSS 上的命名空间；Bucket 名在整个 OSS 中具有全局唯一性，且不能修改；存储在 OSS 上的每个 Object 必须都包含在某个 Bucket 中。一个应用，例如图片分享网站，可以对应一个或多个 Bucket。一个用户最多可创建 10 个 Bucket，但每个 Bucket 中存放的 Object 的数量和大小总和没有限制，用户不需要考虑数据的可扩展性。 Object：在 OSS 中，用户的每个文件都是一个 Object，每个文件需小于 5TB。Object 包含 key、data 和 user meta。其中，key 是 Object 的名字；data 是 Object 的数据；user meta 是用户对该 object 的描述。 12345// 其使用方式非常简单,如下为 java sdk：OSSClient ossClient = new OSSClient(accessKeyId,accessKeySecret);PutObjectResult result = ossClient.putObject(bucketname, bucketKey, inStream, new ObjectMetadata());// 执行以上代码即可将图片流上传至 OSS 服务器上。// 图片的访问方式也非常简单其 url 为：http://bucketname.oss.aliyuncs.com/bucketKey 分布式文件系统：用分布式存储有几个好处，分布式能自动提供冗余，不需要我们去备份，担心数据安全，在文件数量特别大的情况下，备份是一件很痛苦的事情，rsync 扫一次可能是就是好几个小时，还有一点就是分布式存储动态扩容方便。当然在国内的其他一些文件系统里，TFS和 FASTDFS 也有一些用户，但是 TFS 的优势更是针对一些小文件存储，主要是淘宝在用。另外 FASTDFS 在并发高于 300 写入的情况下出现性能问题，稳定性不够友好。OSS 存储使用的是阿里云基于飞天 5k 平台自主研发的高可用，高可靠的分布式文件系统盘古。分布式文件系统盘古和 Google 的 GFS 类似，盘古的架构是 Master-Slave 主从架构，Master 负责元数据管理，Slave 叫做 Chunk Server，负责读写请求。其中 Master 是基于 Paxos 的多 Master 架构，一个 Master 死了之后，另外一个 Master 可以很快接过去，基本能够做到故障恢复在一分钟以内 。文件是按照分片存放，每个会分三个副本，放在不同的机架上，最后提供端到端的数据校验。 HAPROXY 负载均衡：基于 haproxy 的自动 hash 架构 ,这是一种新的缓存架构，由 nginx 作为最前端，代理到缓存机器。 nginx 后面是缓存组，由 nginx 经过 url hash 后将请求分到缓存机器。这个架构方便纯 squid 缓存升级，可以在 squid 的机器上加装 nginx。 nginx 有缓存的功能，可以将一些访问量特大的链接直接缓存在 nginx 上，就不用经过多一次代理的请求，能够保证图片服务器的高可用、高性能。比如 favicon.ico 和网站的 logo。 负载均衡负责 OSS 所有的请求的负载均衡，后台的 http 服务器故障会自动切换，从而保证了 OSS 的服务不间断。 CDN：阿里云 CDN 服务是一个遍布全国的分布式缓存系统，能够将网站文件（如图片或 JavaScript 代码文件）缓存到全国多个城市机房中的服务器上，当一个用户访问你的网站时，会就近到靠近 TA 的城市的服务器上获取数据，这样最终用户访问你的服务速度会非常快。阿里云 CDN 服务在全国部署超过 100 个节点，能提供给用户优良的网络加速效果。当网站业务突然爆发增长时，无需手忙脚乱地扩容网络带宽，使用 CDN 服务即可轻松应对。和 OSS 服务一样，使用 CDN，需要先在 aliyun.com 网站上开通 CDN 服务。开通后，需要在网站上的管理中心创建你的 distribution（即分发频道），每个 distribution 由两个必须的部分组成：distribution ID 和源站地址。使用阿里云 OSS 和 CDN 可以非常方便的针对每个 bucket 进行内容加速，因为每个 bucket 对应一个独立的二级域名，针对每个文件进行 CDN 删除，简单、经济地解决服务的存储和网络问题，毕竟大多数网站或应用的存储和网络带宽多半是被图片或视频消耗掉的。从整个业界来看，最近这样的面向个人用户的云存储如国外的 DropBox 和 Box.net 非常受欢迎，国内的云存储目前比较不错的主要有七牛云存储和又拍云存储。 上传下载分而治之：图片服务器的图片下载比例远远高于上传比例，业务逻辑的处理也区别明显，上传服器对图片重命名，记录入库信息，下载服务器对图片添加水印、修改尺寸之类的动态处理。从高可用的角度，我们能容忍部分图片下载失败，但绝不能有图片上传失败，因为上传失败，意味着数据的丢失。上传与下载分开，能保证不会因下载的压力影响图片的上传，而且还有一点，下载入口和上传入口的负载均衡策略也有所不同。上传需要经过 Quota Server 记录用户和图片的关系等逻辑处理，下载的逻辑处理如果绕过了前端缓存处理，穿透后端业务逻辑处理，需要从 OSS 获取图片路径信息。近期阿里云会推出基于 CDN 就近上传的功能，自动选择离用户最近的 CDN 节点，使得数据的上传下载速度均得到最优化。相较传统 IDC，访问速度提升数倍。 图片防盗链处理：如果服务不允许防盗链，那么访问量会引起带宽、服务器压力等问题。比较通用的解决方案是在 nginx 或者 squid 反向代理软件上添加 refer ACL 判断，OSS 也提供了基于 refer 的防盗链技术。当然 OSS 也提供了更为高级的 URL 签名防盗链，其其实现思路如下： 首先，确认自己的 bucket 权限是 private，即这个 bucket 的所有请求必须在签名认证通过后才被认为是合法的。然后根据操作类型、要访问的 bucket、要访问的 object 以及超时时间，动态地生成一个经过签名的 URL。通过这个签名 URL，你授权的用户就可以在该签名 URL 过期时间前执行相应的操作。 123// 签名的Python代码如下：h=hmac.new(“OtxrzxIsfpFjA7SwPzILwy8Bw21TLhquhboDYROV”, “GET\n\n\n1141889120\n/oss-example/oss-api.jpg”,sha);urllib.quote_plus (base64.encodestring(h.digest()).strip()); 其中 method 可以是 PUT、GET、HEAD、DELETE 中的任意一种；最后一个参数“timeout”是超时的时间，单位是秒。一个通过上面 Python 方法，计算得到的签名 URL 为：http://oss-example.oss-cn-hangzhou.aliyuncs.com/oss-api.jpg?OSSAccessKeyId=44CF9590006BF252F707&amp;Expires=1141889120&amp;Signature=vjbyPxybdZaNmGa%2ByT272YEAiv4%3D 通过这种动态计算签名 URL 的方法，可以有效地保护放在 OSS 上的数据，防止被其他人盗链。 图片编辑处理 API：对于在线图片的编辑处理，GraphicsMagick（GraphicsMagick(http://www.graphicsmagick.org/)）对于从事互联网的技术人员应该不会陌生。GraphicsMagick 是从 ImageMagick 5.5.2 分支出来的，但是现在他变得更稳定和优秀，GM 更小更容易安装、GM 更有效率、GM 的手册非常丰富 GraphicsMagick 的命令与 ImageMagick 基本是一样的。 GraphicsMagick 提供了包括裁、缩放、合成、打水印、图像转换、填充等非常丰富的接口 API,其中的开发包 SDK 也非常丰富，包括了 JAVA(im4java)、C、C++、Perl、PHP、Tcl、Ruby 等的调用，支持超过 88 中图像格式，包括重要的 DPX、GIF、JPEG、JPEG-2000、PNG、PDF、PNM 和 TIFF，GraphicsMagick 可以再绝大多数的平台上使用，Linux、Mac、Windows 都没有问题。但是独立开发这些图片处理服务，对服务器的 IO 要求相对要高一些，而且目前这些开源的图片处理编辑库，相对来说还不是很稳定，笔者在使用 GraphicsMagick 的时候就遇到了 tomcat 进程 crash 情况，需要手动重启 tomcat 服务。 阿里云目前已经对外开放图片处理 API,包括了大多数常用处理解决方案：缩略图、打水印、文字水印、样式、管道等。开发者可以非常方便的使用如上图片处理方案，希望越来越多的开发者能够基于 OSS 开放出更多优秀的产品。 参考资料 图片服务架构演进]]></content>
      <categories>
        <category>Architecture</category>
        <category>Picture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
        <tag>Picture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH 原理与运用]]></title>
    <url>%2F2014%2F07%2F04%2F60583%2F</url>
    <content type="text"><![CDATA[SSH 是每一台 Linux 电脑的标准配置。随着 Linux 设备从电脑逐渐扩展到手机、外设和家用电器，SSH 的使用范围也越来越广。不仅程序员离不开它，很多普通用户也每天使用。 SSH 具备多种功能，可以用于很多场合。有些事情，没有它就是办不成。本文是我的学习笔记，总结和解释了 SSH 的常见用法，希望对大家有用。 什么是SSH简单说，SSH 是一种网络协议，用于计算机之间的加密登录。如果一个用户从本地计算机，使用 SSH 协议登录另一台远程计算机，我们就可以认为，这种登录是安全的，即使被中途截获，密码也不会泄露。 最早的时候，互联网通信都是明文通信，一旦被截获，内容就暴露无疑。1995 年，芬兰学者 Tatu Ylonen 设计了 SSH 协议，将登录信息全部加密，成为互联网安全的一个基本解决方案，迅速在全世界获得推广，目前已经成为 Linux 系统的标准配置。 需要指出的是，SSH 只是一种协议，存在多种实现，既有商业实现，也有开源实现。本文针对的实现是 OpenSSH，它是自由软件，应用非常广泛。 此外，本文只讨论 SSH 在 Linux Shell 中的用法。如果要在 Windows 系统中使用 SSH，会用到另一种软件 PuTTY，这需要另文介绍。 SSH 安装Ubuntu 下 SSHUbuntu 服务端 SSH Server 安装12345678910# 更新源列表sudo apt-get update# 安装 openssh-serversudo apt-get install openssh-server# 查看服务是否启动sudo ps -e |grep ssh# 编辑 SSH 配置文件, 允许密码登陆(PasswordAuthentication yes)sudo gedit /etc/ssh/ssh_config# 重启 SSH Serversudo service ssh restart 最基本的用法SSH 主要用于远程登录。假定你要以用户名 user，登录远程主机 host，只要一条简单命令就可以了。 1$ ssh user@host 如果本地用户名与远程用户名一致，登录时可以省略用户名。 1$ ssh host SSH 的默认端口是 22，也就是说，你的登录请求会送进远程主机的 22 端口。使用 p 参数，可以修改这个端口。 1$ ssh -p 2222 user@host 上面这条命令表示，ssh 直接连接远程主机的 2222 端口。 中间人攻击SSH 之所以能够保证安全，原因在于它采用了公钥加密。整个过程是这样的： 1231）远程主机收到用户的登录请求，把自己的公钥发给用户。2）用户使用这个公钥，将登录密码加密后，发送回来。3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。 这个过程本身是安全的，但是实施的时候存在一个风险：如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。因为不像 https 协议，SSH 协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。可以设想，如果攻击者插在用户与远程主机之间（比如在公共的 wifi 区域），用伪造的公钥，获取用户的登录密码。再用这个密码登录远程主机，那么 SSH 的安全机制就荡然无存了。这种风险就是著名的“中间人攻击”（ Man-in-the-middle attack）。SSH 协议是如何应对的呢？ 口令登陆如果你是第一次登录对方主机，系统会出现下面的提示： 1234$ ssh user@hostThe authenticity of host ‘host (12.18.429.21)’ can’t be established.RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.Are you sure you want to continue connecting (yes/no)? 这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？ 所谓”公钥指纹”，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d，再进行比较，就容易多了。 很自然的一个问题就是，用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。 12345678# 假定经过风险衡量以后，用户决定接受这个远程主机的公钥。Are you sure you want to continue connecting (yes/no)? yes# 系统会出现一句提示，表示host主机已经得到认可。Warning: Permanently added ‘host,12.18.429.21′ (RSA) to the list of known hosts.# 然后，会要求输入密码。Password: (enter password) 如果密码正确，就可以登录了。 当远程主机的公钥被接受以后，它就会被保存在文件$HOME/.ssh/known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。 每个 SSH 用户都有自己的 known_hosts 文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。 公钥登录使用密码登录，每次都必须输入密码，非常麻烦。好在 SSH 还提供了公钥登录，可以省去输入密码的步骤。所谓”公钥登录”，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录 shell，不再要求密码。 这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个： 1$ ssh-keygen 运行上面的命令以后，系统会出现一系列提示，可以一路回车。其中有一个问题是，要不要对私钥设置口令（passphrase），如果担心私钥的安全，这里可以设置一个。 运行结束以后，在$HOME/.ssh/目录下，会新生成两个文件：id_rsa.pub和id_rsa。前者是你的公钥，后者是你的私钥。 这时再输入下面的命令，将公钥传送到远程主机 host 上面： 1$ ssh-copy-id user@host 好了，从此你再登录，就不需要输入密码了。 如果还是不行，就打开远程主机的/etc/ssh/sshd_config这个文件，检查下面几行前面”#”注释是否取掉。 123RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 然后，重启远程主机的 ssh 服务。 12345// ubuntu系统service ssh restart// debian系统/etc/init.d/ssh restart authorized_keys 文件远程主机将用户的公钥，保存在登录后的用户主目录的$HOME/.ssh/authorized_keys文件中。公钥就是一段字符串，只要把它追加在authorized_keys文件的末尾就行了。这里不使用上面的 ssh-copy-id 命令，改用下面的命令，解释公钥的保存过程： 1$ ssh user@host 'mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys' &lt; ~/.ssh/id_rsa.pub 这条命令由多个语句组成，依次分解开来看：（1）”$ ssh user@host”，表示登录远程主机；（2）单引号中的 mkdir .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys，表示登录后在远程 shell 上执行的命令：（3）”$ mkdir -p .ssh”的作用是，如果用户主目录中的 .ssh 目录不存在，就创建一个；（4）’cat &gt;&gt; .ssh/authorized_keys’ &lt; ~/.ssh/id_rsa.pub 的作用是，将本地的公钥文件~/.ssh/id_rsa.pub，重定向追加到远程文件authorized_keys的末尾。写入authorized_keys文件后，公钥登录的设置就完成了。 远程操作SSH 不仅可以用于远程主机登录，还可以直接在远程主机上执行操作。 1234567891011121314$ ssh user@host 'mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys' &lt; ~/.ssh/id_rsa.pub# 单引号中间的部分，表示在远程主机上执行的操作；后面的输入重定向，表示数据通过 SSH 传向远程主机。这就是说，SSH 可以在用户和远程主机之间，建立命令和数据的传输通道，因此很多事情都可以通过 SSH 来完成。下面看几个例子。# 将`$HOME/src/`目录下面的所有文件，复制到远程主机的`$HOME/src/`目录。$ cd &amp;&amp; tar czv src | ssh user@host 'tar xz'# 将远程主机`$HOME/src/`目录下面的所有文件，复制到用户的当前目录。$ ssh user@host 'tar cz src' | tar xzv# 查看远程主机是否运行进程 httpd。$ ssh user@host 'ps ax | grep [h]ttpd' 绑定本地端口既然 SSH 可以传送数据，那么我们可以让那些不加密的网络连接，全部改走 SSH 连接，从而提高安全性。假定我们要让 8080 端口的数据，都通过 SSH 传向远程主机，命令就这样写： 1$ ssh -D 8080 user@host SSH 会建立一个 socket，去监听本地的 8080 端口。一旦有数据传向那个端口，就自动把它转移到 SSH 连接上面，发往远程主机。可以想象，如果 8080 端口原来是一个不加密端口，现在将变成一个加密端口。 本地端口转发有时，绑定本地端口还不够，还必须指定数据传送的目标主机，从而形成点对点的”端口转发”。为了区别后文的”远程端口转发”，我们把这种情况称为”本地端口转发”（Local forwarding）。 假定 host1 是本地主机，host2 是远程主机。由于种种原因，这两台主机之间无法连通。但是，另外还有一台 host3，可以同时连通前面两台主机。因此，很自然的想法就是，通过 host3，将 host1 连上 host2。我们在 host1 执行下面的命令： 1$ ssh -L 2121:host2:21 host3 命令中的 L 参数一共接受三个值，分别是”本地端口:目标主机:目标主机端口”，它们之间用冒号分隔。这条命令的意思，就是指定 SSH 绑定本地端口 2121，然后指定 host3 将所有的数据，转发到目标主机 host2 的 21 端口（假定 host2 运行 FTP，默认端口为 21）。 这样一来，我们只要连接 host1 的 2121 端口，就等于连上了 host2 的 21 端口。 1$ ftp localhost:2121 “本地端口转发”使得 host1 和 host3 之间仿佛形成一个数据传输的秘密隧道，因此又被称为”SSH隧道”。 远程端口转发既然”本地端口转发”是指绑定本地端口的转发，那么”远程端口转发”（remote forwarding）当然是指绑定远程端口的转发。 还是接着看上面那个例子，host1 与 host2 之间无法连通，必须借助 host3 转发。但是，特殊情况出现了，host3 是一台内网机器，它可以连接外网的 host1，但是反过来就不行，外网的 host1 连不上内网的 host3。这时，”本地端口转发”就不能用了，怎么办？ 解决办法是，既然 host3 可以连 host1，那么就从 host3 上建立与 host1 的 SSH 连接，然后在 host1 上使用这条连接就可以了。 我们在 host3 执行下面的命令： 1$ ssh -R 2121:host2:21 host1 R 参数也是接受三个值，分别是”远程主机端口:目标主机:目标主机端口”。这条命令的意思，就是让 host1 监听它自己的 2121 端口，然后将所有数据经由 host3，转发到 host2 的 21 端口。由于对于 host3 来说，host1 是远程主机，所以这种情况就被称为”远程端口绑定”。 绑定之后，我们在 host1 就可以连接 host2 了： 1$ ftp localhost:2121 这里必须指出，”远程端口转发”的前提条件是，host1 和 host3 两台主机都有 sshD 和 ssh 客户端。 SSH 的其他参数SSH 还有一些别的参数，也值得介绍。 N 参数，表示只连接远程主机，不打开远程 shell；T 参数，表示不为这个连接分配 TTY。这个两个参数可以放在一起用，代表这个 SSH 连接只用来传数据，不执行远程操作。 1$ ssh -NT -D 8080 host f 参数，表示 SSH 连接成功后，转入后台运行。这样一来，你就可以在不中断 SSH 连接的情况下，在本地 shell 中执行其他操作。 1$ ssh -f -D 8080 host 要关闭这个后台连接，就只有用 kill 命令去杀掉进程。 参考资料 SSH 原理与运用（一）：远程登录 SSH 原理与运用（二）：远程操作与端口转发]]></content>
      <categories>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javascript 获取 IP 地址方法]]></title>
    <url>%2F2014%2F07%2F04%2F22296%2F</url>
    <content type="text"><![CDATA[Javascript 获取客户端 IP 的方法如下： 1234567891011# 一&lt;script src="http://pv.sohu.com/cityjson?ie=utf-8"&gt;&lt;/script&gt;&lt;script type="text/&lt;A class="infotextkey" href="http://www.jbxue.com/jb/js/" target=_blank&gt;javascript&lt;/A&gt;"&gt;document.write(returnCitySN["cip"]+','+returnCitySN["cname"])&lt;/script&gt;# 二&lt;script src="http://pv.sohu.com/cityjson?ie=utf-8"&gt;&lt;/script&gt;&lt;script type="text/&lt;A class="infotextkey" href="http://www.jbxue.com/jb/js/" target=_blank&gt;javascript&lt;/A&gt;"&gt;document.write(returnCitySN["cip"]+','+returnCitySN["cname"])&lt;/script&gt;# 三&lt;script type="text/javascript" src="http://fw.qq.com/ipaddress" charset="gb2312"&gt;&lt;/script&gt;$(document).ready(function() &#123;$("#ip").val(IPData[0]);$("#add").val(IPData[2]);&#125;)]]></content>
      <categories>
        <category>Javascript</category>
        <category>IP</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux tcpdump 命令详解二]]></title>
    <url>%2F2014%2F07%2F03%2F26161%2F</url>
    <content type="text"><![CDATA[命令使用tcpdump 采用命令行方式，它的命令格式为： 12345678tcpdump [ -AdDeflLnNOpqRStuUvxX ] [ -c count ] [ -C file_size ] [ -F file ] [ -i interface ] [ -m module ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -Z user ] [ expression ] tcpdump 的简单选项介绍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130-A 以ASCII码方式显示每一个数据包(不会显示数据包中链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据(nt: 即Handy for capturing web pages).-c count tcpdump将在接受到count个数据包后退出.-C file-size (nt: 此选项用于配合-w file 选项使用) 该选项使得tcpdump 在把原始数据包直接保存到文件中之前, 检查此文件大小是否超过file-size. 如果超过了, 将关闭此文件,另创一个文件继续用于原始数据包的记录. 新创建的文件名与-w 选项指定的文件名一致, 但文件名后多了一个数字.该数字会从1开始随着新创建文件的增多而增加. file-size的单位是百万字节(nt: 这里指1,000,000个字节,并非1,048,576个字节, 后者是以1024字节为1k, 1024k字节为1M计算所得, 即1M=1024 ＊ 1024 ＝ 1,048,576)-d 以容易阅读的形式,在标准输出上打印出编排过的包匹配码, 随后tcpdump停止.(nt | rt: human readable, 容易阅读的,通常是指以ascii码来打印一些信息. compiled, 编排过的. packet-matching code, 包匹配码,含义未知, 需补充)-dd 以C语言的形式打印出包匹配码.-ddd 以十进制数的形式打印出包匹配码(会在包匹配码之前有一个附加的'count'前缀).-D 打印系统中所有tcpdump可以在其上进行抓包的网络接口. 每一个接口会打印出数字编号, 相应的接口名字, 以及可能的一个网络接口描述. 其中网络接口名字和数字编号可以用在tcpdump 的-i flag 选项(nt: 把名字或数字代替flag), 来指定要在其上抓包的网络接口. 此选项在不支持接口列表命令的系统上很有用(nt: 比如, Windows 系统, 或缺乏 ifconfig -a 的UNIX系统); 接口的数字编号在windows 2000 或其后的系统中很有用, 因为这些系统上的接口名字比较复杂, 而不易使用. 如果tcpdump编译时所依赖的libpcap库太老,-D 选项不会被支持, 因为其中缺乏 pcap_findalldevs()函数.-e 每行的打印输出中将包括数据包的数据链路层头部信息-E spi@ipaddr algo:secret,... 可通过spi@ipaddr algo:secret 来解密IPsec ESP包(nt | rt:IPsec Encapsulating Security Payload,IPsec 封装安全负载, IPsec可理解为, 一整套对ip数据包的加密协议, ESP 为整个IP 数据包或其中上层协议部分被加密后的数据,前者的工作模式称为隧道模式; 后者的工作模式称为传输模式 . 工作原理, 另需补充). 需要注意的是, 在终端启动tcpdump 时, 可以为IPv4 ESP packets 设置密钥(secret）. 可用于加密的算法包括des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, 或者没有(none).默认的是des-cbc(nt: des, Data Encryption Standard, 数据加密标准, 加密算法未知, 另需补充).secret 为用于ESP 的密钥, 使用ASCII 字符串方式表达. 如果以 0x 开头, 该密钥将以16进制方式读入. 该选项中ESP 的定义遵循RFC2406, 而不是 RFC1827. 并且, 此选项只是用来调试的, 不推荐以真实密钥(secret)来使用该选项, 因为这样不安全: 在命令行中输入的secret 可以被其他人通过ps 等命令查看到. 除了以上的语法格式(nt: 指spi@ipaddr algo:secret), 还可以在后面添加一个语法输入文件名字供tcpdump 使用(nt：即把spi@ipaddr algo:secret,... 中...换成一个语法文件名). 此文件在接受到第一个ESP 包时会打开此文件, 所以最好此时把赋予tcpdump 的一些特权取消(nt: 可理解为, 这样防范之后, 当该文件为恶意编写时,不至于造成过大损害).-f 显示外部的IPv4 地址时(nt: foreign IPv4 addresses, 可理解为, 非本机ip地址), 采用数字方式而不是名字.(此选项是用来对付Sun公司的NIS服务器的缺陷(nt: NIS, 网络信息服务, tcpdump 显示外部地址的名字时会用到她提供的名称服务): 此NIS服务器在查询非本地地址名字时,常常会陷入无尽的查询循环). 由于对外部(foreign)IPv4地址的测试需要用到本地网络接口(nt: tcpdump 抓包时用到的接口)及其IPv4 地址和网络掩码. 如果此地址或网络掩码不可用, 或者此接口根本就没有设置相应网络地址和网络掩码(nt: linux 下的 'any' 网络接口就不需要设置地址和掩码, 不过此'any'接口可以收到系统中所有接口的数据包), 该选项不能正常工作.-F file 使用file 文件作为过滤条件表达式的输入, 此时命令行上的输入将被忽略.-i interface 指定tcpdump 需要监听的接口. 如果没有指定, tcpdump 会从系统接口列表中搜寻编号最小的已配置好的接口(不包括 loopback 接口).一但找到第一个符合条件的接口, 搜寻马上结束. 在采用2.2版本或之后版本内核的Linux 操作系统上, 'any' 这个虚拟网络接口可被用来接收所有网络接口上的数据包(nt: 这会包括目的是该网络接口的, 也包括目的不是该网络接口的). 需要注意的是如果真实网络接口不能工作在'混杂'模式(promiscuous)下,则无法在'any'这个虚拟的网络接口上抓取其数据包. 如果 -D 标志被指定, tcpdump会打印系统中的接口编号，而该编号就可用于此处的interface 参数.-l 对标准输出进行行缓冲(nt: 使标准输出设备遇到一个换行符就马上把这行的内容打印出来).在需要同时观察抓包打印以及保存抓包记录的时候很有用. 比如, 可通过以下命令组合来达到此目的: ``tcpdump -l | tee dat'' 或者 ``tcpdump -l &gt; dat &amp; tail -f dat''.(nt: 前者使用tee来把tcpdump 的输出同时放到文件dat和标准输出中, 而后者通过重定向操作'&gt;', 把tcpdump的输出放到dat 文件中, 同时通过tail把dat文件中的内容放到标准输出中)-L 列出指定网络接口所支持的数据链路层的类型后退出.(nt: 指定接口通过-i 来指定)-m module 通过module 指定的file 装载SMI MIB 模块(nt: SMI，Structure of Management Information, 管理信息结构MIB, Management Information Base, 管理信息库. 可理解为, 这两者用于SNMP(Simple Network Management Protoco)协议数据包的抓取. 具体SNMP 的工作原理未知, 另需补充). 此选项可多次使用, 从而为tcpdump 装载不同的MIB 模块.-M secret 如果TCP 数据包(TCP segments)有TCP-MD5选项(在RFC 2385有相关描述), 则为其摘要的验证指定一个公共的密钥secret.-n 不对地址(比如, 主机地址, 端口号)进行数字表示到名字表示的转换.-N 不打印出host 的域名部分. 比如, 如果设置了此选现, tcpdump 将会打印'nic' 而不是 'nic.ddn.mil'.-O 不启用进行包匹配时所用的优化代码. 当怀疑某些bug是由优化代码引起的, 此选项将很有用.-p 一般情况下, 把网络接口设置为非'混杂'模式. 但必须注意 , 在特殊情况下此网络接口还是会以'混杂'模式来工作； 从而, '-p' 的设与不设, 不能当做以下选现的代名词:'ether host &#123;local-hw-add&#125;' 或 'ether broadcast'(nt: 前者表示只匹配以太网地址为host 的包, 后者表示匹配以太网地址为广播地址的数据包).-q 快速(也许用'安静'更好?)打印输出. 即打印很少的协议相关信息, 从而输出行都比较简短.-R 设定tcpdump 对 ESP/AH 数据包的解析按照 RFC1825而不是RFC1829(nt: AH, 认证头, ESP， 安全负载封装, 这两者会用在IP包的安全传输机制中). 如果此选项被设置, tcpdump 将不会打印出'禁止中继'域(nt: relay prevention field). 另外,由于ESP/AH规范中没有规定ESP/AH数据包必须拥有协议版本号域,所以tcpdump不能从收到的ESP/AH数据包中推导出协议版本号.-r file 从文件file 中读取包数据. 如果file 字段为 '-' 符号, 则tcpdump 会从标准输入中读取包数据.-S 打印TCP 数据包的顺序号时, 使用绝对的顺序号, 而不是相对的顺序号.(nt: 相对顺序号可理解为, 相对第一个TCP 包顺序号的差距,比如, 接受方收到第一个数据包的绝对顺序号为232323, 对于后来接收到的第2个,第3个数据包, tcpdump会打印其序列号为1, 2分别表示与第一个数据包的差距为1 和 2. 而如果此时-S 选项被设置, 对于后来接收到的第2个, 第3个数据包会打印出其绝对顺序号:232324, 232325).-s snaplen 设置tcpdump的数据包抓取长度为snaplen, 如果不设置默认将会是68字节(而支持网络接口分接头(nt: NIT, 上文已有描述,可搜索'网络接口分接头'关键字找到那里)的SunOS系列操作系统中默认的也是最小值是96).68字节对于IP, ICMP(nt: Internet Control Message Protocol,因特网控制报文协议), TCP 以及 UDP 协议的报文已足够, 但对于名称服务(nt: 可理解为dns, nis等服务), NFS服务相关的数据包会产生包截短. 如果产生包截短这种情况, tcpdump的相应打印输出行中会出现''[|proto]''的标志（proto 实际会显示为被截短的数据包的相关协议层次). 需要注意的是, 采用长的抓取长度(nt: snaplen比较大), 会增加包的处理时间, 并且会减少tcpdump 可缓存的数据包的数量， 从而会导致数据包的丢失. 所以, 在能抓取我们想要的包的前提下, 抓取长度越小越好.把snaplen 设置为0 意味着让tcpdump自动选择合适的长度来抓取数据包.-T type 强制tcpdump按type指定的协议所描述的包结构来分析收到的数据包. 目前已知的type 可取的协议为: aodv (Ad-hoc On-demand Distance Vector protocol, 按需距离向量路由协议, 在Ad hoc(点对点模式)网络中使用), cnfp (Cisco NetFlow protocol), rpc(Remote Procedure Call), rtp (Real-Time Applications protocol), rtcp (Real-Time Applications con-trol protocol), snmp (Simple Network Management Protocol), tftp (Trivial File Transfer Protocol, 碎文件协议), vat (Visual Audio Tool, 可用于在internet 上进行电 视电话会议的应用层协议), 以及wb (distributed White Board, 可用于网络会议的应用层协议).-t 在每行输出中不打印时间戳-tt 不对每行输出的时间进行格式处理(nt: 这种格式一眼可能看不出其含义, 如时间戳打印成1261798315)-ttt tcpdump 输出时, 每两行打印之间会延迟一个段时间(以毫秒为单位)-tttt 在每行打印的时间戳之前添加日期的打印-u 打印出未加密的NFS 句柄(nt: handle可理解为NFS 中使用的文件句柄, 这将包括文件夹和文件夹中的文件)-U 使得当tcpdump在使用-w 选项时, 其文件写入与包的保存同步.(nt: 即, 当每个数据包被保存时, 它将及时被写入文件中,而不是等文件的输出缓冲已满时才真正写入此文件) -U 标志在老版本的libcap库(nt: tcpdump 所依赖的报文捕获库)上不起作用, 因为其中缺乏pcap_cump_flush()函数.-v 当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.-vv 产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.-vvv 产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面, 其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).-w 把包数据直接写入文件而不进行分析和打印输出. 这些包数据可在随后通过-r 选项来重新读入并进行分析和打印.-W filecount 此选项与-C 选项配合使用, 这将限制可打开的文件数目, 并且当文件数据超过这里设置的限制时, 依次循环替代之前的文件, 这相当于一个拥有filecount 个文件的文件缓冲池. 同时, 该选项会使得每个文件名的开头会出现足够多并用来占位的0, 这可以方便这些文件被正确的排序.-x 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据(但不包括连接层的头部).总共打印的数据大小不会超过整个数据包的大小与snaplen 中的最小值. 必须要注意的是, 如果高层协议数据没有snaplen 这么长,并且数据链路层(比如, Ethernet层)有填充数据, 则这些填充数据也会被打印.(nt: so for link layers that pad, 未能衔接理解和翻译, 需补充 )-xx tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据, 其中包括数据链路层的头部.-X 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据(但不包括连接层的头部).这对于分析一些新协议的数据包很方便.-XX 当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据, 其中包括数据链路层的头部.这对于分析一些新协议的数据包很方便.-y datalinktype 设置tcpdump 只捕获数据链路层协议类型是datalinktype的数据包-Z user 使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID(nt: tcpdump 此处可理解为tcpdump 运行之后对应的进程) 此选项也可在编译的时候被设置为默认打开.(nt: 此时user 的取值未知, 需补充) tcpdump 条件表达式 该表达式用于决定哪些数据包将被打印. 如果不给定条件表达式, 网络上所有被捕获的包都会被打印,否则, 只有满足条件表达式的数据包被打印.(nt: all packets, 可理解为, 所有被指定接口捕获的数据包). 表达式由一个或多个’表达元’组成(nt: primitive, 表达元, 可理解为组成表达式的基本元素). 一个表达元通常由一个或多个修饰符(qualifiers)后跟一个名字或数字表示的id组成(nt: 即, ‘qualifiers id’).有三种不同类型的修饰符:type, dir以及 proto. 123456789101112131415type 修饰符指定id 所代表的对象类型, id可以是名字也可以是数字. 可选的对象类型有: host, net, port 以及portrange(nt: host 表明id表示主机, net 表明id是网络, port 表明id是端而portrange 表明id 是一个端口范围). 如, 'host foo', 'net 128.3', 'port 20', 'portrange 6000-6008'(nt: 分别表示主机 foo,网络 128.3, 端口 20, 端口范围 6000-6008). 如果不指定type 修饰符, id默认的修饰符为host.dir 修饰符描述id 所对应的传输方向, 即发往id 还是从id 接收（nt: 而id 到底指什么需要看其前面的type 修饰符）.可取的方向为: src, dst, src 或 dst, src并且dst.(nt:分别表示, id是传输源, id是传输目的, id是传输源或者传输目的, id是传输源并且是传输目的). 例如, 'src foo','dst net 128.3', 'src or dst port ftp-data'.(nt: 分别表示符合条件的数据包中, 源主机是foo, 目的网络是128.3, 源或目的端口为 ftp-data).如果不指定dir修饰符, id 默认的修饰符为src 或 dst.对于链路层的协议,比如SLIP(nt: Serial Line InternetProtocol, 串联线路网际网络协议), 以及linux下指定'any' 设备, 并指定'cooked'(nt | rt: cooked 含义未知, 需补充) 抓取类型, 或其他设备类型,可以用'inbound' 和 'outbount' 修饰符来指定想要的传输方向.proto 修饰符描述id 所属的协议. 可选的协议有: ether, fddi, tr, wlan, ip, ip6, arp, rarp, decnet, tcp以及 upd.(nt | rt: ether, fddi, tr, 具体含义未知, 需补充. 可理解为物理以太网传输协议, 光纤分布数据网传输协议,以及用于路由跟踪的协议. wlan, 无线局域网协议; ip,ip6 即通常的TCP/IP协议栈中所使用的ipv4以及ipv6网络层协议;arp, rarp 即地址解析协议,反向地址解析协议; decnet, Digital Equipment Corporation开发的, 最早用于PDP-11 机器互联的网络协议; tcp and udp, 即通常TCP/IP协议栈中的两个传输层协议). 例如, `ether src foo', `arp net 128.3', `tcp port 21', `udp portrange 7000-7009'分别表示 '从以太网地址foo 来的数据包','发往或来自128.3网络的arp协议数据包', '发送或接收端口为21的tcp协议数据包', '发送或接收端口范围为7000-7009的udp协议数据包'. 如果不指定proto 修饰符, 则默认为与相应type匹配的修饰符. 例如, 'src foo' 含义是 '(ip or arp or rarp) src foo' (nt: 即, 来自主机foo的ip/arp/rarp协议数据包, 默认type为host),`net bar' 含义是`(ip or arp or rarp) net bar'(nt: 即, 来自或发往bar网络的ip/arp/rarp协议数据包),`port 53' 含义是 `(tcp or udp) port 53'(nt: 即, 发送或接收端口为53的tcp/udp协议数据包).(nt: 由于tcpdump 直接通过数据链路层的 BSD 数据包过滤器或 DLPI(datalink provider interface, 数据链层提供者接口)来直接获得网络数据包, 其可抓取的数据包可涵盖上层的各种协议, 包括arp, rarp, icmp(因特网控制报文协议),ip, ip6, tcp, udp, sctp(流控制传输协议). 对于修饰符后跟id 的格式,可理解为, type id 是对包最基本的过滤条件: 即对包相关的主机, 网络, 端口的限制;dir 表示对包的传送方向的限制; proto表示对包相关的协议限制) 'fddi'(nt: Fiber Distributed Data Interface) 实际上与'ether' 含义一样: tcpdump 会把他们当作一种''指定网络接口上的数据链路层协议''. 如同ehter网(以太网), FDDI 的头部通常也会有源, 目的, 以及包类型, 从而可以像ether网数据包一样对这些域进行过滤. 此外, FDDI 头部还有其他的域, 但不能被放到表达式中用来过滤 同样, 'tr' 和 'wlan' 也和 'ether' 含义一致, 上一段对fddi 的描述同样适用于tr(Token Ring) 和wlan(802.11 wireless LAN)的头部. 对于802.11 协议数据包的头部, 目的域称为DA, 源域称为 SA;而其中的 BSSID, RA, TA 域(nt | rt: 具体含义需补充)不会被检测(nt: 不能被用于包过虑表达式中). 除以上所描述的表达元(‘primitive’)， 还有其他形式的表达元, 并且与上述表达元格式不同. 比如: gateway, broadcast, less, greater以及算术表达式(nt: 其中每一个都算一种新的表达元). 下面将会对这些表达元进行说明. 表达元之间还可以通过关键字and, or 以及 not 进行连接, 从而可组成比较复杂的条件表达式. 比如,`host foo and not port ftp and not port ftp-data’(nt: 其过滤条件可理解为, 数据包的主机为foo,并且端口不是ftp(端口21) 和ftp-data(端口20, 常用端口和名字的对应可在linux 系统中的/etc/service 文件中找到)). 为了表示方便, 同样的修饰符可以被省略, 如’tcp dst port ftp or ftp-data or domain’ 与以下的表达式含义相同’tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain’.(nt: 其过滤条件可理解为,包的协议为tcp, 目的端口为ftp 或 ftp-data 或 domain(端口53) ). 借助括号以及相应操作符,可把表达元组合在一起使用(由于括号是shell的特殊字符, 所以在shell脚本或终端中使用时必须对括号进行转义, 即’(‘ 与’)’需要分别表达成’(‘ 与 ‘)‘). 有效的操作符有: 1234否定操作 (`!&apos; 或 `not&apos;)与操作(`&amp;&amp;&apos; 或 `and&apos;)或操作(`||&apos; 或 `or&apos;) 否定操作符的优先级别最高. 与操作和或操作优先级别相同, 并且二者的结合顺序是从左到右. 要注意的是, 表达’与操作’时, 需要显式写出’and’操作符, 而不只是把前后表达元并列放置(nt: 二者中间的’and’ 操作符不可省略). 如果一个标识符前没有关键字, 则表达式的解析过程中最近用过的关键字(往往也是从左往右距离标识符最近的关键字)将被使用.比如, not host vs and ace是以下表达的精简: not host vs and host ace而不是not (host vs or ace).(nt: 前两者表示, 所需数据包不是来自或发往host vs, 而是来自或发往ace.而后者表示数据包只要不是来自或发往vs或ac都符合要求) 整个条件表达式可以被当作一个单独的字符串参数也可以被当作空格分割的多个参数传入tcpdump, 后者更方便些. 通常, 如果表达式中包含元字符(nt: 如正则表达式中的’*’, ‘.’以及shell中的’(‘等字符)， 最好还是使用单独字符串的方式传入. 这时,整个表达式需要被单引号括起来. 多参数的传入方式中, 所有参数最终还是被空格串联在一起, 作为一个字符串被解析. 附录：tcpdump 的表达元(nt: True 在以下的描述中含义为: 相应条件表达式中只含有以下所列的一个特定表达元, 此时表达式为真, 即条件得到满足) dst host host如果IPv4/v6 数据包的目的域是host, 则与此对应的条件表达式为真.host 可以是一个ip地址, 也可以是一个主机名.src host host如果IPv4/v6 数据包的源域是host, 则与此对应的条件表达式为真.host 可以是一个ip地址, 也可以是一个主机名.host host 如果IPv4/v6数据包的源或目的地址是 host, 则与此对应的条件表达式为真.以上的几个host 表达式之前可以添加以下关键字:ip, arp, rarp, 以及 ip6.比如:ip host host也可以表达为:ether proto \ip and host host(nt: 这种表达方式在下面有说明, 其中ip之前需要有\来转义,因为ip 对tcpdump 来说已经是一个关键字了.) 如果host 是一个拥有多个IP 的主机, 那么任何一个地址都会用于包的匹配(nt: 即发向host 的数据包的目的地址可以是这几个IP中的任何一个, 从host 接收的数据包的源地址也可以是这几个IP中的任何一个). ether dst ehost如果数据包(nt: 指tcpdump 可抓取的数据包, 包括ip 数据包, tcp数据包)的以太网目标地址是ehost,则与此对应的条件表达式为真. Ehost 可以是/etc/ethers 文件中的名字或一个数字地址(nt: 可通过 man ethers 看到对/etc/ethers 文件的描述, 样例中用的是数字地址) ether src ehost如果数据包的以太网源地址是ehost, 则与此对应的条件表达式为真. ether host ehost如果数据包的以太网源地址或目标地址是ehost, 则与此对应的条件表达式为真. gateway host如果数据包的网关地址是host, 则与此对应的条件表达式为真. 需要注意的是, 这里的网关地址是指以太网地址, 而不是IP 地址(nt | rt: I.e., 例如, 可理解为’注意’.the Ethernet source or destination address, 以太网源和目标地址, 可理解为, 指代上句中的’网关地址’ ).host 必须是名字而不是数字, 并且必须在机器的’主机名-ip地址’以及’主机名-以太地址’两大映射关系中 有其条目(前一映射关系可通过/etc/hosts文件, DNS 或 NIS得到, 而后一映射关系可通过/etc/ethers 文件得到. nt: /etc/ethers并不一定存在 , 可通过man ethers 看到其数据格式, 如何创建该文件, 未知,需补充).也就是说host 的含义是 ether host ehost 而不是 host host, 并且ehost必须是名字而不是数字.目前, 该选项在支持IPv6地址格式的配置环境中不起作用(nt: configuration, 配置环境, 可理解为,通信双方的网络配置). dst net net如果数据包的目标地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真.net 可以是从网络数据库文件/etc/networks 中的名字, 也可以是一个数字形式的网络编号. 一个数字IPv4 网络编号将以点分四元组(比如, 192.168.1.0), 或点分三元组(比如, 192.168.1 ), 或点分二元组(比如, 172.16), 或单一单元组(比如, 10)来表达; 对应于这四种情况的网络掩码分别是:四元组:255.255.255.255(这也意味着对net 的匹配如同对主机地址(host)的匹配:地址的四个部分都用到了),三元组:255.255.255.0, 二元组: 255.255.0.0, 一元组:255.0.0.0. 对于IPv6 的地址格式, 网络编号必须全部写出来(8个部分必须全部写出来); 相应网络掩码为:ff:ff:ff:ff:ff:ff:ff:ff, 所以IPv6 的网络匹配是真正的’host’方式的匹配(nt | rt | rc:地址的8个部分都会用到,是否不属于网络的字节填写0, 需接下来补充), 但同时需要一个网络掩码长度参数来具体指定前面多少字节为网络掩码(nt: 可通过下面的net net/len 来指定) src net net如果数据包的源地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真. net net如果数据包的源或目的地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真. net net mask netmask如果数据包的源或目的地址(IPv4或IPv6格式)的网络掩码与netmask 匹配, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt: 比如 src net net mask 255.255.255.0).该选项对于ipv6 网络地址无效. net net/len如果数据包的源或目的地址(IPv4或IPv6格式)的网络编号字段的比特数与len相同, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt | rt | tt: src net net/24, 表示需要匹配源地址的网络编号有24位的数据包). dst port port如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口为port, 则与此对应的条件表达式为真.port 可以是一个数字也可以是一个名字(相应名字可以在/etc/services 中找到该名字, 也可以通过man tcp 和man udp来得到相关描述信息 ). 如果使用名字, 则该名字对应的端口号和相应使用的协议都会被检查. 如果只是使用一个数字端口号,则只有相应端口号被检查(比如, dst port 513 将会使tcpdump抓取tcp协议的login 服务和udp协议的who 服务数据包, 而port domain 将会使tcpdump 抓取tcp协议的domain 服务数据包, 以及udp 协议的domain 数据包)(nt | rt: ambiguous name is used 不可理解, 需补充). src port port如果数据包的源端口为port, 则与此对应的条件表达式为真. port port如果数据包的源或目的端口为port, 则与此对应的条件表达式为真. dst portrange port1-port2如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口属于port1到port2这个端口范围(包括port1, port2), 则与此对应的条件表达式为真. tcpdump 对port1 和port2 解析与对port 的解析一致(nt:在dst port port 选项的描述中有说明). src portrange port1-port2如果数据包的源端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真. portrange port1-port2如果数据包的源端口或目的端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真. 以上关于port 的选项都可以在其前面添加关键字:tcp 或者udp, 比如:tcp src port port这将使tcpdump 只抓取源端口是port 的tcp数据包. less length如果数据包的长度比length 小或等于length, 则与此对应的条件表达式为真. 这与’len &lt;= length’ 的含义一致. greater length如果数据包的长度比length 大或等于length, 则与此对应的条件表达式为真. 这与’len &gt;= length’ 的含义一致. ip proto protocol如果数据包为ipv4数据包并且其协议类型为protocol, 则与此对应的条件表达式为真.Protocol 可以是一个数字也可以是名字, 比如:icmp6, igmp, igrp(nt: Interior Gateway Routing Protocol,内部网关路由协议), pim(Protocol Independent Multicast, 独立组播协议, 应用于组播路由器),ah, esp(nt: ah, 认证头, esp 安全负载封装, 这两者会用在IP包的安全传输机制中 ), vrrp(Virtual Router Redundancy Protocol, 虚拟路由器冗余协议), udp, or tcp. 由于tcp , udp 以及icmp是tcpdump 的关键字,所以在这些协议名字之前必须要用\来进行转义(如果在C-shell 中需要用\来进行转义). 注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来(nt: 实际上只会打印指定协议的一些头部信息, 比如可以用tcpdump -i eth0 ‘ip proto \tcp and host 192.168.3.144’, 则只打印主机192.168.3.144 发出或接收的数据包中tcp 协议头所包含的信息) ip6 proto protocol如果数据包为ipv6数据包并且其协议类型为protocol, 则与此对应的条件表达式为真.注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来 ip6 protochain protocol如果数据包为ipv6数据包并且其协议链中包含类型为protocol协议头, 则与此对应的条件表达式为真. 比如,ip6 protochain 6 将匹配其协议头链中拥有TCP 协议头的IPv6数据包.此数据包的IPv6头和TCP头之间可能还会包含验证头, 路由头, 或者逐跳寻径选项头.由此所触发的相应BPF(Berkeley Packets Filter, 可理解为, 在数据链路层提供数据包过滤的一种机制)代码比较繁琐,并且BPF优化代码也未能照顾到此部分, 从而此选项所触发的包匹配可能会比较慢. ip protochain protocol与ip6 protochain protocol 含义相同, 但这用在IPv4数据包. ether broadcast如果数据包是以太网广播数据包, 则与此对应的条件表达式为真. ether 关键字是可选的. ip broadcast如果数据包是IPv4广播数据包, 则与此对应的条件表达式为真. 这将使tcpdump 检查广播地址是否符合全0和全1的一些约定,并查找网络接口的网络掩码(网络接口为当时在其上抓包的网络接口). 如果抓包所在网络接口的网络掩码不合法, 或者此接口根本就没有设置相应网络地址和网络， 亦或是在linux下的’any’网络接口上抓包(此’any’接口可以收到系统中不止一个接口的数据包(nt: 实际上, 可理解为系统中所有可用的接口)),网络掩码的检查不能正常进行. ether multicast如果数据包是一个以太网多点广播数据包(nt: 多点广播, 可理解为把消息同时传递给一组目的地址, 而不是网络中所有地址,后者为可称为广播(broadcast)), 则与此对应的条件表达式为真. 关键字ether 可以省略. 此选项的含义与以下条件表达式含义一致:`ether[0] &amp; 1 != 0’(nt: 可理解为, 以太网数据包中第0个字节的最低位是1, 这意味这是一个多点广播数据包). ip multicast如果数据包是ipv4多点广播数据包, 则与此对应的条件表达式为真. ip6 multicast如果数据包是ipv6多点广播数据包, 则与此对应的条件表达式为真. ether proto protocol如果数据包属于以下以太协议类型, 则与此对应的条件表达式为真.协议(protocol)字段, 可以是数字或以下所列出了名字: ip, ip6, arp, rarp, atalk(AppleTalk网络协议),aarp(nt: AppleTalk Address Resolution Protocol, AppleTalk网络的地址解析协议),decnet(nt: 一个由DEC公司所提供的网络协议栈), sca(nt: 未知, 需补充),lat(Local Area Transport, 区域传输协议, 由DEC公司开发的以太网主机互联协议),mopdl, moprc, iso(nt: 未知, 需补充), stp(Spanning tree protocol, 生成树协议, 可用于防止网络中产生链接循环),ipx（nt: Internetwork Packet Exchange, Novell 网络中使用的网络层协议）, 或者netbeui(nt: NetBIOS Extended User Interface，可理解为, 网络基本输入输出系统接口扩展). protocol字段可以是一个数字或以下协议名之一:ip, ip6, arp, rarp, atalk, aarp, decnet, sca, lat,mopdl, moprc, iso, stp, ipx, 或者netbeui.必须要注意的是标识符也是关键字, 从而必须通过’\’来进行转义. (SNAP：子网接入协议 （SubNetwork Access Protocol）) 在光纤分布式数据网络接口(其表达元形式可以是’fddi protocol arp’), 令牌环网(其表达元形式可以是’tr protocol arp’),以及IEEE 802.11 无线局域网(其表达元形式可以是’wlan protocol arp’)中, protocol标识符来自802.2 逻辑链路控制层头,在FDDI, Token Ring 或 802.1头中会包含此逻辑链路控制层头. 当以这些网络上的相应的协议标识为过滤条件时, tcpdump只是检查LLC头部中以0x000000为组成单元标识符(OUI, 0x000000标识一个内部以太网)的一段’SNAP格式结构’中的protocol ID 域, 而不会管包中是否有一段OUI为0x000000的’SNAP格式结构’(nt: SNAP, SubNetwork Access Protocol,子网接入协议 ). 以下例外: iso tcpdump 会检查LLC头部中的DSAP域(Destination service Access Point, 目标服务接入点)和SSAP域(源服务接入点).(nt: iso 协议未知, 需补充) stp 以及 netbeuitcpdump 将会检查LLC 头部中的目标服务接入点(Destination service Access Point); atalktcpdump 将会检查LLC 头部中以0x080007 为OUI标识的’SNAP格式结构’, 并会检查AppleTalk etype域.(nt: AppleTalk etype 是否位于SNAP格式结构中, 未知, 需补充). 此外, 在以太网中, 对于ether proto protocol 选项, tcpdump 会为 protocol 所指定的协议检查以太网类型域(the Ethernet type field), 但以下这些协议除外: iso, stp, and netbeuitcpdump 将会检查802.3 物理帧以及LLC 头(这两种检查与FDDI, TR, 802.11网络中的相应检查一致);(nt: 802.3, 理解为IEEE 802.3, 其为一系列IEEE 标准的集合. 此集合定义了有线以太网络中的物理层以及数据链路层的媒体接入控制子层. stp 在上文已有描述) atalktcpdump 将会检查以太网物理帧中的AppleTalk etype 域 , 同时也会检查数据包中LLC头部中的’SNAP格式结构’(这两种检查与FDDI, TR, 802.11网络中的相应检查一致) aarp tcpdump 将会检查AppleTalk ARP etype 域, 此域或存在于以太网物理帧中, 或存在于LLC(由802.2 所定义)的‘SNAP格式结构’中, 当为后者时, 该’SNAP格式结构’的OUI标识为0x000000;(nt: 802.2, 可理解为, IEEE802.2, 其中定义了逻辑链路控制层(LLC), 该层对应于OSI 网络模型中数据链路层的上层部分.LLC 层为使用数据链路层的用户提供了一个统一的接口(通常用户是网络层). LLC层以下是媒体接入控制层(nt: MAC层,对应于数据链路层的下层部分).该层的实现以及工作方式会根据不同物理传输媒介的不同而有所区别(比如, 以太网, 令牌环网,光纤分布数据接口(nt: 实际可理解为一种光纤网络), 无线局域网(802.11), 等等.) ipx tcpdump 将会检查物理以太帧中的IPX etype域, LLC头中的IPX DSAP域，无LLC头并对IPX进行了封装的802.3帧,以及LLC 头部’SNAP格式结构’中的IPX etype 域(nt | rt: SNAP frame, 可理解为, LLC 头中的’SNAP格式结构’.该含义属初步理解阶段, 需补充). decnet src host如果数据包中DECNET源地址为host, 则与此对应的条件表达式为真.(nt:decnet, 由Digital Equipment Corporation 开发, 最早用于PDP-11 机器互联的网络协议) decnet dst host如果数据包中DECNET目的地址为host, 则与此对应的条件表达式为真.(nt: decnet 在上文已有说明) decnet host host如果数据包中DECNET目的地址或DECNET源地址为host, 则与此对应的条件表达式为真.(nt: decnet 在上文已有说明) ifname interface如果数据包已被标记为从指定的网络接口中接收的, 则与此对应的条件表达式为真.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) on interface与 ifname interface 含义一致. rnr num如果数据包已被标记为匹配PF的规则, 则与此对应的条件表达式为真.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) rulenum num与 rulenum num 含义一致. reason code如果数据包已被标记为包含PF的匹配结果代码, 则与此对应的条件表达式为真.有效的结果代码有: match, bad-offset,fragment, short, normalize, 以及memory.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) rset name如果数据包已被标记为匹配指定的规则集, 则与此对应的条件表达式为真.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) ruleset name与 rset name 含义一致. srnr num如果数据包已被标记为匹配指定的规则集中的特定规则(nt: specified PF rule number, 特定规则编号, 即特定规则),则与此对应的条件表达式为真.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) subrulenum num与 srnr 含义一致. action act如果包被记录时PF会执行act指定的动作, 则与此对应的条件表达式为真. 有效的动作有: pass, block.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序)) ip, ip6, arp, rarp, atalk, aarp, decnet, iso, stp, ipx, netbeui与以下表达元含义一致:ether proto pp是以上协议中的一个. lat, moprc, mopdl与以下表达元含义一致:ether proto pp是以上协议中的一个. 必须要注意的是tcpdump目前还不能分析这些协议. vlan [vlan_id]如果数据包为IEEE802.1Q VLAN 数据包, 则与此对应的条件表达式为真.(nt: IEEE802.1Q VLAN, 即IEEE802.1Q 虚拟网络协议, 此协议用于不同网络的之间的互联).如果[vlan_id] 被指定, 则只有数据包含有指定的虚拟网络id(vlan_id), 则与此对应的条件表达式为真.要注意的是, 对于VLAN数据包, 在表达式中遇到的第一个vlan关键字会改变表达式中接下来关键字所对应数据包中数据的开始位置(即解码偏移). 在VLAN网络体系中过滤数据包时, vlan [vlan_id]表达式可以被多次使用. 关键字vlan每出现一次都会增加4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移). 例如:vlan 100 &amp;&amp; vlan 200表示: 过滤封装在VLAN100中的VLAN200网络上的数据包再例如:vlan &amp;&amp; vlan 300 &amp;&amp; ip表示: 过滤封装在VLAN300 网络中的IPv4数据包, 而VLAN300网络又被更外层的VLAN封装 mpls [label_num]如果数据包为MPLS数据包, 则与此对应的条件表达式为真.(nt: MPLS, Multi-Protocol Label Switch, 多协议标签交换, 一种在开放的通信网上利用标签引导数据传输的技术). 如果[label_num] 被指定, 则只有数据包含有指定的标签id(label_num), 则与此对应的条件表达式为真.要注意的是, 对于内含MPLS信息的IP数据包(即MPLS数据包), 在表达式中遇到的第一个MPLS关键字会改变表达式中接下来关键字所对应数据包中数据的开始位置(即解码偏移). 在MPLS网络体系中过滤数据包时, mpls [label_num]表达式可以被多次使用. 关键字mpls每出现一次都会增加4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移). 例如:mpls 100000 &amp;&amp; mpls 1024表示: 过滤外层标签为100000 而层标签为1024的数据包 再如:mpls &amp;&amp; mpls 1024 &amp;&amp; host 192.9.200.1表示: 过滤发往或来自192.9.200.1的数据包, 该数据包的内层标签为1024, 且拥有一个外层标签. pppoed如果数据包为PPP-over-Ethernet的服务器探寻数据包(nt: Discovery packet,其ethernet type 为0x8863),则与此对应的条件表达式为真.(nt: PPP-over-Ethernet, 点对点以太网承载协议, 其点对点的连接建立分为Discovery阶段(地址发现) 和PPPoE 会话建立阶段 , discovery 数据包就是第一阶段发出来的包. ethernet type是以太帧里的一个字段，用来指明应用于帧数据字段的协议) pppoes如果数据包为PPP-over-Ethernet会话数据包(nt: ethernet type 为0x8864, PPP-over-Ethernet在上文已有说明, 可搜索关键字’PPP-over-Ethernet’找到其描述), 则与此对应的条件表达式为真. 要注意的是, 对于PPP-over-Ethernet会话数据包, 在表达式中遇到的第一个pppoes关键字会改变表达式中接下来关键字所对应数据包中数据的开始位置(即解码偏移). 例如:pppoes &amp;&amp; ip表示: 过滤嵌入在PPPoE数据包中的ipv4数据包 tcp, udp, icmp与以下表达元含义一致:ip proto p or ip6 proto p其中p 是以上协议之一(含义分别为: 如果数据包为ipv4或ipv6数据包并且其协议类型为 tcp,udp, 或icmp则与此对应的条件表达式为真) iso proto protocol如果数据包的协议类型为iso-osi协议栈中protocol协议, 则与此对应的条件表达式为真.(nt: [初解]iso-osi 网络模型中每层的具体协议与tcp/ip相应层采用的协议不同. iso-osi各层中的具体协议另需补充 ) protocol 可以是一个数字编号, 或以下名字中之一:clnp, esis, or isis.(nt: clnp, Connectionless Network Protocol, 这是OSI网络模型中网络层协议 , esis, isis 未知, 需补充) clnp, esis, isis是以下表达的缩写iso proto p其中p 是以上协议之一 l1, l2, iih, lsp, snp, csnp, psnp为IS-IS PDU 类型 的缩写.(nt: IS-IS PDU, Intermediate system to intermediate system Protocol Data Unit, 中间系统到中间系统的协议数据单元. OSI(Open Systems Interconnection)网络由终端系统, 中间系统构成.终端系统指路由器, 而终端系统指用户设备. 路由器形成的本地组称之为’区域’（Area）和多个区域组成一个’域’（Domain）.IS-IS 提供域内或区域内的路由. l1, l2, iih, lsp, snp, csnp, psnp 表示PDU的类型, 具体含义另需补充) vpi n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,如果数据包为ATM数据包, 并且其虚拟路径标识为n, 则与此对应的条件表达式为真.(nt: ATM, Asychronous Transfer Mode, 实际上可理解为由ITU-T(国际电信联盟电信标准化部门)提出的一个与TCP/IP中IP层功能等同的一系列协议, 具体协议层次另需补充) vci n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,如果数据包为ATM数据包, 并且其虚拟通道标识为n, 则与此对应的条件表达式为真.(nt: ATM, 在上文已有描述) lane如果数据包为ATM LANE 数据包, 则与此对应的条件表达式为真. 要注意的是, 如果是模拟以太网的LANE数据包或者LANE逻辑单元控制包, 表达式中第一个lane关键字会改变表达式中随后条件的测试. 如果没有指定lane关键字, 条件测试将按照数据包中内含LLC(逻辑链路层)的ATM包来进行. llc如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,如果数据包为ATM数据包, 并且内含LLC则与此对应的条件表达式为真 oamf4s如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是Segment OAM F4 信元(VPI=0 并且 VCI=3), 则与此对应的条件表达式为真. (nt: OAM, Operation Administration and Maintenance, 操作管理和维护,可理解为:ATM网络中用于网络管理所产生的ATM信元的分类方式. ATM网络中传输单位为信元, 要传输的数据终究会被分割成固定长度(53字节)的信元,(初理解: 一条物理线路可被复用, 形成虚拟路径(virtual path). 而一条虚拟路径再次被复用, 形成虚拟信道(virtual channel)).通信双方的编址方式为:虚拟路径编号(VPI)/虚拟信道编号(VCI)). OAM F4 flow 信元又可分为segment 类和end-to-end 类, 其区别未知, 需补充.) oamf4e如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是 end-to-end OAM F4 信元(VPI=0 并且 VCI=4), 则与此对应的条件表达式为真.(nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索’oamf4s’来定位) oamf4如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真.(nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索’oamf4s’来定位) oam如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真.(nt: 此选项与oamf4重复, 需确认) metac如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自’元信令线路’(nt: VPI=0 并且 VCI=1, ‘元信令线路’, meta signaling circuit, 具体含义未知, 需补充),则与此对应的条件表达式为真. bcc如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自’广播信令线路’(nt: VPI=0 并且 VCI=2, ‘广播信令线路’, broadcast signaling circuit, 具体含义未知, 需补充),则与此对应的条件表达式为真. sc如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自’信令线路’(nt: VPI=0 并且 VCI=5, ‘信令线路’, signaling circuit, 具体含义未知, 需补充),则与此对应的条件表达式为真. ilmic如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自’ILMI线路’(nt: VPI=0 并且 VCI=16, ‘ILMI’, Interim Local Management Interface , 可理解为基于SNMP(简易网络管理协议)的用于网络管理的接口)则与此对应的条件表达式为真. connectmsg 如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自’信令线路’并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect,Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真.(nt: Q.2931 为ITU(国际电信联盟)制定的信令协议. 其中规定了在宽带综合业务数字网络的用户接口层建立, 维护, 取消网络连接的相关步骤.) metaconnect如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自’元信令线路’并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect,Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真. expr relop expr如果relop 两侧的操作数(expr)满足relop 指定的关系, 则与此对应的条件表达式为真.relop 可以是以下关系操作符之一: &gt;, &lt;, &lt;=, =, !=.expr 是一个算术表达式. 此表达式中可使用整型常量(表示方式与标准C中一致), 二进制操作符(+, -, *, /, &amp;, |,&lt;&lt;, &gt;&gt;), 长度操作符, 以及对特定数据包中数据的引用操作符. 要注意的是, 所有的比较操作都默认操作数是无符号的,例如, 0x80000000 和 0xffffffff 都是大于0的(nt: 对于有符号的比较, 按照补码规则, 0xffffffff会小于0). 如果要引用数据包中的数据, 可采用以下表达方式:proto [expr : size] proto 的取值可以是以下取值之一:ether, fddi, tr, wlan, ppp, slip, link, ip, arp, rarp,tcp, udp, icmp, ip6 或者 radio. 这指明了该引用操作所对应的协议层.(ether, fddi, wlan,tr, ppp, slip and link 对应于数据链路层, radio 对应于802.11(wlan,无线局域网)某些数据包中的附带的“radio”头(nt: 其中描述了波特率, 数据加密等信息)).要注意的是, tcp, udp 等上层协议目前只能应用于网络层采用为IPv4或IPv6协议的网络(此限制会在tcpdump未来版本中进行修改). 对于指定协议的所需数据, 其在包数据中的偏移字节由expr 来指定. 以上表达中size 是可选的, 用来指明我们关注那部分数据段的长度(nt:通常这段数据是数据包的一个域)， 其长度可以是1, 2, 或4个字节. 如果不给定size, 默认是1个字节. 长度操作符的关键字为len,这代码整个数据包的长度. 例如, ‘ether[0] &amp; 1 != 0’ 将会使tcpdump 抓取所有多点广播数据包.(nt: ether[0]字节的最低位为1表示数据包目的地址是多点广播地址). ‘ip[0] &amp; 0xf != 5’ 对应抓取所有带有选项的IPv4数据包. ‘ip[6:2] &amp; 0x1fff = 0’对应抓取没被破碎的IPv4数据包或者其片段编号为0的已破碎的IPv4数据包. 这种数据检查方式也适用于tcp和udp数据的引用,即, tcp[0]对应于TCP 头中第一个字节, 而不是对应任何一个中间的字节. 一些偏移以及域的取值除了可以用数字也可用名字来表达. 以下为可用的一些域(协议头中的域)的名字: icmptype (指ICMP 协议头中type域), icmpcode (指ICMP 协议头code 域), 以及tcpflags(指TCP协议头的flags 域) 以下为ICMP 协议头中type 域的可用取值:icmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect, icmp-echo, icmp-routeradvert,icmp-routersolicit, icmp-timx-ceed, icmp-paramprob, icmp-tstamp, icmp-tstampreply,icmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply. 以下为TCP 协议头中flags 域的可用取值:tcp-fin, tcp-syn, tcp-rst, tcp-push, tcp-ack, tcp-urg. 参考资料 Linux tcpdump命令详解]]></content>
      <categories>
        <category>Linux</category>
        <category>tcpdump</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux tcpdump 命令详解一]]></title>
    <url>%2F2014%2F07%2F03%2F51016%2F</url>
    <content type="text"><![CDATA[简介用简单的话来定义 tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump 可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供 and、or、not 等逻辑语句来帮助你去掉无用的信息。 实用命令实例 默认启动 12# 普通情况下，直接启动 tcpdump 将监视第一个网络接口上所有流过的数据包。tcpdump 监视指定网络接口的数据包 12# 如果不指定网卡，默认 tcpdump 只会监视第一个网络接口，一般是 eth0。tcpdump -i eth1 监视指定主机的数据包 1234567891011121314151617181920212223# 打印所有进入或离开 sundown 的数据包.tcpdump host sundown# 也可以指定ip,例如截获所有 210.27.48.1 的主机收到的和发出的所有的数据包tcpdump host 210.27.48.1# 打印 helios 与 hot 或者与 ace 之间通信的数据包tcpdump host helios and \( hot or ace \)# 截获主机 210.27.48.1 和主机 210.27.48.2 或 210.27.48.3 的通信tcpdump host 210.27.48.1 and \(210.27.48.2 or 210.27.48.3 \)# 打印 ace 与任何其他主机之间通信的 IP 数据包, 但不包括与 helios 之间的数据包.tcpdump ip host ace and not helios# 如果想要获取主机 210.27.48.1 除了和主机 210.27.48.2 之外所有主机通信的 ip 包，使用命令：tcpdump ip host 210.27.48.1 and ! 210.27.48.2# 截获主机 hostname 发送的所有数据tcpdump -i eth0 src host hostname# 监视所有送到主机 hostname 的数据包tcpdump -i eth0 dst host hostname 监视指定主机和端口的数据包 12345# 如果想要获取主机 210.27.48.1 接收或发出的 telnet 包，使用如下命令tcpdump tcp port 23 host 210.27.48.1# 对本机的 udp 123 端口进行监视 123 为 ntp 的服务端口tcpdump udp port 123 监视指定网络的数据包 123456789# 打印本地主机与 Berkeley 网络上的主机之间的所有通信数据包 (nt: ucb-ether, 此处可理解为‘Berkeley网络’的网络地址，此表达式最原始的含义可表达为: 打印网络地址为 ucb-ether 的所有数据包)tcpdump net ucb-ether# 打印所有通过网关 snup 的 ftp 数据包(注意, 表达式被单引号括起来了, 这可以防止 shell 对其中的括号进行错误解析)tcpdump 'gateway snup and (port ftp or ftp-data)'# 打印所有源地址或目标地址是本地主机的 IP 数据包(如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字)tcpdump ip and not net localnet 监视指定协议的数据包 123456789101112131415161718# 打印 TCP 会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字))tcpdump 'tcp[tcpflags] &amp; (tcp-syn|tcp-fin) != 0 and not src and dst net localnet'# 打印所有源或目的端口是 80，网络层协议为 IPv4，并且含有数据，而不是 SYN，FIN 以及 ACK-only 等不含数据的数据包.(ipv6 的版本的表达式可做练习)# (nt: 可理解为, ip[2:2]表示整个 ip 数据包的长度, (ip[0]&amp;0xf)&lt;&lt;2)表示 ip 数据包包头的长度(ip[0]&amp;0xf代表包中的 IHL 域, 而此域的单位为 32bit, 要换算成字节数需要乘以 4, 即左移 2. (tcp[12]&amp;0xf0)&gt;&gt;4 表示 tcp 头的长度, 此域的单位也是 32bit, 换算成比特数为 ((tcp[12]&amp;0xf0) &gt;&gt; 4) &lt;&lt; ２，即 ((tcp[12]&amp;0xf0)&gt;&gt;2). ((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0 表示: 整个 ip 数据包的长度减去 ip 头的长度，再减去 tcp 头的长度不为 0, 这就意味着, ip 数据包中确实是有数据.对于 ipv6 版本只需考虑 ipv6 头中的'Payload Length' 与 'tcp头的长度'的差值, 并且其中表达方式'ip[]'需换成'ip6[]'.)tcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)'# 打印长度超过 576 字节, 并且网关地址是 snup 的 IP 数据包tcpdump 'gateway snup and ip[2:2] &gt; 576'# 打印所有 IP 层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报tcpdump 'ether[0] &amp; 1 = 0 and ip[16] &gt;= 224'# 打印除'echo request'或者'echo reply'类型以外的 ICMP 数据包（比如,需要打印所有非 ping 程序产生的数据包时可用到此表达式。（nt: 'echo reuqest' 与 'echo reply' 这两种类型的 ICMP 数据包通常由 ping 程序产生））tcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply' tcpdump 与wireshark Wireshark（以前是 ethereal）是 Windows 下非常简单易用的抓包工具。但在 Linux 下很难找到一个好用的图形化抓包工具。还好有 Tcpdump。我们可以用 Tcpdump + Wireshark 的完美组合实现：在 Linux 里抓包，然后在 Windows 里分析包。 12345678910tcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap(1)tcp: ip icmp arp rarp 和 tcp、udp、icmp 这些选项等都要放到第一个参数的位置，用来过滤数据报的类型(2)-i eth1 : 只抓经过接口 eth1 的包(3)-t : 不显示时间戳(4)-s 0 : 抓取数据包时默认抓取长度为 68 字节。加上 -S 0 后可以抓到完整的数据包(5)-c 100 : 只抓取 100 个数据包(6)dst port ! 22 : 不抓取目标端口是 22 的数据包(7)src net 192.168.1.0/24 : 数据包的源网络地址为 192.168.1.0/24(8)-w ./target.cap : 保存成 cap 文件，方便用 ethereal（即 wireshark）分析 使用 tcpdump 抓取 HTTP 包 1234# 0x4745 为"GET"前两个字母"GE",0x4854 为"HTTP"前两个字母"HT"。tcpdump -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854# tcpdump 对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带 -w 参数的 tcpdump 截获数据并保存到文件中，然后再使用其他程序(如 Wireshark)进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。 输出信息含义首先我们注意一下，基本上 tcpdump 总的的输出格式为：系统时间 来源主机.端口 &gt; 目标主机.端口 数据包参数 tcpdump 的输出格式与协议有关.以下简要描述了大部分常用的格式及相关例子. 链路层头 对于FDDI网络, ‘-e’ 使tcpdump打印出指定数据包的’frame control’ 域, 源和目的地址, 以及包的长度.(frame control域控制对包中其他域的解析). 一般的包(比如那些IP datagrams)都是带有’async’(异步标志)的数据包，并且有取值0到7的优先级;比如 ‘async4’就代表此包为异步数据包，并且优先级别为4. 通常认为,这些包们会内含一个 LLC包(逻辑链路控制包); 这时,如果此包不是一个ISO datagram或所谓的SNAP包，其LLC头部将会被打印(nt:应该是指此包内含的 LLC包的包头). 对于Token Ring网络(令牌环网络), ‘-e’ 使tcpdump打印出指定数据包的’frame control’和’access control’域, 以及源和目的地址,外加包的长度. 与FDDI网络类似, 此数据包通常内含LLC数据包. 不管 是否有’-e’选项.对于此网络上的’source-routed’类型数据包(nt:意译为:源地址被追踪的数据包,具体含义未知,需补充), 其包的源路由信息总会被打印. 对于802.11网络(WLAN,即wireless local area network), ‘-e’ 使tcpdump打印出指定数据包的’frame control域,包头中包含的所有地址, 以及包的长度.与FDDI网络类似, 此数据包通常内含LLC数据包. (注意: 以下的描述会假设你熟悉SLIP压缩算法 (nt:SLIP为Serial Line Internet Protocol.), 这个算法可以在RFC-1144中找到相关的蛛丝马迹.) 对于SLIP网络(nt:SLIP links, 可理解为一个网络, 即通过串行线路建立的连接, 而一个简单的连接也可看成一个网络),数据包的’direction indicator’(‘方向指示标志’)(“I”表示入, “O”表示出), 类型以及压缩信息将会被打印. 包类型会被首先打印. 类型分为ip, utcp以及ctcp(nt:未知, 需补充). 对于ip包,连接信息将不被打印(nt:SLIP连接上,ip包的连接信息可能无用或没有定义.reconfirm).对于TCP数据包, 连接标识紧接着类型表示被打印. 如果此包被压缩, 其被编码过的头部将被打印.此时对于特殊的压缩包,会如下显示:S+n 或者 SA+n, 其中n代表包的(顺序号或(顺序号和应答号))增加或减少的数目(nt | rt:S,SA拗口, 需再译).对于非特殊的压缩包,0个或更多的’改变’将会被打印.’改变’被打印时格式如下:‘标志’+/-/=n 包数据的长度 压缩的头部长度.其中’标志’可以取以下值:U(代表紧急指针), W(指缓冲窗口), A(应答), S(序列号), I(包ID),而增量表达’=n’表示被赋予新的值, +/-表示增加或减少. 比如, 以下显示了对一个外发压缩TCP数据包的打印, 这个数据包隐含一个连接标识(connection identifier); 应答号增加了6,顺序号增加了49, 包ID号增加了6; 包数据长度为3字节(octect), 压缩头部为6字节.(nt:如此看来这应该不是一个特殊的压缩数据包). ARP/RARP 数据包 tcpdump对Arp/rarp包的输出信息中会包含请求类型及该请求对应的参数. 显示格式简洁明了. 以下是从主机rtsg到主机csam的’rlogin’(远程登录)过程开始阶段的数据包样例:arp who-has csam tell rtsgarp reply csam is-at CSAM第一行表示:rtsg发送了一个arp数据包(nt:向全网段发送,arp数据包）以询问csam的以太网地址Csam（nt:可从下文看出来, 是Csam）以她自己的以太网地址做了回应(在这个例子中, 以太网地址以大写的名字标识, 而internet地址(即ip地址)以全部的小写名字标识). 如果使用tcpdump -n, 可以清晰看到以太网以及ip地址而不是名字标识:arp who-has 128.3.254.6 tell 128.3.254.68arp reply 128.3.254.6 is-at 02:07:01:00:01:c4 如果我们使用tcpdump -e, 则可以清晰的看到第一个数据包是全网广播的, 而第二个数据包是点对点的:RTSG Broadcast 0806 64: arp who-has csam tell rtsgCSAM RTSG 0806 64: arp reply csam is-at CSAM第一个数据包表明:以arp包的源以太地址是RTSG, 目标地址是全以太网段, type域的值为16进制0806(表示ETHER_ARP(nt:arp包的类型标识)),包的总长度为64字节. TCP 数据包 (注意:以下将会假定你对 RFC-793所描述的TCP熟悉. 如果不熟, 以下描述以及tcpdump程序可能对你帮助不大.(nt:警告可忽略,只需继续看, 不熟悉的地方可回头再看.). 通常tcpdump对tcp数据包的显示格式如下:src &gt; dst: flags data-seqno ack window urgent options src 和 dst 是源和目的IP地址以及相应的端口. flags 标志由S(SYN), F(FIN), P(PUSH, R(RST),W(ECN CWT(nt | rep:未知, 需补充))或者 E(ECN-Echo(nt | rep:未知, 需补充))组成,单独一个’.’表示没有flags标识. 数据段顺序号(Data-seqno)描述了此包中数据所对应序列号空间中的一个位置(nt:整个数据被分段,每段有一个顺序号, 所有的顺序号构成一个序列号空间)(可参考以下例子). Ack 描述的是同一个连接,同一个方向,下一个本端应该接收的(对方应该发送的)数据片段的顺序号. Window是本端可用的数据接收缓冲区的大小(也是对方发送数据时需根据这个大小来组织数据).Urg(urgent) 表示数据包中有紧急的数据. options 描述了tcp的一些选项, 这些选项都用尖括号来表示(如 ). src, dst 和 flags 这三个域总是会被显示. 其他域的显示与否依赖于tcp协议头里的信息. 这是一个从trsg到csam的一个rlogin应用登录的开始阶段.rtsg.1023 &gt; csam.login: S 768512:768512(0) win 4096 csam.login &gt; rtsg.1023: S 947648:947648(0) ack 768513 win 4096 rtsg.1023 &gt; csam.login: . ack 1 win 4096rtsg.1023 &gt; csam.login: P 1:2(1) ack 1 win 4096csam.login &gt; rtsg.1023: . ack 2 win 4096rtsg.1023 &gt; csam.login: P 2:21(19) ack 1 win 4096csam.login &gt; rtsg.1023: P 1:2(1) ack 21 win 4077csam.login &gt; rtsg.1023: P 2:3(1) ack 21 win 4077 urg 1csam.login &gt; rtsg.1023: P 3:4(1) ack 21 win 4077 urg 1第一行表示有一个数据包从rtsg主机的tcp端口1023发送到了csam主机的tcp端口login上(nt:udp协议的端口和tcp协议的端口是分别的两个空间, 虽然取值范围一致). S表示设置了SYN标志. 包的顺序号是768512, 并且没有包含数据.(表示格式为:’first:last(nbytes)’, 其含义是’此包中数据的顺序号从first开始直到last结束，不包括last. 并且总共包含nbytes的用户数据’.) 没有捎带应答(nt:从下文来看，第二行才是有捎带应答的数据包), 可用的接受窗口的大小为4096bytes, 并且请求端(rtsg)的最大可接受的数据段大小是1024字节(nt:这个信息作为请求发向应答端csam, 以便双方进一步的协商). Csam 向rtsg 回复了基本相同的SYN数据包, 其区别只是多了一个’ piggy-backed ack’(nt:捎带回的ack应答, 针对rtsg的SYN数据包). rtsg 同样针对csam的SYN数据包回复了一ACK数据包作为应答. ‘.’的含义就是此包中没有标志被设置. 由于此应答包中不含有数据, 所以包中也没有数据段序列号. 提醒! 此ACK数据包的顺序号只是一个小整数1. 有如下解释:tcpdump对于一个tcp连接上的会话, 只打印会话两端的初始数据包的序列号,其后相应数据包只打印出与初始包序列号的差异.即初始序列号之后的序列号, 可被看作此会话上当前所传数据片段在整个要传输的数据中的’相对字节’位置(nt:双方的第一个位置都是1, 即’相对字节’的开始编号). ‘-Ｓ’将覆盖这个功能, 使数据包的原始顺序号被打印出来. 第六行的含义为:rtsg 向 csam发送了19字节的数据(字节的编号为2到20，传送方向为rtsg到csam). 包中设置了PUSH标志. 在第7行,csam 喊到， 她已经从rtsg中收到了21以下的字节, 但不包括21编号的字节. 这些字节存放在csam的socket的接收缓冲中, 相应地,csam的接收缓冲窗口大小会减少19字节(nt:可以从第5行和第7行win属性值的变化看出来). csam在第7行这个包中也向rtsg发送了一个字节. 在第8行和第9行, csam 继续向rtsg 分别发送了两个只包含一个字节的数据包, 并且这个数据包带PUSH标志. 如果所抓到的tcp包(nt:即这里的snapshot)太小了，以至tcpdump无法完整得到其头部数据, 这时, tcpdump会尽量解析这个不完整的头,并把剩下不能解析的部分显示为’[|tcp]’. 如果头部含有虚假的属性信息(比如其长度属性其实比头部实际长度长或短), tcpdump会为该头部显示’[bad opt]’. 如果头部的长度告诉我们某些选项(nt | rt:从下文来看， 指tcp包的头部中针对ip包的一些选项, 回头再翻)会在此包中,而真正的IP(数据包的长度又不够容纳这些选项, tcpdump会显示’[bad hdr length]’. 抓取带有特殊标志的的TCP包(如SYN-ACK标志, URG-ACK标志等). 在TCP的头部中, 有8比特(bit)用作控制位区域, 其取值为:CWR | ECE | URG | ACK | PSH | RST | SYN | FIN(nt | rt:从表达方式上可推断:这8个位是用或的方式来组合的, 可回头再翻) 现假设我们想要监控建立一个TCP连接整个过程中所产生的数据包. 可回忆如下:TCP使用3次握手协议来建立一个新的连接; 其与此三次握手连接顺序对应，并带有相应TCP控制标志的数据包如下:1) 连接发起方(nt:Caller)发送SYN标志的数据包2) 接收方(nt:Recipient)用带有SYN和ACK标志的数据包进行回应3) 发起方收到接收方回应后再发送带有ACK标志的数据包进行回应 1234567891011120 15 31-----------------------------------------------------------------| source port | destination port |-----------------------------------------------------------------| sequence number |-----------------------------------------------------------------| acknowledgment number |-----------------------------------------------------------------| HL | rsvd |C|E|U|A|P|R|S|F| window size |-----------------------------------------------------------------| TCP checksum | urgent pointer |----------------------------------------------------------------- 一个TCP头部,在不包含选项数据的情况下通常占用20个字节(nt | rt:options 理解为选项数据，需回译). 第一行包含0到3编号的字节,第二行包含编号4-7的字节. 如果编号从0开始算, TCP控制标志位于13字节(nt:第四行左半部分). 123450 7| 15| 23| 31----------------|---------------|---------------|----------------| HL | rsvd |C|E|U|A|P|R|S|F| window size |----------------|---------------|---------------|----------------| | 13th octet | | | 让我们仔细看看编号13的字节:12345| ||---------------||C|E|U|A|P|R|S|F||---------------||7 5 3 0| 这里有我们感兴趣的控制标志位. 从右往左这些位被依次编号为0到7, 从而 PSH位在3号, 而URG位在5号. 提醒一下自己, 我们只是要得到包含SYN标志的数据包. 让我们看看在一个包的包头中, 如果SYN位被设置, 到底在13号字节发生了什么:12345|C|E|U|A|P|R|S|F||---------------||0 0 0 0 0 0 1 0||---------------||7 6 5 4 3 2 1 0| 在控制段的数据中, 只有比特1(bit number 1)被置位. 假设编号为13的字节是一个8位的无符号字符型,并且按照网络字节号排序(nt:对于一个字节来说，网络字节序等同于主机字节序), 其二进制值如下所示:00000010 并且其10进制值为: 02^7 + 02^6 + 02^5 + 02^4 + 02^3 + 02^2 + 12^1 + 02^0 = 2(nt: 1 * 2^6 表示1乘以2的6次方, 也许这样更清楚些, 即把原来表达中的指数7 6 … 0挪到了下面来表达) 接近目标了, 因为我们已经知道, 如果数据包头部中的SYN被置位, 那么头部中的第13个字节的值为2(nt: 按照网络序, 即大头方式, 最重要的字节在前面(在前面,即该字节实际内存地址比较小, 最重要的字节,指数学表示中数的高位, 如356中的3) ). 表达为tcpdump能理解的关系式就是:tcp[13] 2 从而我们可以把此关系式当作tcpdump的过滤条件, 目标就是监控只含有SYN标志的数据包:tcpdump -i xl0 tcp[13] 2 (nt: xl0 指网络接口, 如eth0) 这个表达式是说”让TCP数据包的第13个字节拥有值2吧”, 这也是我们想要的结果. 现在, 假设我们需要抓取带SYN标志的数据包, 而忽略它是否包含其他标志.(nt:只要带SYN就是我们想要的). 让我们来看看当一个含有SYN-ACK的数据包(nt:SYN 和 ACK 标志都有), 来到时发生了什么:12345|C|E|U|A|P|R|S|F||---------------||0 0 0 1 0 0 1 0||---------------||7 6 5 4 3 2 1 0| 13号字节的1号和4号位被置位, 其二进制的值为:00010010 转换成十进制就是: 02^7 + 02^6 + 02^5 + 12^4 + 02^3 + 02^2 + 12^1 + 02 = 18(nt: 1 * 2^6 表示1乘以2的6次方, 也许这样更清楚些, 即把原来表达中的指数7 6 … 0挪到了下面来表达) 现在, 却不能只用’tcp[13] 18’作为tcpdump的过滤表达式, 因为这将导致只选择含有SYN-ACK标志的数据包, 其他的都被丢弃.提醒一下自己, 我们的目标是: 只要包的SYN标志被设置就行, 其他的标志我们不理会. 为了达到我们的目标, 我们需要把13号字节的二进制值与其他的一个数做AND操作(nt:逻辑与)来得到SYN比特位的值. 目标是:只要SYN 被设置就行, 于是我们就把她与上13号字节的SYN值(nt: 00000010). 00010010 SYN-ACK 00000010 SYNAND 00000010 (we want SYN) AND 00000010 (we want SYN) = 00000010 = 00000010 我们可以发现, 不管包的ACK或其他标志是否被设置, 以上的AND操作都会给我们相同的值, 其10进制表达就是2(2进制表达就是00000010).从而我们知道, 对于带有SYN标志的数据包, 以下的表达式的结果总是真(true): ( ( value of octet 13 ) AND ( 2 ) ) ( 2 ) (nt: value of octet 13, 即13号字节的值) 灵感随之而来, 我们于是得到了如下的tcpdump 的过滤表达式tcpdump -i xl0 ‘tcp[13] &amp; 2 2’ 注意, 单引号或反斜杆(nt: 这里用的是单引号)不能省略, 这可以防止shell对&amp;的解释或替换. UDP 数据包 UDP 数据包的显示格式，可通过rwho这个具体应用所产生的数据包来说明:actinide.who &gt; broadcast.who: udp 84 其含义为:actinide主机上的端口who向broadcast主机上的端口who发送了一个udp数据包(nt: actinide和broadcast都是指Internet地址).这个数据包承载的用户数据为84个字节. 一些UDP服务可从数据包的源或目的端口来识别，也可从所显示的更高层协议信息来识别. 比如, Domain Name service requests(DNS 请求,在RFC-1034/1035中), 和Sun RPC calls to NFS(对NFS服务器所发起的远程调用(nt: 即Sun RPC)，在RFC-1050中有对远程调用的描述). UDP 名称服务请求 (注意:以下的描述假设你对Domain Service protoco(nt:在RFC-103中有所描述), 否则你会发现以下描述就是天书(nt:希腊文天书,不必理会, 吓吓你的, 接着看就行)) 名称服务请求有如下的格式:src &gt; dst: id op? flags qtype qclass name (len)(nt: 从下文来看, 格式应该是src &gt; dst: id op flags qtype qclass? name (len))比如有一个实际显示为:h2opolo.1538 &gt; helios.domain: 3+ A? ucbvax.berkeley.edu. (37) 主机h2opolo 向helios 上运行的名称服务器查询ucbvax.berkeley.edu 的地址记录(nt: qtype等于A). 此查询本身的id号为’3’. 符号‘+’意味着递归查询标志被设置(nt: dns服务器可向更高层dns服务器查询本服务器不包含的地址记录). 这个最终通过IP包发送的查询请求数据长度为37字节, 其中不包括UDP和IP协议的头数据. 因为此查询操作为默认值(nt | rt: normal one的理解), op字段被省略.如果op字段没被省略, 会被显示在’3’ 和’+’之间. 同样, qclass也是默认值, C_IN, 从而也没被显示, 如果没被忽略, 她会被显示在’A’之后. 异常检查会在方括中显示出附加的域: 如果一个查询同时包含一个回应(nt: 可理解为, 对之前其他一个请求的回应), 并且此回应包含权威或附加记录段, ancount, nscout, arcount(nt: 具体字段含义需补充) 将被显示为’[na]’, ‘[nn]’, ‘[nau]’, 其中n代表合适的计数. 如果包中以下回应位(比如AA位, RA位, rcode位), 或者字节2或3中任何一个’必须为0’的位被置位(nt: 设置为1), ‘[b2&amp;3]=x’ 将被显示, 其中x表示头部字节2与字节3进行与操作后的值. UDP 名称服务应答 对名称服务应答的数据包，tcpdump会有如下的显示格式src &gt; dst: id op rcode flags a/n/au type class data (len)比如具体显示如下:helios.domain &gt; h2opolo.1538: 3 3/3/7 A 128.32.137.3 (273)helios.domain &gt; h2opolo.1537: 2 NXDomain* 0/1/0 (97) 第一行表示: helios 对h2opolo 所发送的3号查询请求回应了3条回答记录(nt | rt: answer records), 3条名称服务器记录,以及7条附加的记录. 第一个回答记录(nt: 3个回答记录中的第一个)类型为A(nt: 表示地址), 其数据为internet地址128.32.137.3.此回应UDP数据包, 包含273字节的数据(不包含UPD和IP的头部数据). op字段和rcode字段被忽略(nt: op的实际值为Query, rcode, 即response code的实际值为NoError), 同样被忽略的字段还有class 字段(nt | rt: 其值为C_IN, 这也是A类型记录默认取值) 第二行表示: helios 对h2opolo 所发送的2号查询请求做了回应. 回应中, rcode编码为NXDomain(nt: 表示不存在的域)), 没有回答记录,但包含一个名称服务器记录, 不包含权威服务器记录(nt | ck: 从上文来看, 此处的authority records 就是上文中对应的additionalrecords). ‘*’表示权威服务器回答标志被设置(nt: 从而additional records就表示的是authority records).由于没有回答记录, type, class, data字段都被忽略. flag字段还有可能出现其他一些字符, 比如’-‘(nt: 表示可递归地查询, 即RA 标志没有被设置), ‘|’(nt: 表示被截断的消息, 即TC 标志被置位). 如果应答(nt | ct: 可理解为, 包含名称服务应答的UDP数据包, tcpdump知道这类数据包该怎样解析其数据)的’question’段一个条目(entry)都不包含(nt: 每个条目的含义, 需补充),’[nq]’ 会被打印出来. 要注意的是:名称服务器的请求和应答数据量比较大, 而默认的68字节的抓取长度(nt: snaplen, 可理解为tcpdump的一个设置选项)可能不足以抓取数据包的全部内容. 如果你真的需要仔细查看名称服务器的负载, 可以通过tcpdump 的-s 选项来扩大snaplen值. SMB/CIFS 解码 tcpdump 已可以对SMB/CIFS/NBT相关应用的数据包内容进行解码(nt: 分别为’Server Message Block Common’, ‘Internet File System’‘在TCP/IP上实现的网络协议NETBIOS的简称’. 这几个服务通常使用UDP的137/138以及TCP的139端口). 原来的对IPX和NetBEUI SMB数据包的解码能力依然可以被使用(nt: NetBEUI为NETBIOS的增强版本). tcpdump默认只按照最简约模式对相应数据包进行解码, 如果我们想要详尽的解码信息可以使用其-v 启动选现. 要注意的是, -v 会产生非常详细的信息,比如对单一的一个SMB数据包, 将产生一屏幕或更多的信息, 所以此选项, 确有需要才使用. 关于SMB数据包格式的信息, 以及每个域的含义可以参看www.cifs.org 或者samba.org 镜像站点的pub/samba/specs/ 目录. linux 上的SMB 补丁(nt | rt: patch)由 Andrew Tridgell (tridge@samba.org)提供. NFS 请求和回应 tcpdump对Sun NFS(网络文件系统)请求和回应的UDP数据包有如下格式的打印输出:src.xid &gt; dst.nfs: len op argssrc.nfs &gt; dst.xid: reply stat len op results 以下是一组具体的输出数据123456sushi.6709 &gt; wrl.nfs: 112 readlink fh 21,24/10.73165wrl.nfs &gt; sushi.6709: reply ok 40 readlink &quot;../var&quot;sushi.201b &gt; wrl.nfs:144 lookup fh 9,74/4096.6878 &quot;xcolors&quot;wrl.nfs &gt; sushi.201b:reply ok 128 lookup fh 9,74/4134.3150 第一行输出表明: 主机sushi向主机wrl发送了一个’交换请求’(nt: transaction), 此请求的id为6709(注意, 主机名字后是交换请求id号, 而不是源端口号). 此请求数据为112字节, 其中不包括UDP和IP头部的长度. 操作类型为readlink(nt: 即此操作为读符号链接操作),操作参数为fh 21,24/10.73165(nt: 可按实际运行环境, 解析如下, fd 表示描述的为文件句柄, 21,24 表示此句柄所对应设备的主/从设备号对, 10表示此句柄所对应的i节点编号(nt:每个文件都会在操作系统中对应一个i节点, 限于unix类系统中),73165是一个编号(nt: 可理解为标识此请求的一个随机数, 具体含义需补充)). 第二行中, wrl 做了’ok’的回应, 并且在results 字段中返回了sushi想要读的符号连接的真实目录(nt: 即sushi要求读的符号连接其实是一个目录). 第三行表明: sushi 再次请求 wrl 在’fh 9,74/4096.6878’所描述的目录中查找’xcolors’文件. 需要注意的是, 每行所显示的数据含义依赖于其中op字段的类型(nt: 不同op 所对应args 含义不相同), 其格式遵循NFS 协议, 追求简洁明了. 如果tcpdump 的-v选项(详细打印选项) 被设置, 附加的信息将被显示. 比如:1234sushi.1372a &gt; wrl.nfs:148 read fh 21,11/12.195 8192 bytes @ 24576wrl.nfs &gt; sushi.1372a:reply ok 1472 read REG 100664 ids 417/0 sz 29388 (-v 选项一般还会打印出IP头部的TTL, ID， length, 以及fragmentation 域, 但在此例中, 都略过了(nt: 可理解为,简洁起见, 做了删减))在第一行, sushi 请求wrl 从文件 21,11/12.195(nt: 格式在上面有描述)中, 自偏移24576字节处开始, 读取8192字节数据.Wrl 回应读取成功; 由于第二行只是回应请求的开头片段, 所以只包含1472字节(其他的数据将在接着的reply片段中到来, 但这些数据包不会再有NFS头, 甚至UDP头信息也为空(nt: 源和目的应该要有), 这将导致这些片段不能满足过滤条件, 从而没有被打印). -v 选项除了显示文件数据信息, 还会显示附加显示文件属性信息: file type(文件类型, ‘’REG’’ 表示普通文件), file mode(文件存取模式, 8进制表示的), uid 和gid(nt: 文件属主和组属主), file size (文件大小). 如果-v 标志被多次重复给出(nt: 如-vv)， tcpdump会显示更加详细的信息. 必须要注意的是, NFS 请求包中数据比较多, 如果tcpdump 的snaplen(nt: 抓取长度) 取太短将不能显示其详细信息. 可使用‘-s 192’来增加snaplen, 这可用以监测NFS应用的网络负载(nt: traffic). NFS 的回应包并不严格的紧随之前相应的请求包(nt: RPC operation). 从而, tcpdump 会跟踪最近收到的一系列请求包, 再通过其交换序号(nt: transaction ID)与相应请求包相匹配. 这可能产生一个问题， 如果回应包来得太迟, 超出tcpdump 对相应请求包的跟踪范围,该回应包将不能被分析. AFS 请求和回应 AFS(nt: Andrew 文件系统, Transarc , 未知, 需补充)请求和回应有如下的答应12345678src.sport &gt; dst.dport: rx packet-typesrc.sport &gt; dst.dport: rx packet-type service call call-name argssrc.sport &gt; dst.dport: rx packet-type service reply call-name argselvis.7001 &gt; pike.afsfs:rx data fs call rename old fid 536876964/1/1 &quot;.newsrc.new&quot;new fid 536876964/1/1 &quot;.newsrc&quot;pike.afsfs &gt; elvis.7001: rx data fs reply rename 在第一行, 主机elvis 向pike 发送了一个RX数据包.这是一个对于文件服务的请求数据包(nt: RX data packet, 发送数据包 , 可理解为发送包过去, 从而请求对方的服务), 这也是一个RPC调用的开始(nt: RPC, remote procedure call). 此RPC 请求pike 执行rename(nt: 重命名) 操作, 并指定了相关的参数:原目录描述符为536876964/1/1, 原文件名为 ‘.newsrc.new’, 新目录描述符为536876964/1/1, 新文件名为 ‘.newsrc’.主机pike 对此rename操作的RPC请求作了回应(回应表示rename操作成功, 因为回应的是包含数据内容的包而不是异常包). 一般来说, 所有的’AFS RPC’请求被显示时, 会被冠以一个名字(nt: 即decode, 解码), 这个名字往往就是RPC请求的操作名.并且, 这些RPC请求的部分参数在显示时, 也会被冠以一个名字(nt | rt: 即decode, 解码, 一般来说也是取名也很直接, 比如,一个interesting 参数, 显示的时候就会直接是’interesting’, 含义拗口, 需再翻). 这种显示格式的设计初衷为’一看就懂’, 但对于不熟悉AFS 和 RX 工作原理的人可能不是很有用(nt: 还是不用管, 书面吓吓你的, 往下看就行). 如果 -v(详细)标志被重复给出(nt: 如-vv), tcpdump 会打印出确认包(nt: 可理解为, 与应答包有区别的包)以及附加头部信息(nt: 可理解为, 所有包, 而不仅仅是确认包的附加头部信息), 比如, RX call ID(请求包中’请求调用’的ID),call number(‘请求调用’的编号), sequence number(nt: 包顺序号),serial number(nt | rt: 可理解为与包中数据相关的另一个顺信号, 具体含义需补充), 请求包的标识. (nt: 接下来一段为重复描述,所以略去了), 此外确认包中的MTU协商信息也会被打印出来(nt: 确认包为相对于请求包的确认包, Maximum Transmission Unit, 最大传输单元). 如果 -v 选项被重复了三次(nt: 如-vvv), 那么AFS应用类型数据包的’安全索引’(‘security index’)以及’服务索引’(‘service id’)将会被打印. 对于表示异常的数据包(nt: abort packet, 可理解为, 此包就是用来通知接受者某种异常已发生), tcpdump 会打印出错误号(error codes).但对于Ubik beacon packets(nt: Ubik 灯塔指示包, Ubik可理解为特殊的通信协议, beacon packets, 灯塔数据包, 可理解为指明通信中关键信息的一些数据包), 错误号不会被打印, 因为对于Ubik 协议, 异常数据包不是表示错误, 相反却是表示一种肯定应答(nt: 即, yes vote). AFS 请求数据量大, 参数也多, 所以要求tcpdump的 snaplen 比较大, 一般可通过启动tcpdump时设置选项’-s 256’ 来增大snaplen, 以监测AFS 应用通信负载. AFS 回应包并不显示标识RPC 属于何种远程调用. 从而, tcpdump 会跟踪最近一段时间内的请求包, 并通过call number(调用编号), service ID(服务索引) 来匹配收到的回应包. 如果回应包不是针对最近一段时间内的请求包, tcpdump将无法解析该包. KIP AppleTalk协议 (nt | rt: DDP in UDP可理解为, DDP, The AppleTalk Data Delivery Protocol,相当于支持KIP AppleTalk协议栈的网络层协议, 而DDP 本身又是通过UDP来传输的,即在UDP 上实现的用于其他网络的网络层，KIP AppleTalk是苹果公司开发的整套网络协议栈). AppleTalk DDP 数据包被封装在UDP数据包中, 其解封装(nt: 相当于解码)和相应信息的转储也遵循DDP 包规则.(nt:encapsulate, 封装, 相当于编码, de-encapsulate, 解封装, 相当于解码, dump, 转储, 通常就是指对其信息进行打印). /etc/atalk.names 文件中包含了AppleTalk 网络和节点的数字标识到名称的对应关系. 其文件格式通常如下所示:12345number name1.254 ether16.1 icsd-net1.254.110 ace 头两行表示有两个AppleTalk 网络. 第三行给出了特定网络上的主机(一个主机会用3个字节来标识,而一个网络的标识通常只有两个字节, 这也是两者标识的主要区别)(nt: 1.254.110 可理解为ether网络上的ace主机).标识与其对应的名字之间必须要用空白分开. 除了以上内容, /etc/atalk.names中还包含空行以及注释行(以’#’开始的行). AppleTalk 完整网络地址将以如下格式显示:net.host.port 以下为一段具体显示:123144.1.209.2 &gt; icsd-net.112.220office.2 &gt; icsd-net.112.220jssmag.149.235 &gt; icsd-net.2 (如果/etc/atalk.names 文件不存在, 或者没有相应AppleTalk 主机/网络的条目, 数据包的网络地址将以数字形式显示). 在第一行中, 网络144.1上的节点209通过2端口,向网络icsd-net上监听在220端口的112节点发送了一个NBP应用数据包(nt | rt: NBP, name binding protocol, 名称绑定协议, 从数据来看, NBP服务器会在端口2提供此服务.‘DDP port 2’ 可理解为’DDP 对应传输层的端口2’, DDP本身没有端口的概念, 这点未确定, 需补充). 第二行与第一行类似, 只是源的全部地址可用’office’进行标识.第三行表示: jssmag网络上的149节点通过235向icsd-net网络上的所有节点的2端口(NBP端口)发送了数据包.(需要注意的是,在AppleTalk 网络中如果地址中没有节点, 则表示广播地址, 从而节点标识和网络标识最好在/etc/atalk.names有所区别.nt: 否则一个标识x.port 无法确定x是指一个网络上所有主机的port口还是指定主机x的port口). tcpdump 可解析NBP (名称绑定协议) and ATP (AppleTalk传输协议)数据包, 对于其他应用层的协议, 只会打印出相应协议名字(如果此协议没有注册一个通用名字, 只会打印其协议号)以及数据包的大小. NBP 数据包会按照如下格式显示:123icsd-net.112.220 &gt; jssmag.2: nbp-lkup 190: &quot;=:LaserWriter@*&quot;jssmag.209.2 &gt; icsd-net.112.220: nbp-reply 190: &quot;RM1140:LaserWriter@*&quot; 250techpit.2 &gt; icsd-net.112.220: nbp-reply 190: &quot;techpit:LaserWriter@*&quot; 186 第一行表示: 网络icsd-net 中的节点112 通过220端口向网络jssmag 中所有节点的端口2发送了对’LaserWriter’的名称查询请求(nt:此处名称可理解为一个资源的名称, 比如打印机). 此查询请求的序列号为190. 第二行表示: 网络jssmag 中的节点209 通过2端口向icsd-net.112节点的端口220进行了回应: 我有’LaserWriter’资源, 其资源名称为’RM1140’, 并且在端口250上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号. 第三行也是对第一行请求的回应: 节点techpit 通过2端口向icsd-net.112节点的端口220进行了回应:我有’LaserWriter’资源, 其资源名称为’techpit’, 并且在端口186上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号. ATP 数据包的显示格式如下:12345678910111213jssmag.209.165 &gt; helios.132: atp-req 12266&lt;0-7&gt; 0xae030001helios.132 &gt; jssmag.209.165: atp-resp 12266:0 (512) 0xae040000helios.132 &gt; jssmag.209.165: atp-resp 12266:1 (512) 0xae040000helios.132 &gt; jssmag.209.165: atp-resp 12266:2 (512) 0xae040000helios.132 &gt; jssmag.209.165: atp-resp 12266:3 (512) 0xae040000helios.132 &gt; jssmag.209.165: atp-resp 12266:5 (512) 0xae040000helios.132 &gt; jssmag.209.165: atp-resp 12266:6 (512) 0xae040000helios.132 &gt; jssmag.209.165: atp-resp*12266:7 (512) 0xae040000jssmag.209.165 &gt; helios.132: atp-req 12266&lt;3,5&gt; 0xae030001helios.132 &gt; jssmag.209.165: atp-resp 12266:3 (512) 0xae040000helios.132 &gt; jssmag.209.165: atp-resp 12266:5 (512) 0xae040000jssmag.209.165 &gt; helios.132: atp-rel 12266&lt;0-7&gt; 0xae030001jssmag.209.133 &gt; helios.132: atp-req* 12267&lt;0-7&gt; 0xae030002 第一行表示节点 Jssmag.209 向节点helios 发送了一个会话编号为12266的请求包, 请求helios回应8个数据包(这8个数据包的顺序号为0-7(nt: 顺序号与会话编号不同, 后者为一次完整传输的编号,前者为该传输中每个数据包的编号. transaction, 会话, 通常也被叫做传输)). 行尾的16进制数字表示该请求包中’userdata’域的值(nt: 从下文来看, 这并没有把所有用户数据都打印出来 ). Helios 回应了8个512字节的数据包. 跟在会话编号(nt: 12266)后的数字表示该数据包在该会话中的顺序号.括号中的数字表示该数据包中数据的大小, 这不包括atp 的头部. 在顺序号为7数据包(第8行)外带了一个’*’号,表示该数据包的EOM 标志被设置了.(nt: EOM, End Of Media, 可理解为, 表示一次会话的数据回应完毕). 接下来的第9行表示, Jssmag.209 又向helios 提出了请求: 顺序号为3以及5的数据包请重新传送. Helios 收到这个请求后重新发送了这个两个数据包, jssmag.209 再次收到这两个数据包之后, 主动结束(release)了此会话. 在最后一行, jssmag.209 向helios 发送了开始下一次会话的请求包. 请求包中的’*’表示该包的XO 标志没有被设置.(nt: XO, exactly once, 可理解为在该会话中, 数据包在接受方只被精确地处理一次, 就算对方重复传送了该数据包,接收方也只会处理一次, 这需要用到特别设计的数据包接收和处理机制). IP 数据包破碎 (nt: 指把一个IP数据包分成多个IP数据包) 碎片IP数据包(nt: 即一个大的IP数据包破碎后生成的小IP数据包)有如下两种显示格式.(frag id:size@offset+)(frag id:size@offset)(第一种格式表示, 此碎片之后还有后续碎片. 第二种格式表示, 此碎片为最后一个碎片.) id 表示破碎编号(nt: 从下文来看, 会为每个要破碎的大IP包分配一个破碎编号, 以便区分每个小碎片是否由同一数据包破碎而来).size 表示此碎片的大小 , 不包含碎片头部数据. offset表示此碎片所含数据在原始整个IP包中的偏移((nt: 从下文来看,一个IP数据包是作为一个整体被破碎的, 包括头和数据, 而不只是数据被分割). 每个碎片都会使tcpdump产生相应的输出打印. 第一个碎片包含了高层协议的头数据(nt:从下文来看, 被破碎IP数据包中相应tcp头以及IP头都放在了第一个碎片中 ), 从而tcpdump会针对第一个碎片显示这些信息, 并接着显示此碎片本身的信息. 其后的一些碎片并不包含高层协议头信息, 从而只会在显示源和目的之后显示碎片本身的信息. 以下有一个例子: 这是一个从arizona.edu 到lbl-rtsg.arpa途经CSNET网络(nt: CSNET connection 可理解为建立在CSNET 网络上的连接)的ftp应用通信片段:123arizona.ftp-data &gt; rtsg.1170: . 1024:1332(308) ack 1 win 4096 (frag 595a:328@0+)arizona &gt; rtsg: (frag 595a:204@328)rtsg.1170 &gt; arizona.ftp-data: . ack 1536 win 2560 有几点值得注意:第一, 第二行的打印中, 地址后面没有端口号.这是因为TCP协议信息都放到了第一个碎片中, 当显示第二个碎片时, 我们无法知道此碎片所对应TCP包的顺序号. 第二, 从第一行的信息中, 可以发现arizona需要向rtsg发送308字节的用户数据, 而事实是, 相应IP包经破碎后会总共产生512字节数据(第一个碎片包含308字节的数据, 第二个碎片包含204个字节的数据, 这超过了308字节). 如果你在查找数据包的顺序号空间中的一些空洞(nt: hole,空洞, 指数据包之间的顺序号没有上下衔接上), 512这个数据就足够使你迷茫一阵(nt: 其实只要关注308就行,不必关注破碎后的数据总量). 一个数据包(nt | rt: 指IP数据包)如果带有非IP破碎标志, 则显示时会在最后显示’(DF)’.(nt: 意味着此IP包没有被破碎过). 时间戳 tcpdump的所有输出打印行中都会默认包含时间戳信息.时间戳信息的显示格式如下hh:mm:ss.frac (nt: 小时:分钟:秒.(nt: frac未知, 需补充))此时间戳的精度与内核时间精度一致, 反映的是内核第一次看到对应数据包的时间(nt: saw, 即可对该数据包进行操作). 而数据包从物理线路传递到内核的时间, 以及内核花费在此包上的中断处理时间都没有算进来. 参考资料 Linux tcpdump命令详解]]></content>
      <categories>
        <category>Linux</category>
        <category>tcpdump</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[储性能瓶颈的成因、定位与排查]]></title>
    <url>%2F2014%2F07%2F01%2F33805%2F</url>
    <content type="text"><![CDATA[企业数据存储性能瓶颈常常会发生在端口，控制器和磁盘，难点在于找出引起拥塞的单元，往往需要应用多重工具以及丰富的经验来查找并解决。本文详细阐述存储瓶颈发生最常见的四种情况，可能发生的拥塞点，需要监控的参数指标，以及部署存储系统的最佳实践。 数据存储瓶颈的四个常见场景 当多个用户同时访问某一业务应用，无论是邮件服务器，企业资源规划（ERP）系统或数据库，数据请求会累积在队列中。单个 I/O 的响应时间开始增长，短暂延时开始转变成为漫长的等待。 这类响应时间敏感型应用的特征是，很多随机请求，读取比写入更多，I/O 较小。最好的方法是：将负载分布在多块磁盘上，否则可能造成性能瓶颈。 如果应用增加了更多用户，或应用IOPS请求增加，则可能需要在 RAID 组中添加更多磁盘，或数据可能需要跨越更多磁盘，在更多层级做条带化。 存储在这样的情况下往往首先被怀疑，但大多数情况下并非存储引发，原因可能在于网络、应用或服务器。 带宽敏感型应用——如数据备份，视频流或安全登录，这类应用当多个用户同时访问大型文件或数据流时可能造成瓶颈。定位这一问题存储管理员应当从备份服务器开始一路向下检查至磁盘，原因可能存在于这一通路的任何地方。 问题不一定发生在存储，可能是由于备份应用创建的方式或是磁带系统的工作方式引起的。如果瓶颈定位于存储，那么可能是由于服务 I/O 的磁盘数量不足，在控制器造成争用，或是阵列前端口带宽不足。 性能调优需要针对不同应用程序负载来完成。针对大型文件和流数据的调优并不适合于小型文件，反之亦然。这也就是为什么在大多数存储系统中往往做一个平衡，需要用户尝试并找出系统的折中。用户通常需要优化吞吐量或 IOPS，但并不需要对两者同时优化。 RAID 组中的磁盘故障。特别是在 RAID 5 中会造成性能的下降，因为系统需要重建校验数据。相比数据读写操作，重建会对性能造成更大影响。 即便坏盘是造成故障的根源，但控制器还是可能成为瓶颈，因为在重建过程中它需要不停地服务数据。当重建完成时，性能才会恢复正常。 部署了一种新的应用，而卷存在于处理繁忙邮件系统的同一磁盘。如果新的应用变得繁忙，邮件系统性能将会遭受影响。额外的流量最终会将磁盘完全覆盖。 存储瓶颈常发区域 存储区域网络（Storage-area network, SAN）/阵列前端口 存储部署于集中化SAN环境时，需考虑服务器和SAN之间的潜在网络瓶颈。例如，运行多部虚拟机的整合服务器可能不具备支持工作负载要求的足够网络端口。添加网络端口或转移网络密集型工作负载至其他服务器可解决这一问题。如前所述，对于带宽集中型应用，需考虑NFS有多少Fiber Channel 端口, or iSCSI 端口 or Ethernet 端口，需要用户站在带宽的角度来考量整个架构。 可能发生的问题包括： 123456* 如果阵列中端口数量不够，就会发生过饱和/过度使用* 虚拟服务器环境下的过量预定* 端口间负载不均衡* 交换机间链路争用/流量负荷过重* 如某一HBA端口负载过重将导致HBA拥塞。使用虚拟机会导致问题更加严重 存储控制器 一个标准的主动——被动或主动——主动控制器都有一个性能极限。接近这条上限取决于用户有多少块磁盘，因为每块磁盘的IOPS和吞吐量是固定的。 可能出现的问题包括： 12345* 控制器I/O过饱和，使得从缓存到阵列能够处理的IOPS受到限制* 吞吐量“淹没“处理器* CPU过载/处理器功率不足* 性能无法跟上SSD Cache 由于服务器内存和CPU远比机械磁盘快得多，需为磁盘添加高速内存以缓存读写数据。例如，写入磁盘的数据存储在缓存中直到磁盘能够跟上，同时磁盘中的读数据放入缓存中直到能被主机读取。Cache比磁盘快1000倍，因此将数据写入和读出Cache对性能影响巨大。智能缓存算法能够预测你需要查找的数据，你是否会对此数据频繁访问，甚至是将访问频繁的随机数据放在缓存中。 可能发生的问题包括： 12345* Cache memory不足* Cache写入过载，引起性能降低* 频繁访问顺序性数据引起cache超负荷* Cache中需要持续不断地写入新数据，因此如果cache总是在refill，将无法从cache获益 磁盘 磁盘瓶颈与磁盘转速有关, 慢速磁盘会引入较多延时。存储性能问题的排查首先考虑的因素就是磁盘速度，同时有多少块磁盘可进行并发读写。而另一因素是磁盘接口。采用更快的接口能够缓解磁盘瓶颈，但更重要的是在快速接口与相应更大的缓存大小以及转速之间取得平衡。同样，应避免将快速和慢速磁盘混入同一接口，因为慢速磁盘将会造成快速接口与快速磁盘的性能浪费。 可能引发的问题包括： 12345* 过多应用命中磁盘* 磁盘数量不足以满足应用所需的IOPS或吞吐量* 磁盘速度过慢无法满足性能需求及支持繁重工作负荷* Disk group往往是classic存储架构的潜在性能瓶颈，这种结构下RAID最多配置在16块磁盘。Thin结构通常每个LUN拥有更多磁盘，从而数据分布于更多spindle，因增加的并发性而减少了成为瓶颈的可能。 需要监控的指标曾经一度存储厂商们强调的是IOPS和吞吐量，但现在重点逐渐转变成为响应时间。也就是说，不是数据移动的速度有多快，而在于对请求的响应速度有多快。 正常情况下，15,000 rpm Fibre Channel磁盘响应时间为4ms，SAS磁盘响应时间约为5ms至6ms，SATA为10ms，而SSD少于1ms。如果发现Fibre Channel磁盘响应时间为12ms，或SSD响应时间变成5ms，那么就说明可能产生了争用，可能芯片发生了故障。 除了响应时间，其他需要监控的指标包括： 1234567* 队列长度，队列中一次积累的请求数量，平均磁盘队列长度* 平均I/O大小千字节数* IOPS （读和写，随机和顺序，整体平均IOPS）* 每秒百万字节吞吐量* 读写所占比例* 容量（空闲，使用和保留） 数据存储性能最佳实践性能调优和改进的方式有很多种，用户当然可以通过添加磁盘，端口，多核处理器，内存来改善，但问题是：性价比，以及对业务是否实用。本文建议的方式是在预算范围内找寻性能最大化的解决方案。另外一个需要考虑的方面是环境并非一尘不变，系统部署方案要能够适应环境的改变需求。 首先需要考虑刷数据的性能特征，需要了解IO工作情况是怎样的。是否是cache友好型？是否是CPU集中型？业务数据很大数量很少，还是很小但数量很多？另外一方面就是构成存储环境的组件。包括应用，存储系统本身，网络。。。瓶颈可能在哪里，改善哪里最有效？ 以下是一些常规建议： 不要仅仅根据空闲空间来分配存储，而需要结合考虑性能需求，确保为吞吐量或IOPS分配足够多的磁盘。 在磁盘间均衡分布应用负载，以减少热点地区的产生。 理解应用负载类型，并针对负载选择匹配的RAID类型。例如，写密集型应用建议使用RAID 1而不是RAID 5。因为当写入RAID 5时，需要计算校验位，需耗费较多时间。而RAID 1，写入两块磁盘速度快得多，无需计算。 磁盘类型（Fibre Channel, SAS, SATA）与期望性能相匹配。对于关键业务应用部署高性能磁盘，例如15,000 rpm Fibre Channel。 对于I/O密集型应用考虑采用SSD，但并不适用于写性能重要型应用。只要没有达到控制器瓶颈，SSD对读性能提升显著，但对写性能提升并没有明显效果。 采用端对端的监控工具，特别是虚拟服务器环境。虚拟端与物理端之间有一道防火墙，所以，需要穿透防火墙进行端到端的监控。 有些性能分析工具涵盖从应用到磁盘，有些仅局限于存储系统本身。由于性能是一个连锁反应包含很多变量，所以需要全面地分析数据。 以数据仅写入磁盘外部扇区的方式格式化磁盘。因减少数据定位时间而在高I/O环境下提升性能。负面作用是相当一部分磁盘容量未能得以使用。 参考资料 存储性能瓶颈的成因、定位与排查]]></content>
      <categories>
        <category>Storage</category>
      </categories>
      <tags>
        <tag>Storage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android 开发常用库]]></title>
    <url>%2F2014%2F07%2F01%2F56158%2F</url>
    <content type="text"><![CDATA[Android 开发过程中，恰当的使用一些比较成熟的库，能够大大提高开发效率。 GsonGson 是 Google 提供的用来在 Java 对象和 JSON 数据之间进行映射的 Java 类库。可用于将 Java 对象转换成对应的 JSON 表示，也可以将 JSON 字符串转换成一个等效的 Java 对象。如果与 API 打交道的话，那么这将会是你经常需要的东西。我们主要使用 JSON 的原因就是，相较 XML，轻量级的 JSON 要简单的多。 12345// SerializeString userJSON = new Gson().toJson(user);// DeserializeUser user = new Gson().fromJson(userJSON, User.class); Retrofit就如它网站上的介绍“Retrofit 将你的 REST API 变为 Java 接口”一样，Retrofit 把 REST API 返回的数据转化为 Java 对象方便操作，对于在项目中组织 API 调用，是一个不错的解决方案。其请求方法和相对 URL 都带有注解，使得代码变得更加简洁。使用注解，你可以很容易的添加一个请求主体，操纵 URL 或头文件，并添加查询参数。除此之外，每个函数可以定义为同步或异步，具有返回值的函数为同步执行，而异步函数没有返回值且最后一个参数为 Callback 对象。 12345678910111213141516171819202122232425262728public interface RetrofitInterface &#123; // asynchronously with a callback @GET("/api/user") User getUser(@Query("user_id") int userId, Callback&lt;User&gt; callback); // synchronously @POST("/api/user/register") User registerUser(@Body User user);&#125;// exampleRetrofitInterface retrofitInterface = new RestAdapter.Builder() .setServer(API.API_URL).build().create(RetrofitInterface.class);// fetch user with id 2048retrofitInterface.getUser(2048, new Callback&lt;User&gt;() &#123; @Override public void success(User user, Response response) &#123; &#125; @Override public void failure(RetrofitError retrofitError) &#123; &#125;&#125;); EventBusEventBus 是用于简化应用中各个部件之间通信的一个库。比如从一个 Activity 发送消息到一个正在运行的服务，亦或是片段之间简单的互动。而下面使用的示例，就是如果网络连接丢失，该如何通知一个活动。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class NetworkStateReceiver extends BroadcastReceiver &#123; // post event if there is no Internet connection public void onReceive(Context context, Intent intent) &#123; super.onReceive(context, intent); if(intent.getExtras()!=null) &#123; NetworkInfo ni=(NetworkInfo) intent.getExtras().get(ConnectivityManager.EXTRA_NETWORK_INFO); if(ni!=null &amp;&amp; ni.getState()==NetworkInfo.State.CONNECTED) &#123; // there is Internet connection &#125; else if(intent .getBooleanExtra(ConnectivityManager.EXTRA_NO_CONNECTIVITY,Boolean.FALSE)) &#123; // no Internet connection, send network state changed EventBus.getDefault().post(new NetworkStateChanged(false)); &#125;&#125;// eventpublic class NetworkStateChanged &#123; private mIsInternetConnected; public NetworkStateChanged(boolean isInternetConnected) &#123; this.mIsInternetConnected = isInternetConnected; &#125; public boolean isInternetConnected() &#123; return this.mIsInternetConnected; &#125;&#125;public class HomeActivity extends Activity &#123; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); EventBus.getDefault().register(this); // register EventBus &#125; @Override protected void onDestroy() &#123; super.onDestroy(); EventBus.getDefault().unregister(this); // unregister EventBus &#125; // method that will be called when someone posts an event NetworkStateChanged public void onEventMainThread(NetworkStateChanged event) &#123; if (!event.isInternetConnected()) &#123; Toast.makeText(this, "No Internet connection!", Toast.LENGTH_SHORT).show(); &#125; &#125;&#125; ActiveAndroidActiveAndroid 算是一个轻量级的 ORM（对象关系映射），让你无需编写一个单独的SQL语句，就可以保存和检索 SQLite 数据库记录。每个数据库记录都被包裹整齐地归为一类，如 delete（）和 save（）的方法。 12345678910111213// 扩展 ActiveAndroid Model 的对象能够保存在数据库里，如：user.save();// 可以轻易替代大型 SQL 语句：INSERT INTO Users (Nickname, Name, Address, City, PostalCode, Country) VALUES ('Batman','Bruce W','Palisades 21','Gotham','40000','USA');// 获取所有用户的例子：List&lt;User&gt; users = new Select().from(User.class).execute();// 而其对应的 SQL 语句是这样：SELECT Nickname, Name, Address, City, PostalCode, Country FROM Users;// ActiveAndroid 是移除大量，用于和数据库一同工作的样板代码的一个很好的方法。当然除此之外，还有其他开源解决方案，如 GreenDAO 和 ORMLite。 Universal Image LoaderUIL 是是一个开源项目，其目的就是提供一个可重复使用的仪器为异步图像加载、缓存和显示。它的使用很简单： 1imageLoader.displayImage(imageUri, imageView); 尽管 Picasso 拥有更好的API，但其缺乏自定义。而使用 UIL 构建器几乎可以配置所有（其中最重要的就是在抓取和缓存大型图片时，Picasso 会失败）。 良好的开源库会让你的开发变得更简单更快速，而普遍流行的库通常测试良好且易用使用。在大多情况下，你可以很容易的将它们从 Maven 中导入到 Android Studio 项目里。将它们添加到相关性的 build.gradle 文件。并且同步之后，在你的应用里将能够很好的实现它们。 1234567dependencies &#123; compile 'com.google.code.gson:gson:2.2.4' compile 'com.squareup.okhttp:okhttp:1.3.0' compile 'com.squareup.retrofit:retrofit:1.3.0' compile 'de.greenrobot:eventbus:2.2.+' compile 'com.nostra13.universalimageloader:universal-image-loader:1.9.1'&#125; 参考资料 Android 开发者必知的 5 个开源库]]></content>
      <categories>
        <category>Android</category>
        <category>Library</category>
      </categories>
      <tags>
        <tag>Android Library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 用户、组、权限的管理]]></title>
    <url>%2F2014%2F06%2F27%2F35860%2F</url>
    <content type="text"><![CDATA[以下命令基于 Ubuntu 14.04版本。 组管理123456789101112groups --helpUsage: groups [OPTION]... [USERNAME]...Print group memberships for each USERNAME or, if no USERNAME is specified, forthe current process (which may differ if the groups database has changed). --help display this help and exit --version output version information and exitReport groups bugs to bug-coreutils@gnu.orgGNU coreutils home page: &lt;http://www.gnu.org/software/coreutils/&gt;General help using GNU software: &lt;http://www.gnu.org/gethelp/&gt;Report groups translation bugs to &lt;http://translationproject.org/team/&gt;For complete documentation, run: info coreutils 'groups invocation' 1234567891011121314gpasswd --helpUsage: gpasswd [option] GROUPOptions: -a, --add USER add USER to GROUP -d, --delete USER remove USER from GROUP -h, --help display this help message and exit -Q, --root CHROOT_DIR directory to chroot into -r, --remove-password remove the GROUP\'s password -R, --restrict restrict access to GROUP to its members -M, --members USER,... set the list of members of GROUP -A, --administrators ADMIN,... set the list of administrators for GROUPExcept for the -A and -M options, the options cannot be combined. 用户管理1234567891011121314151617181920212223242526272829303132333435useradd -hUsage: useradd [options] LOGIN useradd -D useradd -D [options]Options: -b, --base-dir BASE_DIR base directory for the home directory of the new account -c, --comment COMMENT GECOS field of the new account -d, --home-dir HOME_DIR home directory of the new account -D, --defaults print or change default useradd configuration -e, --expiredate EXPIRE_DATE expiration date of the new account -f, --inactive INACTIVE password inactivity period of the new account -g, --gid GROUP name or ID of the primary group of the new account -G, --groups GROUPS list of supplementary groups of the new account -h, --help display this help message and exit -k, --skel SKEL_DIR use this alternative skeleton directory -K, --key KEY=VALUE override /etc/login.defs defaults -l, --no-log-init do not add the user to the lastlog and faillog databases -m, --create-home create the user's home directory -M, --no-create-home do not create the user's home directory -N, --no-user-group do not create a group with the same name as the user -o, --non-unique allow to create users with duplicate (non-unique) UID -p, --password PASSWORD encrypted password of the new account -r, --system create a system account -R, --root CHROOT_DIR directory to chroot into -s, --shell SHELL login shell of the new account -u, --uid UID user ID of the new account -U, --user-group create a group with the same name as the user -Z, --selinux-user SEUSER use a specific SEUSER for the SELinux user mapping 123456789101112131415161718192021222324252627adduser [--home DIR] [--shell SHELL] [--no-create-home] [--uid ID][--firstuid ID] [--lastuid ID] [--gecos GECOS] [--ingroup GROUP | --gid ID][--disabled-password] [--disabled-login] [--encrypt-home] USER Add a normal useradduser --system [--home DIR] [--shell SHELL] [--no-create-home] [--uid ID][--gecos GECOS] [--group | --ingroup GROUP | --gid ID] [--disabled-password][--disabled-login] USER Add a system useradduser --group [--gid ID] GROUPaddgroup [--gid ID] GROUP Add a user groupaddgroup --system [--gid ID] GROUP Add a system groupadduser USER GROUP Add an existing user to an existing groupgeneral options: --quiet | -q don\'t give process information to stdout --force-badname allow usernames which do not match the NAME_REGEX[_SYSTEM] configuration variable --help | -h usage message --version | -v version number and copyright --conf | -c FILE use FILE as configuration file 密码管理12345678910111213141516171819202122passwd --helpUsage: passwd [options] [LOGIN]Options: -a, --all report password status on all accounts -d, --delete delete the password for the named account -e, --expire force expire the password for the named account -h, --help display this help message and exit -k, --keep-tokens change password only if expired -i, --inactive INACTIVE set password inactive after expiration to INACTIVE -l, --lock lock the password of the named account -n, --mindays MIN_DAYS set minimum number of days before password change to MIN_DAYS -q, --quiet quiet mode -r, --repository REPOSITORY change password in REPOSITORY repository -R, --root CHROOT_DIR directory to chroot into -S, --status report password status on the named account -u, --unlock unlock the password of the named account -w, --warndays WARN_DAYS set expiration warning days to WARN_DAYS -x, --maxdays MAX_DAYS set maximum number of days before password change to MAX_DAYS 文件相关 /etc/group：用户组的配置文件，包括用户和用户组信息 123456# 每条记录包含四项内容，以分号隔开1. 用户组名称2. 用户组密码，`x`值表示未设置密码3. GID，用户组 ID4. 用户列表，多个用户之间以逗号分隔；字段为空表示 GID 值为本用户组 GID 值的用户（可以通过`/etc/passwd`查看） /etc/shadow： /etc/passwd：用户信息配置文件]]></content>
      <categories>
        <category>Ubuntu</category>
        <category>Permission</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Permission</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu SSH 服务开启]]></title>
    <url>%2F2014%2F06%2F27%2F61358%2F</url>
    <content type="text"><![CDATA[开启 SSH 服务 openssh-client，客户端，用于登陆其他服务器，ubuntu 默认已经安装，如果未安装则执行以下命令： 1sudo apt-get install openssh-client openssh-server，服务端，本机对外开放 SSH 服务 12345678910# 安装 openssh-serversudo apt-get install openssh-server# 确认 ssh server 是否启动，sshd 表示 ssh server 启动成功ps -e | grep ssh# 启动 ssh server 服务，ssh server 的配置文件位于 `/etc/ssh/sshd_config`，在这里可以定义 SSH 的服务端口，默认为22sudo /etc/init.d/ssh start# 或service ssh start]]></content>
      <categories>
        <category>Ubuntu</category>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 软件安装与卸载]]></title>
    <url>%2F2014%2F06%2F27%2F64845%2F</url>
    <content type="text"><![CDATA[软件包的安装、卸载软件包的安装 APT 方式 12345678# 普通安装apt-get install softname1 softname2 ...;# 修复安装（-f Atemp to correct broken dependencies）apt-get -f install softname1 softname2 ...;# 重新安装apt-get --reinstall install softname1 softname2 ...; Dpkg 方式 12# 普通安装dpkg -i package_name.deb 源码安装（.tar、tar.gz、tar.bz2、tar.Z） 1234567891011# 首先解压源码压缩包，通过 tar 命令来完成tar zxf xx.tar.gztar zxf xx.tar.Ztar zxf xx.tgzbunzip2 xx.bz2tar xf xx.tar# 进入到解压出的目录中，查看README之类的说明文件，或使用`ls -F --color`或`ls -F`命令查看下可执行文件，可执行文件会以*号的尾部标识。一般依次执行一下操作即可完成安装：./configuremakesudo make install 软件包的卸载 APT 方式 12345678# 移除式卸载（移除软件包，当尾部有+时，表示安装）apt-get remove softname1 softname2 ...;# 清除式卸载（卸载同时，清除配置）apt-get --purge remove softname1 softname2 ...;# 清除式卸载（卸载同时，清除配置）apt-get purge softname1 softname2 ...; Dpkg 方式 12345# 移除式卸载dpkg -r pkg1 pkg2 ...;# 清除式卸载dpkg -P pkg1 pkg2 ...; 查看是否安装某软件包 Dpkg 使用文本文件来作为数据库，通常在/var/lib/dpkg目录下。通常在status文件中存储软件状态和控制信息，在info/目录下备份控制文件，并在其下的.list文件中记录安装文件清单，其下.md5sums保存文件的 MD5 编码。 123456789101112dpkg -lDesired=Unknown/Install/Remove/Purge/Hold| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)||/ Name Version Architecture Description+++-======================================-========================-========================-==================================================================================ii account-plugin-aim 3.8.6-0ubuntu9 amd64 Messaging account plugin for AIMii account-plugin-facebook 0.11+14.04.20140409.1-0u all GNOME Control Center account plugin for single signon - facebookii account-plugin-flickr 0.11+14.04.20140409.1-0u all GNOME Control Center account plugin for single signon - flickrii account-plugin-google 0.11+14.04.20140409.1-0u all GNOME Control Center account plugin for single signonii account-plugin-jabber 3.8.6-0ubuntu9 amd64 Messaging account plugin for Jabber/XMPP...... 以上每条记录对应一个软件包，每条记录前三个字符表示软件包的状态标识，后边依次是软件包名称、版本号和简单描述 1234567891011121314151617181920212223# 第一个字符为期望值，它包括： * u 状态未知，这意味着软件包未安装，并且用户也未发出安装请求 * i 用户请求安装软件包 * r 用户请求卸载软件包 * p 用户请求清除软件包 * h 用户请求保持软件包版本锁定# 第二个字符为软件包当前状态，包括： * n 软件包未安装 * i 软件包安装并完成配置 * c 软件包以前安装过，现在删除了，但是它的配置文件还留在系统中 * u 软件包被解包，但还未配置 * f 试图配置软件包，但是失败了 * h 软件包安装，但是没有安装成功# 第三个字符为错误状态，包括 * 空 表示没有问题 * h 软件包被强制保持，因为有其他软件包依赖需求，无法升级 * r 软件包被破坏，可能需要重新安装才能正常使用（包括删除） * x 软件包被破坏，并且被强制保持 其他查询方式 123456789101112131415161718192021222324252627282930# 通配符模糊查询dpkg -l nano*# 查询系统中属于 nano 的文件dpkg --listfiles nano# 或dpkg-query -L nano# 查看软件nano的详细信息dpkg -s nano# 或dpkg-query -s nano# 查看系统中软件包状态，支持模糊查询dpkg -l# 或dpkg-query -l# 查看某个文件的归属包dpkg -S nano# 或dpkg-query -S nano# 列出与 nginx 相关包dpkg --get-selections | grep nginx# 删除 nginx 相关包sudo apt-get --purge remove nginxsudo apt-get --purge remove nginx-commonsudo apt-get --purge remove nginx-core 其他命令123456789101112131415161718192021222324252627282930313233343536373839apt-cache search # package 搜索包apt-cache show # package 获取包的相关信息，如说明、大小、版本等apt-get install # package 安装包，下载软件包及其所有的依赖包，同时进行包的安装或升级。如果某个包被设置了 hold，将不会被升级apt-get --reinstall install # package --reinstall 重新安装包apt-get -f install # package 强制安装，-f 即 --fix-missingapt-get remove # package 删除包以及任何依赖这个包的其他包apt-get remove --purge # package 删除包，同时删除配置文件等apt-get autoremove --purge # package 删除包及其依赖的软件包和配置文件等，只对6.10有效apt-get update # 更新源apt-get upgrade # 更新已安装的包为最新可用版本，不会安装新的或移除老的包，如果一个包改变了依赖关系而需要安装一个新的包，那么它将不会被升级，而是标识为 hold。建议同时使用 -u 选项，能看到哪些包将会被升级apt-get dist-upgrade # 升级系统，和 apt-get upgrade 类似，但是会安装和移除包来满足依赖关系，具有一定危险性apt-get dselect-upgrade # 使用 dselect 升级apt-cache depends # package 了解使用依赖apt-cache rdepends # package 了解某个具体的依赖，查看该包被哪些包依赖apt-cache showpkg # 显示 package 更多信息以及和其他包的关系apt-get build-dep # package 安装相关的编译环境apt-get source # package 下载该包的源码apt-get clean # 清理下载文件的存档apt-get autoclean # 只清理过时的包apt-get check # 检查是否有损坏的依赖dpkg -S filename # 查找 filename 属于哪个软件包apt-file search filename # 查找 filename 属于哪个软件包apt-file list packagename # 列出软件包的内容apt-file update # 更新 apt-file 的数据库dpkg --info packagename # 列出软件包解包后的包名称dpkg -l ## 列出当前系统中所有的包，可以和参数 less 一起使用在分屏查看（类似于 rpm -qa）dpkg -l | grep -i packagename # 查看系统中与 packagename 相关联得包dpkg -s # 查询已经安装的包的详细信息dpkg -L # 查询系统中已安装的软件包所安装的位置（类似于 rpm -ql）dpkg -S # 查询系统中某个文件属于哪个软件包（类似于 rpm -qf）dpkg -I # 查询 deb 包的详细信息，在一个软件包下载到本地之后看看是否需要安装dpkg -i # 手动安装软件包（这个命令不能解决软件包之前的依赖性问题），如果在安装某一个软件包的时候遇到了软件依赖的问题，可以用 apt-get -f install 在解决依赖性问题dpkg -r # 卸载软件包，不是完全的卸载，它的配置文件还在dpkg -P # 全部卸载（但是还是不能解决软件包的依赖性问题）dpkg -reconfigure # 重新配置dpkg-reconfigure --frontend=dialog debconf # 如果安装时选错了，可以改回来dpkg -c # 列出内容 参考资料 ubuntu 安装和查看已安装]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Analytics 在页面中的使用]]></title>
    <url>%2F2014%2F06%2F23%2F5677%2F</url>
    <content type="text"></content>
      <categories>
        <category>Google</category>
        <category>Analytics</category>
      </categories>
      <tags>
        <tag>Google Analytics</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C Primer Plus]]></title>
    <url>%2F2014%2F06%2F02%2F50389%2F</url>
    <content type="text"><![CDATA[第 1 章 概览 1.1 C 语言的起源1.2 使用 C 语言的理由1.2.1 设计特性1.2.2 高效性1.2.3 可移植性1.2.4 强大的功能和灵活性1.2.5 面向编程人员1.2.6 缺点1.3 C 语言的发展方向1.4 计算机工作的基本原理1.5 高级计算机语言和编译器1.6 使用 C 语言的 7 个步骤1.6.1 第 1 步：定义程序目标1.6.2 第 2 步：设计程序1.6.3 第 3 步 编写代码1.6.4 第 4 步：编译1.6.5 第 5 步：运行程序1.6.6 第 6 步：测试和调试程序1.6.7 第 7 步：维护和修改程序1.6.8 总结1.7 编程机制1.7.1 目标代码文件、可执行文件和库1.7.2 UNIX 系统1.7.3 Linux 系统1.7.4 集成开发环境（Windows 系统下）1.7.5 IBM PC 的 DOS 编译器1.7.6 Macintosh 上的 C1.8 语言标准1.8.1 第 1 个 ANSI/ISO C 标准1.8.2 C99 标准1.9 本书的组织结构1.10 本书体例1.10.1 字体1.10.2 屏幕输出1.11 总结1.12 复习题1.13 编程练习第 2 章 C 语言概述2.1 C 语言的一个简单实例2.2 实例说明2.2.1 第一遍 快速简介2.2.2 第二遍 程序细节2.3 一个简单程序的结构2.4 使程序可读的技巧2.5 更进一步2.5.1 说明2.5.2 多个声明2.5.3 乘法2.5.4 输出多个值2.6 多个函数2.7 调试2.7.1 语法错误2.7.2 语义错误2.7.3 程序状态2.8 关键字和保留标示符2.9 关键概念2.10 总结2.11 复习题2.12 编程练习第 3 章 数据和 C3.1 示例程序3.2 变量与常量数据3.3 数据：数据类型关键字3.3.1 整数类型与浮点数类型3.3.2 整数3.3.3 浮点数3.4 C 数据类型3.4.1 int 类型3.4.2 其他整数类型3.4.3 使用字符：char 类型3.4.4 _Bool 类型3.4.5 可移植的类型：inttypes.h3.4.6 float、double 和 long double 类型3.4.7 复数和虚数类型3.4.8 其他类型3.4.9 类型大小3.5 使用数据类型3.6 参数和易犯的错误3.7 另一个例子：转义序列3.7.1 过程分析3.7.2 刷新输出3.8 关键概念3.9 总结3.10 复习题3.11 编程练习第 4 章 字符串和格式化输入/输出4.1 前导程序4.2 字符串简介4.2.1 char 数组类型和空字符4.2.2 使用字符串4.2.3 strlen() 函数4.3 常量和 C 预处理器4.3.1 const 修饰符4.3.2 系统定义的明显常量4.4 研究和利用 printf() 和 scanf()4.4.1 printf() 函数4.4.2 使用 printf()4.4.3 printf() 的转换说明修饰符4.4.4 转换说明的意义4.4.5 使用 scanf()4.4.6 printf() 和 scanf() 的 * 修饰符4.4.7 printf 的用法提示4.5 关键概念4.6 总结4.7 复习题4.8 编程练习第 5 章 运算符、表达式和语句5.1 循环简介5.2 基本运算符5.2.1 赋值运算符：=5.2.2 加法运算符：+5.2.3 减法运算符：-5.2.4 符号运算符：- 和 +5.2.5 乘法运算符：*5.2.6 除法运算符：/5.2.7 运算符的优先级5.2.8 优先级和求值顺序5.3 其他运算符5.3.1 sizeof 运算符和 size_t 类型5.3.2 取模运算符：%5.3.3 增量和减量运算符：++ 和 –5.3.4 减量：–5.3.5 优先级5.3.6 不要太聪明5.4 表达式和语句5.4.1 表达式5.4.2 语句5.4.3 符合语句（代码块）5.5 类型转换5.6 带有参数的函数5.7 一个示例程序5.8 关键概念5.9 总结5.10 复习题5.11 编程练习第 6 章 C 控制语句：循环6.1 再探 while 循环6.1.1 程序注解6.1.2 C 风格的读循环6.2 while 语句6.2.1 终止 while 循环6.2.2 循环何时终止6.2.3 while：入口条件循环6.2.4 语法要点6.3 比较大小：使用关系运算符和表达式6.3.1 什么是真6.3.2 还有什么是真6.3.3 真值的问题6.3.4 新的 _Bool 类型6.3.5 关系运算符的优先级6.4 不确定循环与计数循环6.5 for 循环6.6 更多赋值运算符：+=、-=、*=、/= 和 %=6.7 逗号运算符6.8 退出条件循环：do while6.9 选择哪种循环6.10 嵌套循环6.10.1 程序讨论6.10.2 嵌套变化6.11 数组6.12 使用函数返回值的循环例子6.12.1 程序讨论6.12.2 使用具有返回值的函数6.13 关键概念6.14 总结6.15 复习题6.16 编程练习第 7 章 C 控制语句：分支和跳转7.1 if 语句7.2 在 if 语句中添加 else 关键字7.2.1 另一个例子：介绍 getchar() 和 putchar()7.2.2 ctype.h 系列字符函数7.2.3 多重选择 else if7.2.4 把 else 与 if 配对7.2.5 多层嵌套的 if7.3 获得逻辑性7.3.1 改变拼写法：iso646.h 头文件7.3.2 优先级7.3.3 求值的顺序7.3.4 范围7.4 一个统计字数的程序7.5 条件运算符 ?:7.6 循环辅助手段：continue 和 break7.6.1 continue 语句7.6.2 break 语句7.7 多重选择：switch 和 break7.7.1 使用 switch 语句7.7.2 只读取一行的首字符7.7.3 多重标签7.7.4 switch 和 if else7.8 goto 语句7.9 关键概念7.10 总结7.11 复习题7.12 编程练习第 8 章 字符输入/输出和输入确认8.1 单字符 I/O：getchar() 和 putchar()8.2 缓冲区8.3 终止键盘输入8.3.1 文件、流和键盘输入8.3.2 文件结尾8.4 重定向和文件8.5 创建一个更友好的用户界面8.5.1 使用缓冲输入8.5.2 混合输入数字和字符8.6 输入确认8.6.1 分析程序8.6.2 输入流和数值8.7 菜单浏览8.7.1 任务8.7.2 使执行更顺利8.7.3 混合字符和数值输入8.8 关键概念8.9 总结8.10 复习题8.11 编程练习第 9 章 函数9.1 函数概述9.1.1 编写和使用一个简单的函数9.1.2 程序分析9.1.3 函数参数9.1.4 定义带有参数的函数：形式参量9.1.5 带参数函数的原型声明9.1.6 调用带有参数的函数：实际参数9.1.7 黑盒子观点9.1.8 使用 return 从函数中返回一个值9.1.9 函数类型9.2 ANSI C 的函数原型9.2.1 产生的问题9.2.2 ANSI 的解决方案9.2.3 无参数和不确定参数9.2.4 函数原型的优点9.3 递归9.3.1 递归的使用9.3.2 递归的基本原理9.3.3 尾递归9.3.4 递归和反向计算9.3.5 递归的优缺点9.4 多源代码文件程序的编译9.4.1 UNIX9.4.2 Linux9.4.3 DOS 命令行编译器9.4.4 Windows 和 Macintosh 编译器9.4.5 头文件的使用9.5 地址运算符：&amp;9.6 改变调用函数中的变量9.7 指针简介9.7.1 间接运算符：*9.7.2 指针声明9.7.3 使用指针在函数间通信9.8 关键概念9.9 总结9.10 复习题9.11 编程练习第 10 章 数组和指针10.1 数组10.1.1 初始化10.1.2 指定初始化项目（C99）10.1.3 为数组赋值10.1.4 数组边界10.1.5 指定数组大小10.2 多维数组10.2.1 初始化二维数组10.2.2 更多维的数组10.3 指针和数组10.4 函数、数组和指针10.4.1 使用指针参数10.4.2 评论：指针和数组10.5 指针操作10.6 保护数组内容10.6.1 对形式参量使用 const10.6.2 有关 const 的其他内容10.7 指针和多维数组10.7.1 指向多维数组的指针10.7.2 指针兼容性10.7.3 函数和多维数组10.8 变长数组（VLA）10.9 复合文字10.10 关键概念10.11 总结10.12 复习题10.13 编程练习第 11 章 字符串和字符串函数11.1 字符串表示和字符串 I/O11.1.1 在程序中定义字符串11.1.2 指针和字符串11.2 字符串输入11.2.1 创建存储空间11.2.2 gets() 函数11.2.3 fgets() 函数11.2.4 scanf() 函数11.3 字符串输出11.3.1 puts() 函数11.3.2 fputs() 函数11.3.3 printf() 函数11.4 自定义字符串输入/输出函数11.5 字符串函数11.5.1 strlen() 函数11.5.2 strcat() 函数11.5.3 strncat() 函数11.5.4 strcmp() 函数11.5.5 strncmp() 函数11.5.6 strcpy() 和 strncpy() 函数 书名《C Primer Plus（第五版）》 书号 ISBN 7-115-13022-1/TP 4411 Stephen Prata 著，云巅工作室 译 清华大学出版社 2005 年 2 月第 1 版第 1 次印刷]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统原理、设计与应用]]></title>
    <url>%2F2014%2F05%2F31%2F43045%2F</url>
    <content type="text"><![CDATA[第 1 章 操作系统简介1.1 什么是操作系统操作系统是一个或多个程序的集合，其提供了一系列的服务，是应用程序与计算机硬件之间的接口，其在多个进程中分配和管理资源的共享。 1.1.1 资源管理者1.1.2 服务提供者1.1.3 虚拟机1.2 操作系统的功能1.2.1 进程当管理 CPU 资源时，通常根据正在运行的程序来进行管理。在执行时，我们将这些程序称之为进程（processes）。为了支持进程，操作系统通常提供如下服务： 创建进程 终止进程 改变进程优先级 提供进程间通信 提供进程同步 在内部，操作系统负责调度（scheduling）和上下文切换（context switching）。调度程序是一种机制，通过这种机制，操作系统选择下一个将要运行的进程。一个进程将 CPU 控制权转交给另一个进程的实际操作称为上下文切换。 1.2.2 存储器系统的性能更依赖于存储管理子系统的行为。存储管理的核心是对分配和释放内存的请求做出响应。建立典型存储管理服务集基础的功能如下： 直接请求额外内存 直接请求内存（当创建新进程时等情况下） 释放内存并返还给操作系统 请求进程间得共享内存区 在大多数环境中，我们要满足更多的内存请求，而不止计算机上实际安装的内存。这种过度分配通常称为虚拟存储器（virtual memory）。 1.2.3 I/O 设备在管理 I/O 设备中，通常为进程提供各种各样的服务，这些服务通常包括： 向进程开放设备或附加设备 从设备中读取数据 往设备写入数据 关闭与释放设备 对合适设备提供独占访问 提供各种各样的特定功能，如复卷磁带和设置串行线路传输速率 1.2.4 文件系统我们使用 I/O 设备来支持的另一个功能是文件系统（file system）。在大多数情况下，文件系统支持的请求集与 I/O 设备子系统相似： 打开文件 读文件 写文件 关闭文件 在文件中搜索随机位置 读取文件元数据（如文件名、大小、所有者、保护码等） 修改已选中的元数据 1.2.5 安全性操作系统绝不允许任何进程终止另一个进程。除了后台的强制运行机制之外，应用程序能请求的服务如下： 设置安全性策略 查询安全性策略 验证自身的远程系统 侦听远程系统来验证自身 加密/解密消息，特别是经由网络的消息 1.2.6 联网在大多数情况下，联网支持是 I/O 子系统的另外一个应用。I/O 设备除了负责数据位在系统的输入输出之外，操作系统还能标准的实现协议栈。将网络协议设计成若干层是很常见的，每层封装其它层。和 I/O 编程一样，有必要让操作系统负责这些协议。从应用程序的角度来看，网络服务应该包括： 与远程服务建立连接 从远程客户端侦听连接 往远程系统发送消息 从远程系统接收消息 关闭与远程系统的连接 1.2.7 用户接口与只处理硬件和操作系统的其他功能相比，处理用户相关的问题时，事情往往变得更复杂，因此，用户接口是需要研究的一个大主题。 1.3 操作系统的历史1.3.1 裸机1.3.2 批处理操作系统作业可以以某种交互会话的形式进行提交，提交的作业仍作为批的一部分运行，以这种方式操作的操作系统称为批处理操作系统（batch operating system）。批处理操作系统突破了一个用户这个限制。尽管在任何时刻，计算机只为一个用户工作，但在使用所有计算设备的过程中有许多用户存在。 1.3.3 分时操作系统分时操作系统（time-sharing operating system）、多道程序操作系统（multiprogramming operating system）或多任务操作系统（multitasking operating system）。这类新型操作系统突破了一个程序这个限制。 1.3.4 分布式操作系统分布式操作系统（distributed operating system）。一些具有多个 CPU 的计算机共享单一物理内存和相同的 I/O 设备，我们将这类计算机称为对称多处理（symmetric multiprocessing，SMP）系统。 1.4 组织操作系统的技术1.4.1 单块设计单块（monolithic）设计。一般认为这类设计的特点是缺乏任何其他的组织形式，但在现实中，单块设计恰好是将设计组织为单个程序。与任何程序一样，这样的设计具有良好的组织结构。大多数操作系统是沿着这个思路进行组织的。 1.4.2 分层设计分层设计的基本思想是：每层增加抽象层，它建立再较低层提供的函数之上。Comer 教授开发的 XINU 操作系统是遵循分层设计的很好例子。 1.4.3 微内核设计一些设计师认为应该将许多传统的核心功能从内核移到其他进程中去，而这些进程由内核进行管理。原则上，这将使内核更小、更容易编写和维护。在这种设计中，在单块内核中通过函数调用完成的许多工作都是要使用微内核的消息传递来处理的。微内核设计影响组件间的通信，本可以通过参数传递或共享变量进行的通信都必须由消息进行传递。微内核操作系统设计的另一个挑战是安全性问题。 微内核设计很好的示例包括 Tanenbaum 教授的 MINIX、Hurd（部分的 GNU 环境来自软件基金会）和 Mach 操作系统，在一些其他用途中，Mash 教授作为 Mac OS X 的基础用于 Apple Macintosh。虽然 Inferno 不是围绕微内核构建的，但通过示例，我们会看到它是如何将一些传统功能转移用户进程的。 1.4.4 虚拟机设计虚拟机操作系统的主要功能是提供硬件有许多副本的错觉。这种做法的典型例子是 IBM 的 VM 操作系统。使用户能同时运行多个操作系统的产品：商业产品 VMware，开源项目 Xen 等。另外一种方法是模拟，在软件中模拟一个完整的计算机，并在此模拟机上运行操作系统。例如：用来运行并行操作系统的 QEMU。 1.5 引导系统从硬件到我们拥有运行操作系统的过程称为引导（bootstrapping）。虽然现在引导这个术语已经很常用，但许多制造商还使用其他术语来代替引导，例如：冷启动（cold start）、静启动（dead start）和初始程序加载（initial program load，IPL）。 有三种典型的方法解决引导问题： * 1.6 系统调用1.6.1 系统调用示例1.6.2 系统调用机制1.7 本章小结1.8 练习第 2 章 操作系统示例2.1 兼容分时系统2.1.1 组织结构2.1.2 引导2.2 多路信息和计算服务2.2.1 组织结构2.2.2 系统调用2.3 RT-112.3.1 组织结构2.4 第 6 版 UNIX2.4.1 组织结构2.4.2 系统调用2.5 虚拟内存系统2.5.1 组织结构2.5.2 引导2.5.3 系统调用2.6 4.3 BSD2.6.1 组织结构2.6.2 系统调用2.7 Windows NT2.7.1 组织结构2.8 TinyOS2.8.1 组织结构2.9 Xen2.9.1 组织结构2.10 本章小结2.11 练习第 3 章 Inferno 的结构与初始化3.1 Inferno 的起源3.2 基本概念3.3 组织结构3.3.1 基本体系结构3.3.2 源代码组织结构3.4 初始化3.4.1 启动 Inferno3.4.2 宿主操作系统的特定初始化3.4.3 与宿主操作系统无关的初始化3.4.4 启动分时3.5 系统调用3.6 本章小结3.7 练习第 4 章 Linux 的结构与初始化4.1 Linux 的起源4.2 组织结构4.2.1 基本体系结构4.2.2 模块4.2.3 源代码组织结构4.3 初始化4.3.1 引导4.3.2 特定处理器初始化4.3.3 与处理器无关的初始化4.3.4 启动分时4.3.5 初始化管理级的初始化4.4 系统调用4.4.1 处理应用方得系统调用4.4.2 处理内核方的系统调用4.5 本章小结4.6 练习第 5 章 进程管理原理5.1 进程的概念5.2 实现进程5.2.1 进程操作5.2.2 进程状态5.2.3 进程表5.3 线程5.4 调度5.4.1 先来先服务5.4.2 最短作业优先5.4.3 轮转法5.4.4 优先级调度5.4.5 调整调度参数5.4.6 两级调度5.4.7 实时调度5.4.8 嵌入式系统的调度5.5 上下文切换5.6 进程的创建与终止5.7 临界区5.7.1 中断控制5.7.2 原子操作指令5.7.3 Peterson 算法5.7.4 信号量5.7.5 管程5.7.6 消息传递5.7.7 示例5.8 死锁5.8.1 充分必要条件5.8.2 处理死锁5.9 本章小结5.10 练习第 6 章 进程管理示例6.1 CTSS6.1.1 进程状态6.1.2 系统调用6.1.3 调度6.2 Multics6.2.1 系统调用6.2.2 进程状态6.2.3 调度6.3 RT-116.3.1 系统调用6.3.2 进程状态6.3.3 进程表6.3.4 调度6.4 第 6 版 UNIX6.4.1 系统调用6.4.2 进程状态6.4.3 进程表6.4.4 调度6.5 4.3 BSD6.5.1 系统调用6.5.2 进程状态与进程表6.5.3 调度6.6 VMS6.6.1 系统调用6.6.2 进程状态6.6.3 调度6.7 Windows NT6.7.1 系统调用6.7.2 进程状态6.7.3 进程表与线程表6.7.4 调度6.8 TinyOS6.9 Xen6.10 本章小结6.11 练习第 7 章 Inferno 中的进程管理7.1 Inferno 中的进程7.2 进程的状态7.2.1 内核进程7.2.2 用户进程7.3 进程的数据结构7.3.1 内核进程表7.3.2 内核进程表项7.3.3 用户进程表7.3.4 用户进程表项7.4 进程的创建7.4.1 解释进程创建指令7.4.2 实现进程创建7.5 进程的终止7.6 进程调度7.6.1 插入就绪表7.6.2 从就绪表中删除7.6.3 分时7.6.4 运行时间片7.7 本章小结7.8 练习第 8 章 Linux 中的进程管理8.1 进程与线程8.1.1 Linux 中的内核线程8.1.2 进程间的关系8.2 系统调用8.3 进程状态8.4 进程表8.5 进程的创建8.5.1 处理系统调用8.5.2 创建进程8.5.3 特定体系结构的步骤8.6 进程调度8.6.1 优先级8.6.2 队列结构8.6.3 时钟计时单元8.6.4 调度程序8.7 本章小结练习第 9 章 存储管理原理9.1 存储层次结构9.2 地址变换9.2.1 基址/上下界寄存器9.2.2 分段存储9.2.3 分页存储9.3 存储相关的服务9.4 存储布局9.5 内存分配技术9.5.1 空闲空间管理9.5.2 碎片9.5.3 分区9.5.4 选择策略9.5.5 伙伴系统管理9.6 过度分配技术9.6.1 交换9.6.2 段交换9.6.3 分页9.6.4 段页式9.6.5 内存映射文件9.6.6 写时复制9.6.7 性能问题9.7 嵌入式系统的存储管理9.8 本章小结练习第 10 章 存储管理示例10.1 CTSS10.2 Multics10.2.1 存储相关的系统调用10.2.2 存储布局10.2.3 段式管理与页式管理10.3 RT-1110.3.1 存储相关的系统调用10.3.2 存储布局10.3.3 USR 与 KMON 交换10.4 第 6 版 UNIX10.4.1 存储相关的系统调用10.4.2 存储布局10.4.3 空闲空间管理10.4.4 分配10.4.5 交换10.5 4.3 BSD10.5.1 存储相关的系统调用10.5.2 存储布局10.5.3 空闲空间管理10.5.4 交换与页替换10.6 VMS10.6.1 页表10.6.2 存储布局10.6.3 空闲空间管理10.6.4 交换与页替换10.6.5 存储相关的系统调用10.7 Windows NT10.7.1 系统调用10.7.2 存储布局10.7.3 页式管理10.8 TinyOS10.9 Xen10.9.1 超级调用10.9.2 存储布局10.9.3 页式管理10.10 本章小结练习第 11 章 Inferno 中的存储管理11.1 概述11.2 存储布局11.3 存储管理的数据结构11.3.1 存储池11.3.2 存储块11.4 存储管理的实现11.4.1 分配内存11.4.2 从树中删除空闲块11.4.3 释放内存11.4.4 把空闲块插入树中11.5 垃圾收集11.5.1 堆结构11.5.2 引用计数11.5.3 并发垃圾收集器11.5.4 实现并发垃圾收集11.6 本章小结11.7 练习第 12 章 Linux 中的存储管理12.1 存储布局12.2 系统调用12.3 分配机制12.3.1 管理区页的分配12.3.2 slab 分配器12.3.3 内核的内存分配12.4 页管理12.4.1 页表12.4.2 页替换12.5 存储管理的数据结构12.5.1 进程分配的表示12.5.2 虚拟内存区表示12.6 存储管理的实现12.6.1 处理分配系统调用12.6.2 增加区域12.6.3 处理缺页12.6.4 解决缺页错误12.6.5 处理新页面12.7 本章小结12.8 练习第 13 章 I/O 设备管理原理13.1 I/O 子系统的要素13.2 I/O 设备的硬件特性13.2.1 磁盘驱动器13.2.2 串口通信13.2.3 控制器接口技术13.3 I/O 设备类型13.3.1 通信设备与存储设备13.3.2 流设备与块设备13.4 I/O 子系统设计的目标13.5 I/O 设备服务13.6 设备驱动器的结构13.7 设备管理技术13.7.1 缓冲区13.7.2 交叉存取13.7.3 电梯算法13.7.4 RAID13.7.5 水位标志13.7.6 人工输入处理13.7.7 伪设备13.8 本章小结13.9 练习第 14 章 I/O 设备管理示例14.1 CTSS14.2 Multics14.3 RT-1114.4 第 6 版 UNIX14.5 4.3 BSD14.6 VMS14.7 Windows NT14.8 TinyOS14.9 Xen14.10 本章小结14.11 练习第 15 章 Inferno 中的 I/O 设备15.1 设备驱动程序结构15.2 并行端口支持15.2.1 为写请求服务15.2.2 写入单字节15.3 键盘支持15.3.1 初始化键盘控制器15.3.2 处理键盘中断15.4 IDE 磁盘支持15.4.1 处理 I/O 请求15.4.2 初始化 IDE 控制器操作15.4.3 处理 IDE 控制器中断15.5 本章小结15.6 练习第 16 章 Linux 中的 I/O 设备16.1 块请求支持16.2 两半中断处理程序结构16.3 并行端口驱动程序16.3.1 处理系统调用16.3.2 选择合适的底层写入16.3.3 从缓冲区写入字节16.3.4 配置控制器16.4 软盘驱动程序16.4.1 处理请求16.4.2 调度软盘操作16.4.3 执行软盘操作16.4.4 启动命令16.4.5 准备数据传输16.4.6 控制器编程16.4.7 处理软盘中断16.4.8 完成软盘操作本章小结练习第 17 章 文件系统原理17.1 文件系统服务17.1.1 共享与独占访问17.1.2 访问模式17.1.3 文件结构17.1.4 元数据17.1.5 内存映射文件17.2 总体文件系统设计17.2.1 文件系统形式17.2.2 主要数据结构17.3 名称空间17.3.1 驱动器指示符17.3.2 账户说明符17.3.3 分层命名17.3.4 文件扩展名17.3.5 文件版本17.3.6 特殊文件与目录17.3.7 相对路径名与绝对路径名17.4 管理存储空间17.4.1 文件系统元数据17.4.2 数据单位17.4.3 空闲空间管理17.4.4 普通文件17.4.5 稀疏文件17.4.6 分支17.4.7 目录17.4.8 别名17.5 一致性检测17.6 日志与日志结构的文件系统17.7 块高速缓存17.8 本章小结17.9 练习第 18 章 文件系统示例18.1 CTSS18.1.1 第一个 CTSS 文件系统18.1.2 第二个 CTSS 文件系统18.2 Multics18.3 RT-1118.4 第 6 版 UNIX18.5 4.3 BSD18.6 VMS18.7 Windows NT18.8 本章小结18.9 练习第 19 章 Inferno 中的文件系统19.1 文件服务器的作用19.1.1 Styx 协议19.1.2 内置内核文件系统19.1.3 用户空间文件服务器19.2 根设备服务器19.2.1 提供命名服务19.2.2 遍历根服务器树19.2.3 从根服务器读取19.3 通用 Styx 消息处理程序19.3.1 创建目录项19.3.2 生成命名19.3.3 遍历目录树19.4 本地 Inferno 文件系统19.4.1 初始化19.4.2 主服务进程19.4.3 处理 Styx 请求19.4.4 遍历目录树19.4.5 搜索目录19.4.6 读文件19.4.7 磁盘上的数据结构19.4.8 读取目录项19.4.9 读取文件块19.4.10 查找文件块19.4.11 处理间接块19.4.12 从缓冲区高速缓存中获取19.5 本章小结19.6 练习第 20 章 Linux 中的文件系统20.1 虚拟文件系统20.1.1 超级块20.1.2 i- 节点20.1.3 目录项20.1.4 文件20.2 EXT3 文件系统20.3 EXT3 的磁盘结构20.3.1 EXT3 超级块20.3.2 EXT3-I 节点20.3.3 EXT3 目录项20.4 EXT3 命令查找20.4.1 遍历路径20.4.2 通用目录查找（第一部分）20.4.3 通用目录查找（第二部分）20.4.4 EXT3 目录查找20.4.5 EXT3 目录搜索20.4.6 EXT3 目录块搜索20.5 写入文件20.5.1 Linux 的写入系统调用20.5.2 写入通用文件20.5.3 写入 EXT3 文件20.6 在 EXT3 中定位文件块20.5.1 Linux 的写入系统调用20.5.2 写入通用文件20.5.3 写入 EXT3 文件20.6 在 EXT3 中定位文件块20.6.1 标识间接块20.6.2 读取间接块20.7 本章小结20.8 练习第 21 章 操作系统安全原理21.1 用户认证21.1.1 用户名与密码21.1.2 散列函数加密21.1.3 回调21.1.4 挑战/响应认证21.1.5 一次性密码21.1.6 生物认证21.2 基本资源保护21.2.1 特权用户21.2.2 访问 CPU 特性21.2.3 内存访问21.2.4 简单的代码保护21.2.5 访问控制列表21.2.6 权能21.3 威胁类型21.3.1 中间人攻击21.3.2 特洛伊木马21.3.3 陷阱门21.3.4 逻辑/时间炸弹21.3.5 病毒21.3.6 蠕虫21.3.7 隐蔽通道21.3.8 拒绝服务21.4 橙皮书分级21.4.1 D 组21.4.2 C 组21.4.3 B 组21.4.4 A 组21.5 加密21.5.1 对称加密21.5.2 公钥加密学21.6 Multics 的保护环21.7 Inferno 的安全21.8 Linux 的安全21.9 本章小结21.10 练习第 22 章 分布式系统原理22.1 基本概念22.1.1 资源共享22.1.2 同步操作22.1.3 一致性22.1.4 分布式互斥22.1.5 容错22.1.6 自稳定22.2 处理器共享22.2.1 对称多处理22.2.2 集群22.2.3 网格22.3 分布式时钟22.3.1 逻辑时钟22.3.2 物理时钟22.4 选举算法22.4.1 欺负算法22.4.2 环算法22.5 本章小结22.6 练习附录 A 便于宿主 InfernoA.1 建立配置A.2 编译器与开发工具A.3 PATH 环境变量A.4 其他环境变量A.5 编译系统A.6 运行新版本A.7 小结附录 B 编译本地 InfernoB.1 建立配置B.2 创建工具链B.3 创建引导程序代码B.4 建立内核配置B.5 生成加载程序配置B.6 创建内核镜像B.7 生成软盘镜像B.8 运行新内核B.9 小结 书名《操作系统原理、设计与应用》 英文名 Principle of Operating Systems：Design and Applications 书号 ISBN 978-7-302-22318-4 Brian L. Stuart 著，葛秀慧 田浩 刘展威 等译 清华大学出版社 2010 年 6 月第 1 版第 1 次印刷]]></content>
      <categories>
        <category>Operation System</category>
      </categories>
      <tags>
        <tag>Operation System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse 配置及优化]]></title>
    <url>%2F2014%2F04%2F30%2F12169%2F</url>
    <content type="text"><![CDATA[Windows 环境配置 HOME JAVA_HOME PATH eclipse 插件配置安装方式：Help -&gt; Install New Software -&gt; Add -&gt; Archive，或者通过 Help -&gt; Eclipse Marketplace 来安装 安装 Eclipse Color Theme 插件，配置编辑器样式 StartExplorer，跨平台的 eclipse 快捷打开文件所在文件夹的插件 Subversive - SVN Team Provider 插件 EGit - Git Team Provider 插件，用于 git 管理 Enide Studio 插件，Node.js，JavaScript 等开发插件 UML Designer (Eclipse Kepler version) 3.0，UML 设计插件 eclipse 加速 validation 中，关闭 build 下的所有校验（可以保留Classpath Dependency Validator），只开启 manual 手工校验 Plug-in Development &gt; Target Platform &gt; plug-in 中关闭无关或暂且不用的 plug-in Preferences &gt; General &gt; Startup and Shutdown 取消无关或暂且不用的 plug-ins 将 Preferences 中的 Dashboard 调整为不随 eclipse 启动 编码配置 Preferences &gt; General &gt; Workspace 中 Text file encoding 改为 UTF-8 Preferences &gt; General &gt; Content Types 中更改 Text 下的 Java Properties File、Java Source File、Javascript Source File、JSP 为 UTF-8，其余 content types 的编码可以根据需要进行调整 字体设置 Preferences &gt; General &gt; Appearance &gt; Colors and Fonts 中 更改 Basic 下的 Text Font，建议字体：Consolas、Courier new、Inconsolata，脚本改为：中欧字符 快捷键设置 Preferences &gt; General &gt; Keys 中 Content Assist 快捷键更改为 alt + / 标签装饰 Preferences &gt; General &gt; Appearance &gt; Label Decorations 设置各种标签装饰 Console 输出 Preferences &gt; Run/Debug &gt; Console 设置 Console buffer size(characters) 为 800000 编辑区配置 Preferences &gt; General &gt; Editors &gt; Text Editors （或者在文件编辑区域左侧边，点击右键），勾选 Show Line Numbers 开启行号显示 拼写检查 Preferences &gt; General &gt; Editors &gt; Text Editors &gt; Spelling 中取消勾选 Enable spell checking，关闭拼写检查 代码风格及代码模板 Preferences &gt; Java &gt; Code Style &gt; Formatter 中配置 Java 代码风格 Preferences &gt; Java &gt; Code Style &gt; Code Templates 中勾选 Automatically add comments for new methods and types 开启 comments Preferences &gt; Java &gt; Editor &gt; Templates 中配置代码模板 Preferences &gt; XML &gt; XML Files &gt; Editors 中 Formatting 块中 Line width（行宽） 更改为合适的值，例如：100 常见警告解决办法 git 工具未安装：安装 git http://git-scm.com/ 工具，按说明配置 System Settings；或者取消警告消息 12# 错误消息EGit couldn't detect the installation path "gitPrefix" of native Git. Hence EGit can't respect system level Git settings which might be configured in $&#123;gitPrefix&#125;/etc/gitconfig under the native Git installation directory. The most important of these settings is core.autocrlf. Git for Windows by default sets this parameter to true in this system level configuration. The Git installation location can be configured on the Team &gt; Git &gt; Configuration preference page's 'System Settings' tab. This warning can be switched off on the Team &gt; Git &gt; Confirmations and Warnings preference page. HOME 环境变量未设置：设置 HOME 环境变量；或者取消告警消息 123456# 错误消息Warning: The environment variable HOME is not set. The following directory will be used to store the Gituser global configuration and to define the default location to store repositories: 'C:\Documents and Settings\Wizard'. If this isnot correct please set the HOME environment variable and restart Eclipse. Otherwise Git for Windows andEGit might behave differently since they see different configuration options.This warning can be switched off on the Team &gt; Git &gt; Confirmations and Warnings preference page. pom.xml 文件未设置 project.build.sourceEncoding 属性 12# 错误消息Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent! 1234&lt;!-- 解决办法：在 pom.xml 的 project 节点下增加如下内容 --&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;&lt;/properties&gt; 常见错误解决办法]]></content>
      <categories>
        <category>Eclipse</category>
      </categories>
      <tags>
        <tag>Eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 11.04 下使用 Nexus 搭建 Maven 仓库]]></title>
    <url>%2F2014%2F04%2F30%2F62995%2F</url>
    <content type="text"><![CDATA[仓库管理器优点 时间及带宽的节省，加速组织内部项目构建。 可控制 Maven 下载的机制，为组织的总体架构和政策实施提供了依赖方面的控制（例如，避免不小心添加 GPL 许可证的依赖等等）。 为开发人员和部门之间提供一种共享内部项目构件的快照版本和发布版本的机制，避免组织内的每个成员单独下载并构建各自的内部项目。 Java 下载及安装 根据需求，在 http://www.oracle.com/technetwork/java/javase/downloads/index.html 下载对应 JDK 版本。或者通过 wget 命令将下载中的 JDK 链接地址通过命令行下载。 将 JDK 压缩包复制至指定目录，解压 JDK 压缩包，并配置环境变量。 1234567891011121314151617181920212223242526272829# 创建 Java JDK 目标目录sudo mkdir -p /usr/lib/java# 将 JDK 压缩包复制至 /usr/lib/java 目录sudo cp jdk-7u55-linux-x64.tar.gz /usr/lib/java# 解压 JDKcd /usr/lib/javasudo tar zxvf jdk-7u55-linux-x64.tar.gz# 给当前用户赋予可执行权限sudo chmod u+x jdk1.7.0_55# Windows 下可以采用 gedit 编辑器（或其他编辑器）配置环境变量sudo gedit /etc/profile# 或类 Unix 环境下，采用 nano 或 vi 等编辑器配置环境变量sudo nano /etc/profile# 将如下内容添加至文件中，保存并关闭文件 # JDK environment export JAVA_HOME=/usr/lib/java/jdk1.7.0_55 export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH# 重新登陆使配置生效，或执行以下命令使配置生效source /etc/profile# 测试 JAVA 版本java -version Nexus 下载及安装进入 Nexus 下载页面，下载安装 Nexus，并配置环境。 123456789101112131415161718192021222324# 下载 nexus oss（nexus pro 收费）当前版本 2.8.0wget http://www.sonatype.org/downloads/nexus-latest-bundle.zip# 复制至/usr/lcoalsudo cp nexus-latest-bundle.zip /usr/local# 解压unzip nexus-latest-bundle.zip# 创建软连接ln -s nexus-2.8.0-05 nexus# 编辑 /etc/profile 文件，配置 Nexus 环境sudo vi /etc/profile# 在文件中加入如下内容 # Nexus environment export NEXUS_HOME=/usr/local/nexus# 重新登陆，或执行以下命令使配置生效source /etc/profile# 为 nexus-2.8.0_05 及 sonatype-work 赋权sudo chmod -R a+rwx nexus-2.8.0_05sudo chmod -R a+rwx sonatype-work 启动 Nexus简单启动 nexus 12345678# console 启动cd /usr/local/nexus./bin/nexus console# 后台启动./bin/nexus start# 查看日志tail -f logs/wrapper.log 以服务启动 nexus 123456789101112# 假设 nexus 用户具有运行 nexus 服务的权限# 复制 $NEXUS_HOME/bin/nexus 到 /etc/init.d/nexus，或创建一个symlinksudo ln -s $NEXUS_HOME/bin/nexus /etc/init.d/nexus# 给/etc/init.d/nexus 脚本赋可执行权限chmod 755 /etc/init.d/nexus# 更改 /etc/init.d/nexus 脚本中的内容 1. 设置 NEXUS_HOME="/usr/local/nexus" 2. 设置 RUN_AS_USER=nexus 或其他具有权限的用户来执行 Nexus 服务，避免使用 root 来运行 Nexus 服务 3. 参考资料 Repository Management with Nexus Configuring Nexus as a Service]]></content>
      <categories>
        <category>Tools</category>
        <category>Nexus</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Nexus</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2F2014%2F04%2F10%2F19568%2F</url>
    <content type="text"><![CDATA[初级用户：以下是初学者常用的一些命令。 ls 命令ls 命令是列出目录内容(List Directory Contents)的意思。运行它就是列出文件夹里的内容，可能是文件也可能是文件夹。 1234567891011121314151617181920212223242526272829303132333435363738394041424344root@tecmint:~# lsAndroid-Games MusicPictures PublicDesktop Tecmint.comDocuments TecMint-SyncDownloads Templates# “ls -l”命令以详情模式(long listing fashion)列出文件夹的内容。root@tecmint:~# ls -ltotal 40588drwxrwxr-x 2 ravisaive ravisaive 4096 May 8 01:06 Android Gamesdrwxr-xr-x 2 ravisaive ravisaive 4096 May 15 10:50 Desktopdrwxr-xr-x 2 ravisaive ravisaive 4096 May 16 16:45 Documentsdrwxr-xr-x 6 ravisaive ravisaive 4096 May 16 14:34 Downloadsdrwxr-xr-x 2 ravisaive ravisaive 4096 Apr 30 20:50 Musicdrwxr-xr-x 2 ravisaive ravisaive 4096 May 9 17:54 Picturesdrwxrwxr-x 5 ravisaive ravisaive 4096 May 3 18:44 Tecmint.comdrwxr-xr-x 2 ravisaive ravisaive 4096 Apr 30 20:50 Templates# "ls -a"命令会列出文件夹里的所有内容，包括以"."开头的隐藏文件。root@tecmint:~# ls -a. .gnupg .dbus .goutputstream-PI5VVW .mission-control.adobe deja-dup .grsync .mozilla .themes.gstreamer-0.10 .mtpaint .thumbnails .gtk-bookmarks .thunderbird.HotShots .mysql_history .htaccess .apport-ignore.xml .ICEauthority .profile .bash_history .icons .bash_logout .fbmessenger.jedit .pulse .bashrc .liferea_1.8 .pulse-cookie .Xauthority .gconf .local .Xauthority.HGHVWW .cache.gftp .macromedia .remmina .cinnamon .gimp-2.8.ssh .xsession-errors .compiz .gnome teamviewer_linux.deb .xsession-errors.old .config .gnome2 .zoncolor# 注意：在 Linux 中，文件以“.”开头的就是隐藏文件，并且每个文件，文件夹，设备或者命令都是以文件对待。ls -l 命令输出： 1. d (代表了是目录)。 2. rwxr-xr-x 是文件或者目录对所属用户，同一组用户和其它用户的权限。 3. 上面例子中第一个ravisaive 代表了文件文件属于用户ravisaive 4. 上面例子中的第二个ravisaive代表了文件文件属于用户组ravisaive 5. 4096 代表了文件大小为4096字节。 6。 May 8 01:06 代表了文件最后一次修改的日期和时间. 7. 最后面的就是文件/文件夹的名字 lsblk 命令“lsblk”就是列出块设备。除了 RAM 外，以标准的树状输出格式，整齐地显示块设备。 1234567891011121314151617181920212223242526root@tecmint:~# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 232.9G 0 disk├─sda1 8:1 0 46.6G 0 part /├─sda2 8:2 0 1K 0 part├─sda5 8:5 0 190M 0 part /boot├─sda6 8:6 0 3.7G 0 part [SWAP]├─sda7 8:7 0 93.1G 0 part /data└─sda8 8:8 0 89.2G 0 part /personalsr0 11:0 1 1024M 0 rom# “lsblk -l”命令以列表格式显示块设备(而不是树状格式)。root@tecmint:~# lsblk -lNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 232.9G 0 disksda1 8:1 0 46.6G 0 part /sda2 8:2 0 1K 0 partsda5 8:5 0 190M 0 part /bootsda6 8:6 0 3.7G 0 part [SWAP]sda7 8:7 0 93.1G 0 part /datasda8 8:8 0 89.2G 0 part /personalsr0 11:0 1 1024M 0 rom# 注意：lsblk 是最有用和最简单的方式来了解新插入的 USB 设备的名字，特别是当你在终端上处理磁盘/块设备时。 md5sum 命令“md5sum”就是计算和检验 MD5 信息签名。md5 checksum(通常叫做哈希)使用匹配或者验证文件的文件的完整性，因为文件可能因为传输错误，磁盘错误或者无恶意的干扰等原因而发生改变。 12345root@tecmint:~# md5sum teamviewer_linux.deb47790ed345a7b7970fc1f2ac50c97002 teamviewer_linux.deb# 注意：用户可以使用官方提供的和 md5sum 生成签名信息匹对以此检测文件是否改变。Md5sum 没有 sha1sum 安全，这点我们稍后讨论。 dd命令“dd”命令代表了转换和复制文件。可以用来转换和复制文件，大多数时间是用来复制 iso 文件(或任何其它文件)到一个 usb 设备(或任何其它地方)中去，所以可以用来制作 USB 启动器。 12345root@tecmint:~# dd if=/home/user/Downloads/debian.iso of=/dev/sdb1 bs=512M; sync# 注意：在上面的例子中，usb 设备就是 sdb1（你应该使用 lsblk 命令验证它，否则你会重写你的磁盘或者系统），请慎重使用磁盘的名，切忌。# dd 命令在执行中会根据文件的大小和类型 以及 usb 设备的读写速度，消耗几秒到几分钟不等。 uname 命令“uname”命令就是 Unix Name 的简写。显示机器名，操作系统和内核的详细信息。 123456789101112root@tecmint:~# uname -aLinux tecmint 3.8.0-19-generic #30-Ubuntu SMP Wed May 1 16:36:13 UTC 2013 i686 i686 i686 GNU/Linux# 注意： uname 显示内核类别， uname -a 显示详细信息。上面的输出详细说明了 uname -a 1. “Linux“: 机器的内核名 2. “tecmint“: 机器的节点名 3. “3.8.0-19-generic“: 内核发布版本 4. “#30-Ubuntu SMP“: 内核版本 5. “i686“: 处理器架构 6。 “GNU/Linux“: 操作系统名 history 命令“history”命令就是历史记录。它显示了在终端中所执行过的所有命令的历史。 12345678910111213141516171819root@tecmint:~# history 1 sudo add-apt-repository ppa:tualatrix/ppa 2 sudo apt-get update 3 sudo apt-get install ubuntu-tweak 4 sudo add-apt-repository ppa:diesch/testing 5 sudo apt-get update 6 sudo apt-get install indicator-privacy 7 sudo add-apt-repository ppa:atareao/atareao 8 sudo apt-get update 9 sudo apt-get install my-weather-indicator 10 pwd 11 cd &amp;&amp; sudo cp -r unity/6 /usr/share/unity/ 12 cd /usr/share/unity/icons/ 13 cd /usr/share/unity # 注意：按住“CTRL + R”就可以搜索已经执行过的命令，它可以在你写命令时自动补全。 (reverse-i-search)‘if': ifconfig sudo 命令“sudo”(super user do)命令允许授权用户执行超级用户或者其它用户的命令。通过在 sudoers 列表的安全策略来指定。 12345root@tecmint:~# sudo add-apt-repository ppa:tualatrix/ppa# 注意：sudo 允许用户借用超级用户的权限，然而"su"命令实际上是允许用户以超级用户登录。# 所以 sudo 比 su 更安全。并不建议使用 sudo 或者 su 来处理日常用途，因为它可能导致严重的错误如果你意外的做错了事。# 这就是为什么在 linux 社区流行一句话：“To err is human, but to really foul up everything, you need root password.” mkdir 命令“mkdir”(Make directory)命令在命名路径下创建新的目录。然而如果目录已经存在了，那么它就会返回一个错误信息”不能创建文件夹，文件夹已经存在了”(“cannot create folder, folder already exists”) 1234root@tecmint:~# mkdir tecmint# 注意：目录只能在用户拥有写权限的目录下才能创建。mkdir：不能创建目录`tecmint`，因为文件已经存在了。# （上面的输出中不要被文件迷惑了，你应该记住我开头所说的-在 linux 中，文件，文件夹，驱动，命令，脚本都视为文件） touch 命令“touch”命令代表了将文件的访问和修改时间更新为当前时间。touch命令只会在文件不存在的时候才会创建它。如果文件已经存在了，它会更新时间戳，但是并不会改变文件的内容。 123root@tecmint:~# touch tecmintfile# 注意：touch 可以用来在用户拥有写权限的目录下创建不存在的文件。 chmod 命令“chmod”命令就是改变文件的模式位。chmod 会根据要求的模式来改变每个所给的文件，文件夹，脚本等等的文件模式（权限）。 1234567891011121314151617181920212223242526# 在文件(文件夹或者其它，为了简单起见，我们就使用文件)中存在3中类型的权限 Read (r)=4 Write(w)=2 Execute(x)=1# 所以如果你想给文件只读权限，就设置为'4';只写权限，设置权限为'2';只执行权限，设置为 1 ; 读写权限，就是 4 + 2 = 6, 以此类推。# 现在需要设置 3 种用户和用户组权限。第一个是拥有者，然后是用户所在的组，最后是其它用户。rwxr-x--x abc.sh# 这里 root 的权限是 rwx（读写和执行权限），# 所属用户组权限是 r-x (只有读和执行权限, 没有写权限)，# 对于其它用户权限是 -x(只有只执行权限)# 为了改变它的权限，为拥有者，用户所在组和其它用户提供读，写，执行权限。root@tecmint:~# chmod 777 abc.sh# 三种都只有读写权限root@tecmint:~# chmod 666 abc.sh# 拥有者用户有读写和执行权限，用户所在的组和其它用户只有可执行权限root@tecmint:~# chmod 711 abc.sh# 注意：对于系统管理员和用户来说，这个命令是最有用的命令之一了。# 在多用户环境或者服务器上，对于某个用户，如果设置了文件不可访问，那么这个命令就可以解决，如果设置了错误的权限，那么也就提供了为授权的访问。 chown 命令“chown”命令就是改变文件拥有者和所在用户组。每个文件都属于一个用户组和一个用户。在你的目录下，使用”ls -l”,你就会看到像这样的东西。 1234567891011121314root@tecmint:~# ls -ldrwxr-xr-x 3 server root 4096 May 10 11:14 Binarydrwxr-xr-x 2 server server 4096 May 13 09:42 Desktop# 在这里，目录 Binary 属于用户"server",和用户组"root",而目录"Desktop"属于用户“server”和用户组"server"# “chown”命令用来改变文件的所有权，所以仅仅用来管理和提供文件的用户和用户组授权。root@tecmint:~# chown server:server Binarydrwxr-xr-x 3 server server 4096 May 10 11:14 Binarydrwxr-xr-x 2 server server 4096 May 13 09:42 Desktop# 注意：“chown”所给的文件改变用户和组的所有权到新的拥有者或者已经存在的用户或者用户组。 apt 命令Debian 系列以“apt”命令为基础，“apt”代表了 Advanced Package Tool。APT 是一个为 Debian 系列系统（Ubuntu，Kubuntu等等）开发的高级包管理器，在 Gnu/Linux 系统上，它会为包自动地，智能地搜索，安装，升级以及解决依赖。 12345678910111213141516171819202122232425262728293031323334353637root@tecmint:~# apt-get install mplayerReading package lists... DoneBuilding dependency tree Reading state information... DoneThe following package was automatically installed and is no longer required: java-wrappersUse 'apt-get autoremove' to remove it.The following extra packages will be installed: esound-common libaudiofile1 libesd0 libopenal-data libopenal1 libsvga1 libvdpau1 libxvidcore4Suggested packages: pulseaudio-esound-compat libroar-compat2 nvidia-vdpau-driver vdpau-driver mplayer-doc netselect fpingThe following NEW packages will be installed: esound-common libaudiofile1 libesd0 libopenal-data libopenal1 libsvga1 libvdpau1 libxvidcore4 mplayer0 upgraded, 9 newly installed, 0 to remove and 8 not upgraded.Need to get 3,567 kB of archives.After this operation, 7,772 kB of additional disk space will be used.Do you want to continue [Y/n]? yroot@tecmint:~# apt-get updateHit http://ppa.launchpad.net raring Release.gpg Hit http://ppa.launchpad.net raring Release.gpg Hit http://ppa.launchpad.net raring Release.gpg Hit http://ppa.launchpad.net raring Release.gpg Get:1 http://security.ubuntu.com raring-security Release.gpg [933 B]Hit http://in.archive.ubuntu.com raring Release.gpg Hit http://ppa.launchpad.net raring Release.gpg Get:2 http://security.ubuntu.com raring-security Release [40.8 kB] Ign http://ppa.launchpad.net raring Release.gpg Get:3 http://in.archive.ubuntu.com raring-updates Release.gpg [933 B] Hit http://ppa.launchpad.net raring Release.gpg Hit http://in.archive.ubuntu.com raring-backports Release.gpg# 注意：上面的命令会导致系统整体的改变，所以需要 root 密码（查看提示符为"#"，而不是“$”）.和 yum 命令相比，Apt 更高级和智能。# 见名知义，apt-cache 用来搜索包中是否包含子包 mplayer, apt-get 用来安装，升级所有的已安装的包到最新版。 关于 apt-get 和 apt-cache 命令更多信息，请查看 25 APT-GET和APT-CACHE命令 tar 命令“tar”命令是磁带归档(Tape Archive)，对创建一些文件的的归档和它们的解压很有用。 1234567root@tecmint:~# tar -zxvf abc.tar.gz (记住'z'代表了.tar.gz)root@tecmint:~# tar -jxvf abc.tar.bz2 (记住'j'代表了.tar.bz2)root@tecmint:~# tar -cvf archieve.tar.gz(.bz2) /path/to/folder/abc# 注意： "tar.gz"代表了使用 gzip 归档，“bar.bz2”使用 bzip 压缩的，它压缩的更好但是也更慢。 了解更多”tar 命令”的例子，请查看 18 Tar命名例子 cal 命令“cal”（Calender），它用来显示当前月份或者未来或者过去任何年份中的月份。 1234567891011121314151617181920212223242526272829303132root@tecmint:~# calMay 2013 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31# 显示已经过去的月份，1835 年 2 月root@tecmint:~# cal 02 1835 February 1835 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28# 显示未来的月份，2145 年 7 月。root@tecmint:~# cal 07 2145 July 2145 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31# 注意： 你不需要往回调整日历 50 年，既不用复杂的数据计算你出生那天，也不用计算你的生日在哪天到来，因为它的最小单位是月，而不是日。 date 命令“date”命令使用标准的输出打印当前的日期和时间，也可以深入设置。 123456789root@tecmint:~# dateFri May 17 14:13:29 IST 2013root@tecmint:~# date --set='14 may 2013 13:57'Mon May 13 13:57:00 IST 2013# 注意：这个命令在脚本中十分有用，以及基于时间和日期的脚本更完美。而且在终端中改变日期和时间，让你更专业！！！（当然你需要 root 权限才能操作这个，因为它是系统整体改变） cat 命令“cat”代表了连结（Concatenation），连接两个或者更多文本文件或者以标准输出形式打印文件的内容。 12345678root@tecmint:~# cat a.txt b.txt c.txt d.txt abcd.txtroot@tecmint:~# cat abcd.txt....contents of file abcd...# 注意：“&gt;&gt;”和“&gt;”调用了追加符号。它们用来追加到文件里，而不是显示在标准输出上。“&gt;”符号会删除已存在的文件，然后创建一个新的文件。所以因为安全的原因，建议使用“&gt;&gt;”，它会写入到文件中，而不是覆盖或者删除。 在深入探究之前，我必须让你知道通配符(你应该知道通配符，它出现在大多数电视选秀中)。通配符是 shell 的特色，和任何 GUI 文件管理器相比，它使命令行更强大有力！如你所看到那样，在一个图形文件管理器中，你想选择一大组文件，你通常不得不使用你的鼠标来选择它们。这可能觉得很简单，但是事实上，这种情形很让人沮丧！ 例如，假如你有一个有很多很多各种类型的文件和子目录的目录，然后你决定移动所有文件名中包含“Linux”字样的 HTML 文件到另外一个目录。如何简单的完成这个？如果目录中包含了大量的不同名的 HTML 文件，你的任务很巨大，而不是简单了。 在 Linux CLI 中，这个任务就很简单，就好像只移动一个 HTML 文件，因为有 shell 的通配符，才会如此简单。这些是特殊的字符，允许你选择匹配某种字符模式的文件名。它帮助你来选择，即使是大量文件名中只有几个字符，而且在大多数情形中，它比使用鼠标选择文件更简单。 这里就是常用通配符列表： Wildcard Matches * 零个或者更多字符 ? 恰好一个字符 [abcde] 恰好列举中的一个字符 [a-e] 恰好在所给范围中的一个字符 [!abcde] 任何字符都不在列举中 [!a-e] 任何字符都不在所给的范围中 {debian,linux} 恰好在所给选项中的一整个单词 ! 叫做非，带’!’的反向字符串为真 更多请阅读Linux cat 命令的实例 13 Linux中cat命令实例 cp 命令“copy”就是复制。它会从一个地方复制一个文件到另外一个地方。 123root@tecmint:~# cp /home/user/Downloads abc.tar.gz /home/user/Desktop (Return 0 when sucess)# 注意： cp，在 shell 脚本中是最常用的一个命令，而且它可以使用通配符（在前面一块中有所描述），来定制所需的文件的复制。 mv 命令“mv”命令将一个地方的文件移动到另外一个地方去。 123root@tecmint:~# mv /home/user/Downloads abc.tar.gz /home/user/Desktop (Return 0 when sucess)# 注意：mv 命令可以使用通配符。mv 需谨慎使用，因为移动系统的或者未授权的文件不但会导致安全性问题，而且可能系统崩溃。 pwd 命令“pwd”（print working directory），在终端中显示当前工作目录的全路径。 12345root@tecmint:~# pwd/home/user/Desktop# 注意： 这个命令并不会在脚本中经常使用，但是对于新手，当从连接到 nux 很久后在终端中迷失了路径，这绝对是救命稻草。 cd 命令最后，经常使用的“cd”命令代表了改变目录。它在终端中改变工作目录来执行，复制，移动，读，写等等操作。 1234567root@tecmint:~# cd /home/user/Desktopserver@localhost:~$ pwd/home/user/Desktop# 注意： 在终端中切换目录时，cd 就大显身手了。“cd ～”会改变工作目录为用户的家目录，而且当用户发现自己在终端中迷失了路径时，非常有用。“cd ..”从当前工作目录切换到(当前工作目录的)父目录。 中级用户：下面你将学会如何进行自定义搜索，知道正在进行的进程和停掉进程，如何使用Linux的强势功能和如何在系统内编译C，C++和JAVA程序。 命令: find搜索指定目录下的文件，从开始于父目录，然后搜索子目录。 12345678910111213141516171819202122232425262728293031323334353637383940root@tecmint:~# find -name *.sh./Desktop/load.sh./Desktop/test.sh./Desktop/shutdown.sh./Binary/firefox/run-mozilla.sh./Downloads/kdewebdev-3.5.8/quanta/scripts/externalpreview.sh./Downloads/kdewebdev-3.5.8/admin/doxygen.sh./Downloads/kdewebdev-3.5.8/admin/cvs.sh./Downloads/kdewebdev-3.5.8/admin/ltmain.sh./Downloads/wheezy-nv-install.sh# 注意： `-name‘选项是搜索大小写敏感。可以使用`-iname‘选项，这样在搜索中可以忽略大小写。（* 是通配符，可以搜索所有的文件；‘.sh‘你可以使用文件名或者文件名的一部分来制定输出结果）root@tecmint:~# find -iname *.SH ( find -iname *.Sh / find -iname *.sH)./Desktop/load.sh./Desktop/test.sh./Desktop/shutdown.sh./Binary/firefox/run-mozilla.sh./Downloads/kdewebdev-3.5.8/quanta/scripts/externalpreview.sh./Downloads/kdewebdev-3.5.8/admin/doxygen.sh./Downloads/kdewebdev-3.5.8/admin/cvs.sh./Downloads/kdewebdev-3.5.8/admin/ltmain.sh./Downloads/wheezy-nv-install.shroot@tecmint:~# find -name *.tar.gz/var/www/modules/update/tests/aaa_update_test.tar.gz./var/cache/flashplugin-nonfree/install_flash_player_11_linux.i386.tar.gz./home/server/Downloads/drupal-7.22.tar.gz./home/server/Downloads/smtp-7.x-1.0.tar.gz./home/server/Downloads/noreqnewpass-7.x-1.2.tar.gz./usr/share/gettext/archive.git.tar.gz./usr/share/doc/apg/php.tar.gz./usr/share/doc/festival/examples/speech_pm_1.0.tar.gz./usr/share/doc/argyll/examples/spyder2.tar.gz./usr/share/usb_modeswitch/configPack.tar.gz# 注意：以上命令查找根目录下和所有文件夹以及加载的设备的子目录下的所有包含‘tar.gz'的文件。 ’find’命令的更详细信息请参考 35 Find Command Examples in Linux 命令: grep‘grep‘命令搜索指定文件中包含给定字符串或者单词的行。举例搜索‘/etc/passwd‘文件中的‘tecmint’ 1234567891011121314151617181920212223242526272829303132333435root@tecmint:~# grep tecmint /etc/passwdtecmint:x:1000:1000:Tecmint,,,:/home/tecmint:/bin/bash# 使用’-i'选项将忽略大小写。root@tecmint:~# grep -i TECMINT /etc/passwdtecmint:x:1000:1000:Tecmint,,,:/home/tecmint:/bin/bash# 使用’-r'选项递归搜索所有自目录下包含字符串 “127.0.0.1“.的行。root@tecmint:~# grep -r "127.0.0.1" /etc//etc/vlc/lua/http/.hosts:127.0.0.1/etc/speech-dispatcher/modules/ivona.conf:#IvonaServerHost "127.0.0.1"/etc/mysql/my.cnf:bind-address = 127.0.0.1/etc/apache2/mods-available/status.conf: Allow from 127.0.0.1 ::1/etc/apache2/mods-available/ldap.conf: Allow from 127.0.0.1 ::1/etc/apache2/mods-available/info.conf: Allow from 127.0.0.1 ::1/etc/apache2/mods-available/proxy_balancer.conf:# Allow from 127.0.0.1 ::1/etc/security/access.conf:#+ : root : 127.0.0.1/etc/dhcp/dhclient.conf:#prepend domain-name-servers 127.0.0.1;/etc/dhcp/dhclient.conf:# option domain-name-servers 127.0.0.1;/etc/init/network-interface.conf: ifconfig lo 127.0.0.1 up || true/etc/java-6-openjdk/net.properties:# localhost &amp; 127.0.0.1)./etc/java-6-openjdk/net.properties:# http.nonProxyHosts=localhost|127.0.0.1/etc/java-6-openjdk/net.properties:# localhost &amp; 127.0.0.1)./etc/java-6-openjdk/net.properties:# ftp.nonProxyHosts=localhost|127.0.0.1/etc/hosts:127.0.0.1 localhost# 注意：您还可以使用以下选项： 1. -w 搜索单词 (egrep -w ‘word1|word2‘ /path/to/file)。 2. -c 用于统计满足要求的行 (i.e., total number of times the pattern matched) (grep -c ‘word‘ /path/to/file)。 3. –color 彩色输出 (grep –color server /etc/passwd)。 命令: man‘man‘是系统帮助页。Man 提供命令所有选项及用法的在线文档。几乎所有的命令都有它们的帮助页，例如： 12345678910111213141516171819202122root@tecmint:~# man manMAN(1) Manual pager utils MAN(1)NAME man - an interface to the on-line reference manualsSYNOPSIS man [-C file] [-d] [-D] [--warnings[=warnings]] [-R encoding] [-L locale] [-m system[,...]] [-M path] [-S list] [-e extension] [-i|-I] [--regex|--wildcard] [--names-only] [-a] [-u] [--no-subpages] [-P pager] [-r prompt] [-7] [-E encoding] [--no-hyphenation] [--no-justification] [-p string] [-t] [-T[device]] [-H[browser]] [-X[dpi]] [-Z] [[section] page ...] ... man -k [apropos options] regexp ... man -K [-w|-W] [-S list] [-i|-I] [--regex] [section] term ... man -f [whatis options] page ... man -l [-C file] [-d] [-D] [--warnings[=warnings]] [-R encoding] [-L locale] [-P pager] [-r prompt] [-7] [-E encoding] [-p string] [-t] [-T[device]] [-H[browser]] [-X[dpi]] [-Z] file ... man -w|-W [-C file] [-d] [-D] page ... man -c [-C file] [-d] [-D] page ... man [-hV]# 上面是 man 命令的系统帮助页，类似的有 cat 和 ls 的帮助页。# 注意：系统帮助页是为了命令的使用和学习而设计的。 命令: psps命令给出正在运行的某个进程的状态，每个进程有特定的 id 成为 PID。 123456789101112131415161718192021222324252627root@tecmint:~# ps PID TTY TIME CMD 4170 pts/1 00:00:00 bash 9628 pts/1 00:00:00 ps # 使用‘-A‘选项可以列出所有的进程及其 PID。root@tecmint:~# ps -A PID TTY TIME CMD 1 ? 00:00:01 init 2 ? 00:00:00 kthreadd 3 ? 00:00:01 ksoftirqd/0 5 ? 00:00:00 kworker/0:0H 7 ? 00:00:00 kworker/u:0H 8 ? 00:00:00 migration/0 9 ? 00:00:00 rcu_bh....# 注意：当你要知道有哪些进程在运行或者需要知道想杀死的进程 PID 时 ps 命令很管用。你可以把它与‘grep‘合用来查询指定的输出结果，例如：root@tecmint:~# ps -A | grep -i ssh 1500 ? 00:09:58 sshd 4317 ? 00:00:00 sshd # ps 命令与 grep 命令用管道线分割可以得到我们想要的结果。 命令: kill也许你从命令的名字已经猜出是做什么的了,kill 是用来杀死已经无关紧要或者没有响应的进程.它是一个非常有用的命令,而不是非常非常有用.你可能很熟悉 Windows 下要杀死进程可能需要频繁重启机器因为一个在运行的进程大部分情况下不能够杀死,即使杀死了进程也需要重新启动操作系统才能生效.但在 linux 环境下,事情不是这样的.你可以杀死一个进程并且重启它而不是重启整个操作系统. 杀死一个进程需要知道进程的 PID. 1234567891011121314# 假设你想杀死已经没有响应的‘apache2'进程,运行如下命令:root@tecmint:~# ps -A | grep -i apache21285 ? 00:00:00 apache2# 搜索‘apache2'进程,找到 PID 并杀掉它.例如:在本例中‘apache2'进程的 PID 是 1285..root@tecmint:~# kill 1285 (to kill the process apache2)# 注意:每次你重新运行一个进程或者启动系统,每个进程都会生成一个新的 PID.你可以使用 ps 命令获得当前运行进程的 PID.# 另一个杀死进程的方法是:root@tecmint:~# pkill apache2# 注意:kill 需要 PID 作为参数,pkill 可以选择应用的方式,比如指定进程的所有者等. 命令: whereiswhereis的作用是用来定位命令的二进制文件\资源\或者帮助页.举例来说,获得ls和kill命令的二进制文件/资源以及帮助页: 123456789root@tecmint:~# whereis lsls: /bin/ls /usr/share/man/man1/ls.1.gzroot@tecmint:~# whereis killkill: /bin/kill /usr/share/man/man2/kill.2.gz /usr/share/man/man1/kill.1.gz# 注意:当需要知道二进制文件保存位置时有用. 命令: service‘service‘命令控制服务的启动、停止和重启，它让你能够不重启整个系统就可以让配置生效以开启、停止或者重启某个服务。 1234567891011121314151617181920# 在 Ubuntu 上启动 apache2 server：root@tecmint:~# service apache2 start * Starting web server apache2 apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1 for ServerNamehttpd (pid 1285) already running [ OK ]# 重启 apache2 server：root@tecmint:~# service apache2 restart* Restarting web server apache2 apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1 for ServerName ... waiting .apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1 for ServerName [ OK ] # 停止 apache2 server：root@tecmint:~# service apache2 stop * Stopping web server apache2 apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1 for ServerName ... waiting [ OK ] # 注意：要想使用 service 命令，进程的脚本必须放在‘/etc/init.d‘，并且路径必须在指定的位置。 # 如果要运行“service apache2 start”实际上实在执行“service /etc/init.d/apache2 start”. 命令: aliasalias 是一个系统自建的 shell 命令，允许你为名字比较长的或者经常使用的命令指定别名。 123456789101112131415161718192021222324# 我经常用‘ls -l‘命令，它有五个字符（包括空格）。于是我为它创建了一个别名‘l'。root@tecmint:~# alias l='ls -l'# 试试它是否能用：root@tecmint:~# ltotal 36drwxr-xr-x 3 tecmint tecmint 4096 May 10 11:14 Binarydrwxr-xr-x 3 tecmint tecmint 4096 May 21 11:21 Desktopdrwxr-xr-x 2 tecmint tecmint 4096 May 21 15:23 Documentsdrwxr-xr-x 8 tecmint tecmint 4096 May 20 14:56 Downloadsdrwxr-xr-x 2 tecmint tecmint 4096 May 7 16:58 Musicdrwxr-xr-x 2 tecmint tecmint 4096 May 20 16:17 Picturesdrwxr-xr-x 2 tecmint tecmint 4096 May 7 16:58 Publicdrwxr-xr-x 2 tecmint tecmint 4096 May 7 16:58 Templatesdrwxr-xr-x 2 tecmint tecmint 4096 May 7 16:58 Videos# 去掉’l'别名，要使用 unalias 命令：root@tecmint:~# unalias l# 再试试：root@tecmint:~# lbash: l: command not found 命令: df报告系统的磁盘使用情况。在跟踪磁盘使用情况方面对于普通用户和系统管理员都很有用。 ‘df‘ 通过检查目录大小工作，但这一数值仅当文件关闭时才得到更新。 12345678910111213root@tecmint:~# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/sda1 47929224 7811908 37675948 18% /none 4 0 4 0% /sys/fs/cgroupudev 1005916 4 1005912 1% /devtmpfs 202824 816 202008 1% /runnone 5120 0 5120 0% /run/locknone 1014120 628 1013492 1% /run/shmnone 102400 44 102356 1% /run/user/dev/sda5 184307 79852 94727 46% /boot/dev/sda7 95989516 61104 91045676 1% /data/dev/sda8 91953192 57032 87218528 1% /personal ‘df’命令的更多例子请参阅 12 df Command Examples in Linux. 命令: du估计文件的空间占用。 逐层统计文件（例如以递归方式）并输出摘要。 123456789101112131415161718root@tecmint:~# du8 ./Daily Pics/wp-polls/images/default_gradient8 ./Daily Pics/wp-polls/images/default32 ./Daily Pics/wp-polls/images8 ./Daily Pics/wp-polls/tinymce/plugins/polls/langs8 ./Daily Pics/wp-polls/tinymce/plugins/polls/img28 ./Daily Pics/wp-polls/tinymce/plugins/polls32 ./Daily Pics/wp-polls/tinymce/plugins36 ./Daily Pics/wp-polls/tinymce580 ./Daily Pics/wp-polls1456 ./Daily Pics36 ./Plugins/wordpress-author-box16180 ./Plugins12 ./May Articles 2013/Xtreme Download Manager4632 ./May Articles 2013/XCache# 注意: ‘df‘只显示文件系统的使用统计，但‘du‘统计目录内容。 ‘du‘命令的更详细信息请参阅 10 du (Disk Usage) Commands. 命令: rm‘rm’ 标准移除命令。 rm 可以用来删除文件和目录。 123456789# 删除目录root@tecmint:~# rm PassportApplicationForm_Main_English_V1.0rm: cannot remove 'PassportApplicationForm_Main_English_V1.0': Is a directory# 'rm' 不能直接删除目录,需要加上相应的'-rf'参数才可以。root@tecmint:~# rm -rf PassportApplicationForm_Main_English_V1.0# 警告: "rm -rf" 命令是一个破坏性的命令,假如你不小心删除一个错误的目录。一旦你使用'rm -rf' 删除一个目录,在目录中所有的文件包括目录本身会被永久的删除,所以使用这个命令要非常小心。 命令: echoecho 的功能正如其名，就是基于标准输出打印一段文本。它和 shell 无关，shell 也不读取通过 echo 命令打印出的内容。然而在一种交互式脚本中，echo 通过终端将信息传递给用户。它是在脚本语言，交互式脚本语言中经常用到的命令。 12345678910111213141516171819202122232425root@tecmint:~# echo "Tecmint.com is a very good website"Tecmint.com is a very good website# 创建一小段交互式脚本 1. 在桌面上新建一个文件，命名为 ‘interactive_shell.sh‘ (记住必须带 ‘.sh‘扩展名)。 2. 复制粘贴如下脚本代码，确保和下面的一致。 #!/bin/bash echo "Please enter your name:" read name echo "Welcome to Linux $name" 3. 接下来，设置执行权限并运行脚本。 root@tecmint:~# chmod 777 interactive_shell.sh root@tecmint:~# ./interactive_shell.sh Please enter your name: Ravi Saive Welcome to Linux Ravi Saive# 注意: ‘#!/bin/bash‘ 告诉 shell 这是一个脚本，并且在脚本首行写上这句话是个好习惯。. ‘read‘ 读取给定的输出. 命令: passwd这是一个很重要的命令，在终端中用来改变自己密码很有用。显然的，因为安全的原因，你需要知道当前的密码。 123456789root@tecmint:~# passwdChanging password for tecmint.(current) UNIX password: ********Enter new UNIX password: ********Retype new UNIX password: ********Password unchanged [这里表示密码未改变，例如：新密码=旧密码]Enter new UNIX password: #####Retype new UNIX password:##### 命令: lpr这个命令用来在命令行上将指定的文件在指定的打印机上打印。 123root@tecmint:~# lpr -P deskjet-4620-series 1-final.pdf# 注意： "lpq"命令让你查看打印机的状态（是开启状态还是关闭状态）和等待打印中的工作(文件)的状态。 命令: cmp比较两个任意类型的文件并将结果输出至标准输出。如果两个文件相同， ‘cmp‘默认返回0；如果不同，将显示不同的字节数和第一处不同的位置。 123456789101112131415# 以下面两个文件为例：# file1.txtroot@tecmint:~# cat file1.txtHi My name is Tecmint# file2.txtroot@tecmint:~# cat file2.txtHi My name is tecmint [dot] com# 比较一下这两个文件，看看命令的输出。root@tecmint:~# cmp file1.txt file2.txtfile1.txt file2.txt differ: byte 15, line 1 命令: wgetWget是用于非交互式（例如后台）下载文件的免费工具.支持HTTP, HTTPS, FTP协议和 HTTP 代理。 123456789101112131415161718# 使用wget下载ffmpegroot@tecmint:~# wget http://downloads.sourceforge.net/project/ffmpeg-php/ffmpeg-php/0.6.0/ffmpeg-php-0.6.0.tbz2--2013-05-22 18:54:52-- http://downloads.sourceforge.net/project/ffmpeg-php/ffmpeg-php/0.6.0/ffmpeg-php-0.6.0.tbz2Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 216.34.181.59Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|216.34.181.59|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://kaz.dl.sourceforge.net/project/ffmpeg-php/ffmpeg-php/0.6.0/ffmpeg-php-0.6.0.tbz2 [following]--2013-05-22 18:54:54-- http://kaz.dl.sourceforge.net/project/ffmpeg-php/ffmpeg-php/0.6.0/ffmpeg-php-0.6.0.tbz2Resolving kaz.dl.sourceforge.net (kaz.dl.sourceforge.net)... 92.46.53.163Connecting to kaz.dl.sourceforge.net (kaz.dl.sourceforge.net)|92.46.53.163|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 275557 (269K) [application/octet-stream]Saving to: ‘ffmpeg-php-0.6.0.tbz2’100%[===========================================================================&gt;] 2,75,557 67.8KB/s in 4.0s 2013-05-22 18:55:00 (67.8 KB/s) - ‘ffmpeg-php-0.6.0.tbz2’ saved [275557/275557] 命令: mountmount 是一个很重要的命令，用来挂载不能自动挂载的文件系统。你需要 root 权限挂载设备。 1234567891011121314151617181920212223# 在插入你的文件系统后，首先运行"lsblk"命令，识别出你的设备，然后把分配的设备名记下来。root@tecmint:~# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 931.5G 0 disk├─sda1 8:1 0 923.6G 0 part /├─sda2 8:2 0 1K 0 part└─sda5 8:5 0 7.9G 0 part [SWAP]sr0 11:0 1 1024M 0 rom sdb 8:16 1 3.7G 0 disk└─sdb1 8:17 1 3.7G 0 part# 从这个输出上来看，很明显我插入的是 4GB 的 U 盘，因而“sdb1”就是要挂载上来的文件系统。以 root 用户操作，然后切换到 /dev 目录，它是所有文件系统挂载的地方。root@tecmint:~# suPassword:root@tecmint:~# cd /dev# 创建一个任何名字的目录，但是最好和引用相关。root@tecmint:~# mkdir usb# 现在将“sdb1”文件系统挂载到“usb”目录.root@tecmint:~# mount /dev/sdb1 /dev/usb 命令: gccgcc 是 Linux 环境下 C 语言的内建编译器。下面是一个简单的 C 程序，在桌面上保存为 Hello.c （记住必须要有‘.c‘扩展名）。 1234567#include &lt;stdio.h&gt;int main()&#123; printf("Hello world\n"); return 0;&#125; 1234567891011121314151617# 编译root@tecmint:~# gcc Hello.c# 运行root@tecmint:~# ./a.outHello world# 注意: 编译 C 程序时，输出会自动保存到一个名为“a.out”的新文件，因此每次编译C程序“a.out”都会被修改。 因此编译期间最好定义输出文件名.，这样就不会有覆盖输出文件的风险了。# 用这种方法编译root@tecmint:~# gcc -o Hello Hello.c# 这里‘-o‘将输出写到‘Hello‘文件而不是 ‘a.out‘。再运行一次。root@tecmint:~# ./HelloHello world 命令: g++g++ 是 C++ 的内建编译器。下面是一个简单的 C++ 程序，在桌面上保存为 Add.cpp （记住必须要有‘.cpp‘扩展名）。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int main()&#123; int a; int b; cout&lt;&lt;"Enter first number:\n"; cin &gt;&gt; a; cout &lt;&lt;"Enter the second number:\n"; cin&gt;&gt; b; cin.ignore(); int result = a + b; cout&lt;&lt;"Result is"&lt;&lt;" "&lt;&lt;result&lt;&lt;endl; cin.get(); return 0;&#125; 123456789101112131415161718192021# 编译root@tecmint:~# g++ Add.cpp# 运行root@tecmint:~# ./a.outEnter first number:......# 注意：编译 C++ 程序时，输出会自动保存到一个名为“a.out”的新文件，因此每次编译 C++ 程序 “a.out”都会被修改。 因此编译期间最好定义输出文件名.，这样就不会有覆盖输出文件的风险了。# 用这种方法编译root@tecmint:~# g++ -o Add Add.cpp# 运行root@tecmint:~# ./AddEnter first number:...... 命令：javaJava 是世界上使用最广泛的编程语言之一. 它也被认为是高效, 安全和可靠的编程语言. 现在大多数基于网络的服务都使用 Java实 现. 拷贝以下代码到一个文件就可以创建一个简单的 Java 程序. 不妨把文件命名为 tecmint.java (记住：’.java’扩展名是必需的). 123456class tecmint &#123; public static void main(String[] arguments) &#123; System.out.println("Tecmint "); &#125;&#125; 1234567# 用 javac 编译 tecmint.javaroot@tecmint:~# javac tecmint.java# 运行root@tecmint:~# java tecmint# 注意：几乎所有的 Linux 发行版都带有 gcc 编译器, 大多数发行版都内建了 g++ 和 java 编译器, 有些也可能没有. 你可以用 apt 或 yum 安装需要的包. 高级用户：以下将解释管理 Linux 服务器所需的一些命令。 命令：ifconfigifconfig 用来配置常驻内核的网络接口信息。在系统启动必要时用来设置网络适配器的信息。之后，它通常是只需要在调试时或当系统需要调整时使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# 检查活动网络适配器[avishek@tecmint ~]$ ifconfigeth0 Link encap:Ethernet HWaddr 40:2C:F4:EA:CF:0E inet addr:192.168.1.3 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe80::422c:f4ff:feea:cf0e/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:163843 errors:0 dropped:0 overruns:0 frame:0 TX packets:124990 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:154389832 (147.2 MiB) TX bytes:65085817 (62.0 MiB) Interrupt:20 Memory:f7100000-f7120000lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:78 errors:0 dropped:0 overruns:0 frame:0 TX packets:78 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:4186 (4.0 KiB) TX bytes:4186 (4.0 KiB)# 检查所有的网络适配器# “-a”参数用来显示所有网络适配器(网卡)的详细信息,包括那些停用的适配器。[avishek@tecmint ~]$ ifconfig -aeth0 Link encap:Ethernet HWaddr 40:2C:F4:EA:CF:0E inet addr:192.168.1.3 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe80::422c:f4ff:feea:cf0e/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:163843 errors:0 dropped:0 overruns:0 frame:0 TX packets:124990 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:154389832 (147.2 MiB) TX bytes:65085817 (62.0 MiB) Interrupt:20 Memory:f7100000-f7120000lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:78 errors:0 dropped:0 overruns:0 frame:0 TX packets:78 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:4186 (4.0 KiB) TX bytes:4186 (4.0 KiB)virbr0 Link encap:Ethernet HWaddr 0e:30:a3:3a:bf:03 inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)# 停用网络适配器[avishek@tecmint ~]$ ifconfig eth0 down# 启用网络适配器[avishek@tecmint ~]$ ifconfig eth0 up# 指定 IP 地址到网络适配器，为网络适配器 eth0 设定 IP 地址“192.168.1.12”。[avishek@tecmint ~]$ ifconfig eth0 192.168.1.12# 更改网络适配器 eth0 的子网掩码[avishek@tecmint ~]$ ifconfig eth0 netmask 255.255.255.# 更改网络适配器 eth0 的广播地址[avishek@tecmint ~]$ ifconfig eth0 broadcast 192.168.1.255# 为网络适配器 eth0 指定 IP 地址,子网掩码，广播地址[avishek@tecmint ~]$ ifconfig eth0 192.168.1.12 netmask 255.255.255.0 broadcast 192.168.1.255# 注：如果你设置一块无线网卡的信息，你可以使用的命令是“iwconfig”。 欲知更多 ifconfig 命令的例子和使用方法，读 15个有用的ifconfig 命令。 命令：netstatnetstat 命令显示各种网络相关的信息，如网络连接，路由表，接口统计，伪装连接，组播成员身份等…. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 列出所有的网络端口[avishek@tecmint ~]$ netstat -aActive UNIX domain sockets (servers and established)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ACC ] STREAM LISTENING 741379 /run/user/user1/keyring-I5cn1c/gpgunix 2 [ ACC ] STREAM LISTENING 8965 /var/run/acpid.socketunix 2 [ ACC ] STREAM LISTENING 18584 /tmp/.X11-unix/X0unix 2 [ ACC ] STREAM LISTENING 741385 /run/user/user1/keyring-I5cn1c/sshunix 2 [ ACC ] STREAM LISTENING 741387 /run/user/user1/keyring-I5cn1c/pkcs11unix 2 [ ACC ] STREAM LISTENING 20242 @/tmp/dbus-ghtTjuPN46unix 2 [ ACC ] STREAM LISTENING 13332 /var/run/samba/winbindd_privileged/pipeunix 2 [ ACC ] STREAM LISTENING 13331 /tmp/.winbindd/pipeunix 2 [ ACC ] STREAM LISTENING 11030 /var/run/mysqld/mysqld.sockunix 2 [ ACC ] STREAM LISTENING 19308 /tmp/ssh-qnZadSgJAbqd/agent.3221unix 2 [ ACC ] STREAM LISTENING 436781 /tmp/HotShotsunix 2 [ ACC ] STREAM LISTENING 46110 /run/user/ravisaive/pulse/nativeunix 2 [ ACC ] STREAM LISTENING 19310 /tmp/gpg-zfE9YT/S.gpg-agent....# 显示所有 tcp 相关端口[avishek@tecmint ~]$ netstat -atActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:mysql *:* LISTEN tcp 0 0 *:5901 *:* LISTEN tcp 0 0 *:5902 *:* LISTEN tcp 0 0 *:x11-1 *:* LISTEN tcp 0 0 *:x11-2 *:* LISTEN tcp 0 0 *:5938 *:* LISTEN tcp 0 0 localhost:5940 *:* LISTEN tcp 0 0 ravisaive-OptiPl:domain *:* LISTEN tcp 0 0 ravisaive-OptiPl:domain *:* LISTEN tcp 0 0 localhost:ipp *:* LISTEN tcp 0 0 ravisaive-OptiPle:48270 ec2-23-21-236-70.c:http ESTABLISHEDtcp 0 0 ravisaive-OptiPle:48272 ec2-23-21-236-70.c:http TIME_WAIT tcp 0 0 ravisaive-OptiPle:48421 bom03s01-in-f22.1:https ESTABLISHEDtcp 0 0 ravisaive-OptiPle:48269 ec2-23-21-236-70.c:http ESTABLISHEDtcp 0 0 ravisaive-OptiPle:39084 channel-ecmp-06-f:https ESTABLISHED...# 显示所有连接的统计信息[avishek@tecmint ~]$ netstat -sIp: 4994239 total packets received 0 forwarded 0 incoming packets discarded 4165741 incoming packets delivered 3248924 requests sent out 8 outgoing packets droppedIcmp: 29460 ICMP messages received 566 input ICMP message failed. ICMP input histogram: destination unreachable: 98 redirects: 29362 2918 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 2918IcmpMsg: InType3: 98 InType5: 29362 OutType3: 2918Tcp: 94533 active connections openings 23 passive connection openings 5870 failed connection attempts 7194 connection resets received....# 好的！由于某些原因如果你不想解析 netstat 输出的主机、端口和用户名称的话。[avishek@tecmint ~]$ netstat -an# 好，你可能需要获取的 netstat 持续输出的动态信息，通过传递中断输出指令 (ctrl + c)来停止。[avishek@tecmint ~]$ netstat -c 更多关于“netstat”的例子和使用方法，浏览文章 20 个 netstat 的使用案例。 命令：nslookup网络实用程序，用于获得互联网服务器的信息。顾名思义，该实用程序将发现通过查询 DNS 域的名称服务器信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475[avishek@tecmint ~]$ nslookup tecmint.comServer: 192.168.1.1Address: 192.168.1.1#53Non-authoritative answer:Name: tecmint.comAddress: 50.16.67.239# 查询邮件、交换器记录[avishek@tecmint ~]$ nslookup -query=mx tecmint.comServer: 192.168.1.1Address: 192.168.1.1#53Non-authoritative answer:tecmint.com mail exchanger = 0 smtp.secureserver.net.tecmint.com mail exchanger = 10 mailstore1.secureserver.net.Authoritative answers can be found from:# 查询域名服务器[avishek@tecmint ~]$ nslookup -type=ns tecmint.comServer: 192.168.1.1Address: 192.168.1.1#53Non-authoritative answer:tecmint.com nameserver = ns3404.com.tecmint.com nameserver = ns3403.com.Authoritative answers can be found from:# 查询 DNS 记录[avishek@tecmint ~]$ nslookup -type=any tecmint.comServer: 192.168.1.1Address: 192.168.1.1#53Non-authoritative answer:tecmint.com mail exchanger = 10 mailstore1.secureserver.net.tecmint.com mail exchanger = 0 smtp.secureserver.net.tecmint.com nameserver = ns06.domaincontrol.com.tecmint.com nameserver = ns3404.com.tecmint.com nameserver = ns3403.com.tecmint.com nameserver = ns05.domaincontrol.com.Authoritative answers can be found from:# 查询 起始 授权机构[avishek@tecmint ~]$ nslookup -type=soa tecmint.comServer: 192.168.1.1Address: 192.168.1.1#53Non-authoritative answer:tecmint.com origin = ns3403.hostgator.com mail addr = dnsadmin.gator1702.hostgator.com serial = 2012081102 refresh = 86400 retry = 7200 expire = 3600000 minimum = 86400Authoritative answers can be found from:# 查询端口号，更改使用你想要连接的端口号[avishek@tecmint ~]$ nslookup -port 56 tecmint.comServer: tecmint.comAddress: 50.16.76.239#53Name: 56Address: 14.13.253.12 更多阅读 8个 Nslookup 命令 命令：digdig 是查询 DNS 域名服务器的工具，可以查询的主机地址、 邮件交流、 域名服务器相关的信息。在任何 Linux (Unix) 或 Macintosh OS X 操作系统上，都可以使用该工具。dig 的最典型的用法是单个主机的查询。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[avishek@tecmint ~]$ dig tecmint.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6 &lt;&lt;&gt;&gt; tecmint.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;# 关闭注释行[avishek@tecmint ~]$ dig tecmint.com +nocomments; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6 &lt;&lt;&gt;&gt; tecmint.com +nocomments;; global options: +cmd;tecmint.com. IN Atecmint.com. 14400 IN A 40.216.66.239;; Query time: 418 msec;; SERVER: 192.168.1.1#53(192.168.1.1);; WHEN: Sat Jun 29 13:53:22 2013;; MSG SIZE rcvd: 45# 关闭认证块[avishek@tecmint ~]$ dig tecmint.com +noauthority; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6 &lt;&lt;&gt;&gt; tecmint.com +noauthority;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;# 关闭 其他 块[avishek@tecmint ~]$ dig tecmint.com +noadditional; &lt;&lt;&gt;&gt; DiG 9.9.2-P1 &lt;&lt;&gt;&gt; tecmint.com +noadditional;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;# 关闭 统计块[avishek@tecmint ~]$ dig tecmint.com +nostats; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6 &lt;&lt;&gt;&gt; tecmint.com +nostats;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;# 关闭回复块[avishek@tecmint ~]$ dig tecmint.com +noanswer; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6 &lt;&lt;&gt;&gt; tecmint.com +noanswer;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;# 关闭所有块[avishek@tecmint ~]$ dig tecmint.com +noall; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6 &lt;&lt;&gt;&gt; tecmint.com +noall;; global options: +cmd 阅读更多 10 个 Linux Dig 命令实例。 命令：uptime你连接到你的 Linux 服务器时发现一些不寻常或恶意的东西，你会做什么？猜测……不，绝不！你可以运行 uptime 来验证当服务器无人值守时到底发生了什么事情。 123[avishek@tecmint ~]$ uptime14:37:10 up 4:21, 2 users, load average: 0.00, 0.00, 0.04 命令：wall对系统管理员来说一个最重要的命令。wall 发送一条消息到大家登录端将其 mesg 权限设置为”yes”。这条信息可以被 wall 作为参数，或者可以将它作为 wall 的标准输入。 12345[avishek@tecmint ~]$ wall "we will be going down for maintenance for one hour sharply at 03:30 pm"Broadcast message from root@localhost.localdomain (pts/0) (Sat Jun 29 14:44:02 2013):we will be going down for maintenance for one hour sharply at 03:30 pm 命令：mesg其他人们可以使用”wtrite”命令,将在在向您发送文本到屏幕上。你可以控制是否显示。 123mesg [n|y]n - prevents the message from others popping up on the screen.y – Allows messages to appear on your screen. 命令：write如果 ‘mesg’ 是 ‘y’，让你的文本直接发送到另一台 Linux 机器的屏幕。 1[avishek@tecmint ~]$ write ravisaive 命令：talk增强的 write 命令，talk 命令可让你与其他登录的用户交谈。 1234567[avishek@tecmint ~]$ talk ravisaive# 注：如果 talk 命令没安装的话，可以通过 apt 或 yum 安装所需的包。[avishek@tecmint ~]$ yum install talkOR[avishek@tecmint ~]$ apt-get install talk 命令：w是否觉得命令’w’很滑稽？但是事实上不是的。它是一个命令，尽管只有一个字符长！命令”w”是 uptime 和 who 命令，以前后的顺序组合在一起。 1234567[avishek@tecmint ~]$ w15:05:42 up 4:49, 3 users, load average: 0.02, 0.01, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATserver tty7 :0 14:06 4:43m 1:42 0.08s pam: gdm-passwoserver pts/0 :0.0 14:18 0.00s 0.23s 1.65s gnome-terminalserver pts/1 :0.0 14:47 4:43 0.01s 0.01s bash 命令：rename见名知意，这个命令重命名文件。rename 将会通过从文件名的首字符开始替换，重命名为指定的文件名。 12345Give the file names a1, a2, a3, a4.....1213# 仅仅写这些命令：[@Lesus 注： 在 Ubuntu上 不支持这种格式， rename 与 mv 不同的是，rename 可以批量修改，如同带了 while 的 mv 操作。]rename a1 a0 a?rename a1 a0 a?? 命令：top显示 CPU 进程信息。这个命令自动刷新，默认是持续显示 CPU 进程信息，除非使用了中断指令。 12345678910111213141516171819202122232425262728293031323334[avishek@tecmint ~]$ toptop - 14:06:45 up 10 days, 20:57, 2 users, load average: 0.10, 0.16, 0.21Tasks: 240 total, 1 running, 235 sleeping, 0 stopped, 4 zombie%Cpu(s): 2.0 us, 0.5 sy, 0.0 ni, 97.5 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem: 2028240 total, 1777848 used, 250392 free, 81804 buffersKiB Swap: 3905532 total, 156748 used, 3748784 free, 381456 cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 23768 ravisaiv 20 0 1428m 571m 41m S 2.3 28.9 14:27.52 firefox 24182 ravisaiv 20 0 511m 132m 25m S 1.7 6.7 2:45.94 plugin-containe 26929 ravisaiv 20 0 5344 1432 972 R 0.7 0.1 0:00.07 top 24875 ravisaiv 20 0 263m 14m 10m S 0.3 0.7 0:02.76 lxterminal 1 root 20 0 3896 1928 1228 S 0.0 0.1 0:01.62 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.06 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:17.28 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 7 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/u:0H 8 root rt 0 0 0 0 S 0.0 0.0 0:00.12 migration/0 9 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 10 root 20 0 0 0 0 S 0.0 0.0 0:26.94 rcu_sched 11 root rt 0 0 0 0 S 0.0 0.0 0:01.95 watchdog/0 12 root rt 0 0 0 0 S 0.0 0.0 0:02.00 watchdog/1 13 root 20 0 0 0 0 S 0.0 0.0 0:17.80 ksoftirqd/1 14 root rt 0 0 0 0 S 0.0 0.0 0:00.12 migration/1 16 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/1:0H 17 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 cpuset 18 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 khelper 19 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kdevtmpfs 20 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 netns 21 root 20 0 0 0 0 S 0.0 0.0 0:00.04 bdi-default 22 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kintegrityd 23 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kblockd 24 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 ata_sff 另查看 12 TOP命令例子。[@Lesus 注：htop 比 top 命令更好用，不过需要自己安装] 命令：mkfs.ext4这个命令在指定的设备上创建一个新的 ext4 文件系统，如果这个命令后面跟的是个错误的设备，那么整个设备就会被擦除和格式化，所以建议不要运行这个命令，除非你清楚自己正在干什么。 12Mkfs.ext4 /dev/sda1 (sda1 block will be formatted)mkfs.ext4 /dev/sdb1 (sdb1 block will be formatted) 更多查看：Ext4是什么及怎么创建和转换 vi/emac/nano 命令vi (visual), emac, nano 是 linux 中最常用的一些编辑器。它们经常用于编辑文本，配置,… 等文件. A quick guide to work around vi and nano is, emac is a. 12345678910111213141516171819202122# vi 编辑器：[avishek@tecmint ~]$ touch a.txt (创建一个名为a.txt的文本文件)[avishek@tecmint ~]$ vi a.txt (用vi打开a.txt)# 按下‘i’键进入插入模式, 否则你不能输入任何内容echo "Hello" (这里的文本会存到文件中) 1. alt+x (退出插入模式, 记得在最后的字符间留有一些空格。 2. ctrl+x 命令或你上一个单词将被删除)。 3. :wq! (以当前的文本保存文件, 记住‘!’ 是覆盖的意思)。# nano 编辑器：[avishek@tecmint ~]$ nano a.txt (用nano打开 a.txt)edit, with the content, required# ctrl +x (关闭编辑器)。它会显示如下的提示输出信息：Save modified buffer (ANSWERING "No" WILL DESTROY CHANGES) ? Y Yes N No ^C Cancel# 点击‘y’ 选择 yes 并输入文件名，就完成编辑了。 命令：rsyncRsync 复制文件，参数 -P 开启进度条。如果你已经安装了 rsync，你可以使用一个简单的别名。 1234567891011121314alias cp='rsync -aP'# 现在尝试在终端复制一个大文件，这样将会看到显示剩余部分的输出，与进度条类似。# 而且，保持和维护备份是系统管理员不得不做的最重要、最无聊的工作之一。Rsync 是一个用于新建和维护备份的非常好用的终端工具（也存在许多其它工具）。[avishek@tecmint ~]$ rsync -zvr IMG_5267\ copy\=33\ copy\=ok.jpg ~/Desktop/sending incremental file listIMG_5267 copy=33 copy=ok.jpgsent 2883830 bytes received 31 bytes 5767722.00 bytes/sectotal size is 2882771 speedup is 1.00# 注意: -z 表示压缩， -v 表示详细信息，-r 表示递归。 命令：free跟踪内存的使用和资源一样重要，就像管理员执行的任何其它任务，可以使用 ‘free’ 命令来在这里救援. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 当前内存使用状态Current Usage Status of Memory[avishek@tecmint ~]$ free total used free shared buffers cachedMem: 2028240 1788272 239968 0 69468 363716-/+ buffers/cache: 1355088 673152Swap: 3905532 157076 3748456# 设置输出单位为KB，MB或GB[avishek@tecmint ~]$ free -b total used free shared buffers cachedMem: 2076917760 1838272512 238645248 0 71348224 372670464-/+ buffers/cache: 1394253824 682663936Swap: 3999264768 160845824 3838418944[avishek@tecmint ~]$ free -k total used free shared buffers cachedMem: 2028240 1801484 226756 0 69948 363704-/+ buffers/cache: 1367832 660408Swap: 3905532 157076 3748456[avishek@tecmint ~]$ free -m total used free shared buffers cachedMem: 1980 1762 218 0 68 355-/+ buffers/cache: 1338 641Swap: 3813 153 3660[avishek@tecmint ~]$ free -g total used free shared buffers cachedMem: 1 1 0 0 0 0-/+ buffers/cache: 1 0Swap: 3 0 3# 以可读的格式显示，检查当前内存使用[avishek@tecmint ~]$ free -h total used free shared buffers cachedMem: 1.9G 1.7G 208M 0B 68M 355M-/+ buffers/cache: 1.3G 632MSwap: 3.7G 153M 3.6G# 设定 时间间隔 后 ，持续检查 使用状态[avishek@tecmint ~]$ free -s 3 total used free shared buffers cachedMem: 2028240 1824096 204144 0 70708 364180-/+ buffers/cache: 1389208 639032Swap: 3905532 157076 3748456 total used free shared buffers cachedMem: 2028240 1824192 204048 0 70716 364212-/+ buffers/cache: 1389264 638976Swap: 3905532 157076 3748456 阅读更多 10 个 Free 命令使用实例。 命令：mysqldump好了，现在你从名字上就能明白这个命令所代表的作用。mysqldump 命令会转储(备份)数据库的全部或特定一部分数据到一个给定的文件中。例如： 1[avishek@tecmint ~]$ mysqldump -u root -p --all-databases &gt; /home/server/Desktop/backupfile.sql 注意： mysqldump 需要 mysql 在运行中并且有正确的授权密码。我们在 用 mysqldump 命令备份数据库中讨论了一些有用的 “mysqldump” 命令用法。 命令：mkpasswd根据指定的长度，产生一个难猜的随机密码。 12345678910111213[avishek@tecmint ~]$ mkpasswd -l 10zI4+Ybqfx9[avishek@tecmint ~]$ mkpasswd -l 20w0Pr7aqKk&amp;hmbmqdrlmk# 注意： -l 10 产生一个 10 个字符的随机密码，而 -l 20 产生 20 个字符的密码，它可以设置为任意长度来取得所希望的结果。# 这个命令很有用，经常在脚本语言里使用来产生随机的密码。你可能需要 yum 或 apt ‘expect’ 包来使用这个命令。[avishek@tecmint ~]$ yum install expect# 或[avishek@tecmint ~]$ apt-get install expect 命令：paste合并两个或多个文本文件，按行来进行合并。 1234567891011121314151617# 如果 file1 的内容是：123# file2 是这样的:abcd[avishek@tecmint ~]$ paste file1 file2 &gt; file3# 结果file3将是:1 a2 b3 c d 命令：lsoflsof 是”list open files”(“列表中打开的文件”) 的缩写，显示您的系统当前已打开的所有文件。这是非常有用的对于想找出哪些进程使用某一特定文件，或显示为单个进程打开所有文件。一些有用的 10 个 lsof 命令示例，你可能会感兴趣阅读。 123456789101112131415161718192021222324252627[avishek@tecmint ~]$ lsofCOMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAMEinit 1 root cwd DIR 8,1 4096 2 /init 1 root rtd DIR 8,1 4096 2 /init 1 root txt REG 8,1 227432 395571 /sbin/initinit 1 root mem REG 8,1 47080 263023 /lib/i386-linux-gnu/libnss_files-2.17.soinit 1 root mem REG 8,1 42672 270178 /lib/i386-linux-gnu/libnss_nis-2.17.soinit 1 root mem REG 8,1 87940 270187 /lib/i386-linux-gnu/libnsl-2.17.soinit 1 root mem REG 8,1 30560 263021 /lib/i386-linux-gnu/libnss_compat-2.17.soinit 1 root mem REG 8,1 124637 270176 /lib/i386-linux-gnu/libpthread-2.17.soinit 1 root mem REG 8,1 1770984 266166 /lib/i386-linux-gnu/libc-2.17.soinit 1 root mem REG 8,1 30696 262824 /lib/i386-linux-gnu/librt-2.17.soinit 1 root mem REG 8,1 34392 262867 /lib/i386-linux-gnu/libjson.so.0.1.0init 1 root mem REG 8,1 296792 262889 /lib/i386-linux-gnu/libdbus-1.so.3.7.2init 1 root mem REG 8,1 34168 262840 /lib/i386-linux-gnu/libnih-dbus.so.1.0.0init 1 root mem REG 8,1 95616 262848 /lib/i386-linux-gnu/libnih.so.1.0.0init 1 root mem REG 8,1 134376 270186 /lib/i386-linux-gnu/ld-2.17.soinit 1 root 0u CHR 1,3 0t0 1035 /dev/nullinit 1 root 1u CHR 1,3 0t0 1035 /dev/nullinit 1 root 2u CHR 1,3 0t0 1035 /dev/nullinit 1 root 3r FIFO 0,8 0t0 1714 pipeinit 1 root 4w FIFO 0,8 0t0 1714 pipeinit 1 root 5r 0000 0,9 0 6245 anon_inodeinit 1 root 6r 0000 0,9 0 6245 anon_inodeinit 1 root 7u unix 0xf5e91f80 0t0 8192 @/com/ubuntu/upstartinit 1 root 8w REG 8,1 3916 394 /var/log/upstart/teamviewerd.log.1 (deleted) 参考资料 对 Linux 新手非常有用的 20 个命令 20 Useful Commands for Linux Newbies 对中级 Linux 用户非常有用的 20 个命令 20 Advanced Commands for Middle Level Linux Users 对 Linux 专家非常有用的 20 个命令 20 Advanced Commands for Linux Experts]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 查看系统配置常用命令]]></title>
    <url>%2F2014%2F04%2F10%2F42364%2F</url>
    <content type="text"><![CDATA[系统12345678uname -an # 查看内核/操作系统/ CPU 信息head -n 1 /etc/issue # 查看操作系统版本cat /proc/cpuinfo # 查看 CPU 信息hostname # 查看计算机名lspci -tv # 列出所有 PCI 设备lsusb -tv # 列出所有 USB 设备ismod # 列出加载的内核模块env # 查看环境变量 资源1234567free -m # 查看内存使用量和交换区使用量df -h # 查看各分区使用情况du -sh &lt;目录名&gt; # 查看指定目录的大小grep MemTotal /proc/meminfo # 查看内存总量grep MemFree /proc/meminfo # 查看空闲内存量uptime # 查看系统运行时间、用户数、负载cat /proc/loadavg # 查看系统负载 磁盘和分区12345mount | column -t # 查看挂接的分区状态fdisk -l # 查看所有分区swapon -s # 查看所有交换分区hdparm -i /dev/hda # 查看磁盘参数（仅适用于 IDE 设备）dmesg | grep IDE # 查看启动时 IDE 设备检测状况 网络123456ifconfig # 查看所有网络接口的属性iptables -L # 查看防火墙设置route -n # 查看路由表netstat -lntp # 查看所有监听端口netstat -antp # 查看所有已经建立的连接netstat -s # 查看网络统计信息 进程12ps -ef # 查看所有进程top # 实时显示进程状态 用户123456w # 查看活动用户id &lt;用户名&gt; # 查看指定用户信息last # 查看用户登录日志cut -d: -f1 /etc/passwd # 查看系统所有用户cut -d: -f1 /etc/group # 查看系统所有组crontab -l # 查看当前用户的计划任务 服务12chkconfig --list # 列出所有系统服务chkconfig --list | grep on # 列出所有启动的系统服务 程序1rpm -qa # 查看所有安装的软件包 其他123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# 查看主板序列号dmidecode | grep -i 'serial number'# 用硬件检测程序 kuduz 探测新硬件service kudzu startservice kudzu restart# 查看 CPU 信息cat /proc/cpuinfodmesg | grep -i 'cpu'dmidecode -t processor# 查看内存信息cat /proc/meminfofree -mvmstat# 查看板卡信息cat /proc/pci# 查看显卡/声卡信息ispci | grep -i 'VGA'dmesg | grep -i 'VGA'# 查看网卡信息dmesg | grep -i 'eth'cat /etc/sysconfig/hwconfgrep -i 'eth'lspci | grep -i 'eth'# 查看 PCI 信息lspcicat /proc/pci# 查看 USB 设备cat /proc/bus/usb/devices# 查看键盘和鼠标cat /proc/bus/input/devices# 查看系统硬盘信息和使用情况fdiskdisk -ldf# 查看各设备的中断请求（IRQ）cat /proc/interrupts# 查看系统体系结构uname -an# 查看及启动系统的 32 位或 64 位内核模式isalist -visainfo -visainfo -b# 查看硬件信息，包括 bios、cpu、内存等信息dmidecode# 测定当前的显示器刷新频率/usr/sbin/ffbconfig -rev \?# 查看系统配置/usr/platform/sun4u/sbin/prtdiag -v# 查看当前系统中已经应用的补丁showrev -p# 显示当前的运行级别who -rH# 查看当前的 bind 版本信息nslookup -class=chaos -q=txt version.bind# 查看硬件信息dmesg | more# 显示外设信息，如 usb、网卡等信息lspci# 查看已加载的驱动lsnodlshw# 查看当前处理器的类型和速度（主频）psrinfo -v# 打印当前的 OBP 版本号prtconf -v# 查看硬盘物理信息（vendor、RPM、Capacity）iostat -E# 查看磁盘的几何参数和分区信息prtvtoc /dev/rdsk/c0t0d0s# 显示已经使用和未使用的 i-node 数目df -F ufs -o iisalist -v# 对于“/proc”中文件可使用文件查看命令浏览其内容，文件中包含系统特定信息 主机 CPU 信息：Cpuinfo 主机 DMA 通道信息：Dma 文件系统信息：Filesystems 主机中断信息：Interrupts 主机 I/O 端口号信息：Ioports 主机内存信息：Meninfo Linux 内存版本信息：Version # 备注：proc - process infomation pseudo-filesystem 进程信息伪装文件系统 参考资料Linux 系统配置常用命令]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源协议简介]]></title>
    <url>%2F2014%2F04%2F10%2F3854%2F</url>
    <content type="text"><![CDATA[Open Source Initiative 组织批准的开源协议中，我们常见的有：BSD、GPL、LGPL、MIT 等。 BSD 开源协议（original BSD license、FreeBSD license、Original BSD license）BSD 开源协议是一个给予使用者很大自由的协议。基本上使用者可以”为所欲为”,可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。 但”为所欲为”的前提当你发布使用了 BSD 协议的代码，或则以 BSD 协议代码为基础做二次开发自己的产品时，需要满足三个条件： 如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中的 BSD 协议。 如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。 不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。 BSD 代码鼓励代码共享，但需要尊重代码作者的著作权。BSD 由于允许使用者修改和重新发布代码，也允许使用或在 BSD 代码上开发商业软件发布和销售，因此是对商业集成很友好的协议。而很多的公司企业在选用开源产品的时候都首选 BSD 协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者二次开发。 Apache Licence 2.0（Apache License, Version 2.0、Apache License, Version 1.1、Apache License, Version 1.0）Apache Licence 是著名的非盈利开源组织 Apache 采用的协议。该协议和 BSD 类似，同样鼓励代码共享和尊重原作者的著作权，同样允许代码修改，再发布（作为开源或商业软件）。需要满足的条件也和 BSD 类似： 需要给代码的用户一份 Apache Licence。 如果你修改了代码，需要再被修改的文件中说明。 在延伸的代码中（修改和有源代码衍生的代码中）需要带有原来代码中的协议，商标，专利声明和其他原来作者规定需要包含的说明。 如果再发布的产品中包含一个 Notice 文件，则在 Notice 文件中需要带有 Apache Licence。你可以在 Notice 中增加自己的许可，但不可以表现为对 Apache Licence 构成更改。 Apache Licence 也是对商业应用友好的许可。使用者也可以在需要的时候修改代码来满足需要并作为开源或商业产品发布/销售。 GPL（GNU General Public License）我们很熟悉的 Linux 就是采用了 GPL。GPL 协议和 BSD, Apache Licence 等鼓励代码重用的许可很不一样。GPL 的出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用，但不允许修改后和衍生的代码做为闭源的商业软件发布和销售。这也就是为什么我们能用免费的各种linux，包括商业公司的 linux 和 linux 上各种各样的由个人，组织，以及商业软件公司开发的免费软件了。 GPL 协议的主要内容是只要在一个软件中使用(“使用”指类库引用，修改后的代码或者衍生代码)GPL 协议的产品，则该软件产品必须也采用 GPL 协议，既必须也是开源和免费。这就是所谓的”传染性”。GPL 协议的产品作为一个单独的产品使用没有任何问题，还可以享受免费的优势。 由于 GPL 严格要求使用了 GPL 类库的软件产品必须使用 GPL 协议，对于使用 GPL 协议的开源代码，商业软件或者对代码有保密要求的部门就不适合集成/采用作为类库和二次开发的基础。 其它细节如再发布的时候需要伴随GPL协议等和BSD/Apache等类似。 LGPL（GNU Lesser General Public License）LGPL 是 GPL 的一个为主要为类库使用设计的开源协议。和 GPL 要求任何使用/修改/衍生之GPL类库的的软件必须采用 GPL 协议不同。LGPL 允许商业软件通过类库引用(link)方式使用 LGPL 类库而不需要开源商业软件的代码。这使得采用 LGPL 协议的开源代码可以被商业软件作为类库引用并发布和销售。 但是如果修改 LGPL 协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用 LGPL 协议。因此 LGPL 协议的开源代码很适合作为第三方类库被商业软件引用，但不适合希望以 LGPL 协议代码为基础，通过修改和衍生的方式做二次开发的商业软件采用。 GPL/LGPL 都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品。 AGPL（The GNU Affero General Public License）原有的GPL协议，由于现在网络服务公司兴起（如：google）产生了一定的漏洞，比如使用GPL的自由软件，但是并不发布与网络之中，则可以自由的使用GPL协议却不开源自己私有的解决方案。AGPL则增加了对此做法的约束。 MIT（MIT）MIT 是和 BSD 一样宽范的许可协议，作者只想保留版权，而无任何其他了限制。也就是说，你必须在你的发行版里包含原许可协议的声明，无论你是以二进制发布的还是以源代码发布的。 CPAL（Common Public Attribution License）CPAL 本质上其是由 Mozilla 公共许可证（MPL）加入新的条款构成的。该许可证要求开发者对软件进行标记。 MPL（The Mozilla Public License）MPL 是 1998 年初 Netscape 的 Mozilla 小组为其开源软件项目设计的软件许可证。MPL 更好的平衡了开发者对源代码的需求和他们可以利用源代码获得的利益。MPL 在许多权利与义务的约定方面同著名的 GPL 许可证和 BSD 许可证相同，都是符合 OSIA 认定的开源软件许可证。MPL 主要有以下几个显著不同： MPL 虽然也要求经 MPL 许可证发布的源代码的修改也要以 MPL 许可证的方式再许可出来，以保证其他人可以在 MPL 许可证下共享源代码，但是，在 MPL 中对“发布”的定义是“以源代码方式发布的文件”，这就允许企业更灵活的在自己的商业软件中使用 MPL 许可证发布的源码。 MPL 许可证第三条第 7 条款中 允许被许可人将经过 MPL 许可证获得的源代码同自己其他类型的代码混合得到自己的软件程序。 对软件专利的态度，MPL 许可证不像 GPL 许可证那样明确表示反对软件专利，但是却明确要求源代码的提供者不能提供已经受专利保护的源代码（除非他本人是专利权人，并书面向公众免费许可这些源代码），也不能在将这些源代码以开放源代码许可证形式许可后，再去申请与这些源代码有关的专利。 参考资料 开源协议 五种开源协议的比较(BSD,Apache,GPL,LGPL,MIT) Various Licenses and Comments about Them]]></content>
      <categories>
        <category>License</category>
      </categories>
      <tags>
        <tag>License</tag>
        <tag>Open Source</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pow 安装配置及使用]]></title>
    <url>%2F2014%2F03%2F29%2F63724%2F</url>
    <content type="text"><![CDATA[Pow，Mac OS X 上零配置的 Rack Server。它使得开发 Rails 及 Rack 应用更为简便。 官网：http://pow.cx/ Homebrew 的 GitHub 源码：https://github.com/Homebrew/homebrew Pow 的 GitHub 源码：https://github.com/basecamp/pow Pow 文档说明：http://pow.cx/manual.html Pow 安装说明：https://github.com/basecamp/pow/wiki/Installation Pow 常见错误解决办法：https://github.com/basecamp/pow/wiki/Troubleshooting 通过官方包安装（推荐方式）12curl get.pow.cx | sh 通过源码安装123456789# 若未安装node 先安装nodebrew install node# clone 源码git clone git@github.com:basecamp/pow.gitcd pownpm --global installnpm --global run-script pow restart# 若你希望在每次登陆时都通过 launchd 启动 Pow 则launchctl load -Fw "$HOME/Library/LaunchAgents/cx.pow.powd.plist" Homebrew 安装及配置123456789101112131415# 安装 powbrew install pow# 根据 Caveats 配置相关目录mkdir -p ~/Library/Application\ Support/Pow/Hosts# 创建软链接，若 ~/.pow 目录不存在，则先mkdir ~/.powln -s ~/Library/Application\ Support/Pow/Hosts ~/.pow# Setup port 80 forwarding and launchd agents:sudo pow --install-systempow --install-local# Load launchd agents:sudo launchctl load -w /Library/LaunchDaemons/cx.pow.firewall.plistlaunchctl load -w ~/Library/LaunchAgents/cx.pow.powd.plist 使用方法1234# 执行以下链接命令，之后可以用 `http://myapp.dev/` 地址访问该项目cd ~/.pow$ ln -s ~/Projects/myapp]]></content>
      <categories>
        <category>Pow</category>
      </categories>
      <tags>
        <tag>Homebrew</tag>
        <tag>Pow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iOS 开发笔记]]></title>
    <url>%2F2014%2F03%2F28%2F37701%2F</url>
    <content type="text"></content>
      <categories>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>iOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xcode 使用技巧]]></title>
    <url>%2F2014%2F03%2F26%2F4670%2F</url>
    <content type="text"><![CDATA[在 IB 中，选中一个 view 并右键点击，将会出现灰色的 HUD，可以在其上方便地拖拉或设定事件和 outlet。你可以同时打开多个这样的面板来一次性添加所有 outlet。右键点击面板，随便拖动一下面板，然后再打开另一个。你会发现前一个面板也留下来了，这样你就可以方便地进行拖拽设定了。（当然，对于成组和行为类似的 IBOutlet，应该直接使用 IBOutletCollection 来进行处理会更方便。） 快速显示控件之间的距离：选中一个控件 A，然后按住 option 键并将鼠标移动到其他控件上，你可以发现 view 之间的距离都以很容易理解的方式显示出来了。不仅是同层次的 view，被选中 view 与其他层次的 view 之间的距离关系也可以同样显示。 快速选择叠加控件：对于一些复杂的 view 层级关系，我们往往直接在 IB 中选择会比较困难。比如 view 相互覆盖时，我们很难甚至不能在编辑视图中选中底层的 view。这时候一般的做法是打开左侧的 view 层级面板，一层层展开然后选择自己需要的 view。其实我们也有更简单的方法：按住 Cmd + Shift，然后在需要选择的 view 上方按右键，就可以列出在点击位置上所有的 view 的列表。藉此就可以方便快速地选中想要的 view 了。 添加辅助线：IB 中是可以添加水平和垂直的辅助线的。并且辅助线是可以拖动、重复添加和删除的。水平辅助线的快捷键是：Command ＋ Shift ＋ －垂直辅助线的快捷键是：Command ＋ Shift ＋ ｜当然，也可以通过菜单命令来生成，位置在 Editor 菜单下。 显示控件相对位置：在IB中，选中一个control A,然后按住alt键，鼠标指向B，就显示A和B的相对位置关系，指向父view也行 代码格式化：Re-Indent]]></content>
      <categories>
        <category>Tools</category>
        <category>Xcode</category>
      </categories>
      <tags>
        <tag>Xcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SourceTree 工具]]></title>
    <url>%2F2014%2F03%2F25%2F8794%2F</url>
    <content type="text"><![CDATA[本地文件和服务器文件冲突解决办法 Dsicard Hunk 服务器覆盖本地冲突文件 Stage Hunk 本地覆盖服务器冲突文件 Discard Selected 服务器覆盖本地冲突文件中选中行代码 Stage Selected 本地覆盖服务器冲突文件中选中行代码]]></content>
      <categories>
        <category>Tools</category>
        <category>SourceTree</category>
      </categories>
      <tags>
        <tag>SourceTree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iOS 7 iPhone/iPad 应用开发技术详解]]></title>
    <url>%2F2014%2F03%2F25%2F49425%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>iOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL ES（IOS，Android）开发环境搭建]]></title>
    <url>%2F2014%2F03%2F25%2F3378%2F</url>
    <content type="text"><![CDATA[Mac 下开发环境搭建基于 Eclipse 搭建 Eclipse 下载地址：http://www.eclipse.org/downloads/ * 下载 Eclipse IDE for C/C++ Developers 或 Eclipse for Parallel Application Developers 版本。版本自带 C/C++ Development Tools（CDT）。或下载 Eclipse Standard 版本，自行安装 CDT 等相关插件 * DevCPP 工具安装。 * 配置 Eclipse - window - preference - C/C++ - environment 1. path 配置 2. LIBRARY_PATH 3. C_INCLUDE_PATH]]></content>
      <categories>
        <category>OpenGL ES</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>OpenGL ES</tag>
        <tag>iOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL ES 学习]]></title>
    <url>%2F2014%2F03%2F25%2F42665%2F</url>
    <content type="text"></content>
      <categories>
        <category>OpenGL ES</category>
      </categories>
      <tags>
        <tag>OpenGL ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iOS 下 OpenGL ES]]></title>
    <url>%2F2014%2F03%2F25%2F45156%2F</url>
    <content type="text"></content>
      <categories>
        <category>iOS</category>
        <category>OpenGL ES</category>
      </categories>
      <tags>
        <tag>OpenGL ES</tag>
        <tag>iOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android 下 OpenGL ES]]></title>
    <url>%2F2014%2F03%2F25%2F32281%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Android</category>
        <category>OpenGL ES</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>OpenGL ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android 开发环境搭建]]></title>
    <url>%2F2014%2F03%2F25%2F55140%2F</url>
    <content type="text"><![CDATA[基于 Android Studio 搭建 基于 Eclipse 搭建]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Objective-C 学习]]></title>
    <url>%2F2014%2F03%2F23%2F47427%2F</url>
    <content type="text"><![CDATA[简介预备知识 具备 C 类似编程语言的经验，对于不具备语言基础的，可以先阅读 Dava Mark 写的《Learn C On the Mac》。 历史背景 20世纪80年代早期，Brad Cox 结合 C 语言及 Smalltakl 语言形成了 Objective-C。 内容简介Objective-C 是 C 语言的一个扩展集。Objective-C 以 C 语言为基础，扩展了许多特性。 对 C 的扩展Hello World 安装 Xcode 编写代码 123456789#import &lt;Foundation/Foundation.h&gt;int main (int argc, const char *argv[])&#123; NSlog(@&quot;Hello, world!&quot;); return (0);&#125; // main .m 扩展名表示 Objective-C 文件，应由 Objective-C 编译器处理；.c 由 C编译器处理；.cpp 由 C++ 编译器处理。在 Xcode 中，所有这些编译工作全由 GCC（GNU Compiler Collection，GNU编译器集合）处理，这个编译器能理解 C 语言的这三个变体 #importC 语言中使用 #include 语句通知编译器在头文件中查询定义；Objective-C 中也可以使用 #include 来实现这个目的，但一般只使用 #import。#import 保证头文件只被包含一次 C 语言中，长用基于 #ifdef 命令的方案来避免一个文件包含另一个文件，而后者又包含第一个文件的情况；Objective-C 中，使用 #import 可以实现这个功能。 框架是一种聚集在一个单元的部件集合，包含头文件、库、图像、声音文件等。苹果公司提供 Cocoa（Cocoa 包含 Foundation 和 Application Kit（也称为 AppKit））、Carbon、QuickTime、OpenGL 等技术框架。还有一个支持框架的套件，包含 Core Animation 和 Core Image。 Foundation 框架包含的头文件 Headers 目录位置：/System/Library/Frameworks/Foundation.framework/Headers/ 。仅查看，不修改或删除以避免造成破坏。 学完本书后，还需要精通 Cocoa 和 Application Kit，用户界面元素、打印、声音、颜色和声音管理、AppleScript 支持等。参阅《Learn Cocoa on the Mac》。 NSLog() 和 @“字符串” 类似 C 语言的 printf()，相对添加了新特性，例如时间戳、日期戳和自动附加换行符（’\n’）等。 NS 前缀代表函数来自Cocoa（前身NextSTEP）。 双引号字符串前加 @ 符号，表示引用的字符串应该作为 Cocoa 的 NSString 元素来处理 布尔类型类型 BOOL，值 YES 或 NO。 Objective-C 中的 BOOL 实际上是一种对带符号的字符类型（signed char）的定义（typedef），它使用8位存储空间。YES 定义为1，NO 定义为0（使用 #define）。Objective-C 并不将 BOOL 作为仅能保存 YES 或 NO 值得真正布尔类型来处理。编译器将 BOOL 认作8位二进制数，YES 和 NO 只是一种约定。这引发了一个小问题：如果不小心将一个长于1字节的整型值（例如 short 或 int 值）赋给一个 BOOL 变量，那么只有低位字节会用作 BOOL 值。假设该低位字节刚好为0（例如8960，写成十六进制为0x2300），BOOL 值将会是0，即 NO 值。 面向对象编程基础知识面向对象编程（Object-Oriented Programming，OOP）。Cocoa 基于 OOP 概念，Objective-C 是一种面向对象语言 间接（indirection）变量与间接12345678910111213141516#import &lt;Foundation/Foundation.h&gt;int main(int argc, const char * argv[])&#123; int count = 5; NSLog(@&quot;The numbers from 1 to %d:&quot;, count); int i; for (i = 1; i &lt;= count; i++) &#123; NSLog(@&quot;%d\n&quot;, i); &#125; return (0);&#125; // main 使用文件名的间接12345678910111213141516171819202122232425#import &lt;Foundation/Foundation.h&gt;int main(int argc, const char * argv[])&#123; if (argc == 1) &#123; NSLog(@&quot;You need to provide a file name!&quot;); return (1); &#125; FILE *wordFile = fopen(argv[1], &quot;r&quot;); char word[100]; while (fgets(word, 100, wordFile)) &#123; // strip off the trailing \n word[strlen[word] - 1] = &apos;\0&apos;; NSLog(@&quot;%s is %d characters long&quot;, word, strlen(word)); &#125; fclose(wordFile); return (0);&#125; // main 在 Xcode 中提供文件路径：在 Xcode 文件列表中展开 Executables，并双击程序名；单击 Arguments 区域下的加号，并输入启动参数。 在面向对象的编程中使用间接继承为何使用继承继承语法12@interface Circle : NSObject 某些语言（例如 C++）具有多继承特性。但 Objective-C 不支持多继承。你可以通过 Objective-C 的其他特性获取多继承的优点，例如分类或协议 继承的工作机制方法调度对象收到消息时，它从自身开始往其继承链上的超类层层往上查找对应方法，并执行。若在最高级别的超类（NSObject）中也没有该方法，则会出现运行时错误。 实例变量重写方法复合什么是复合存取方法为存取方法命名：setter 方法需加前缀 set；getter 方法则仅仅根据其返回的属性名称来命名，不要将get作为前缀 get 这个词在 Cocoa 中有特殊约定含义：get 出现在 Cocoa 的方法名称中，意味着这个方法会通过你当做参数传入的指针来返回数值。例如，NSData的getBytes方法。 复合（has a）与继承（is a）的选择源文件组织Objective-C 类的源码分为两部分：接口（interface），用来提供类的公共描述；实现（implementation），告诉编译器如何让该类工作，实现了接口中声明的方法。 .h 文件存放接口部分代码：类的 @interface 指令、公共 struct 定义、enum 常量、#defines 和 extern 全局变量等。 .m 文件存放所有实现细节：类的 @implementation 指令、全局变量的定义、私有struct等 .mm 文件表示你用 Objective-C++ 编写代码的文件，可以使用 C++ 语言和 Objective-C 结合编程 @class 创建向前引用，避免循环依赖关系时，编译错误 深入了解 Xcode 通用常用快捷键 control + A： 移动到行首（同 command + 左箭头） control + E： 移动到行尾（同 command + 右箭头） control + D： 删除（Delete）光标右边的字符 control + K： 删除（Kill）光标所在行中光标后的代码 control + L： 将插入点置于窗口正中。找不到光标或者想要移动窗口使插入点快速位于正中的快捷键 Xcode 快捷键 command + shift + D： 查找文件 command + option + 上箭头： 查看当前文件的配套文件 command + shift + E： 打开扩展编辑器 command + [： 左移代码块 command + ]： 右移代码块 Tab： 接受代码提示 Esc： 显示代码提示菜单 control + .： 循环浏览代码提示 shift + control + .： 反向循环浏览代码提示 control + /： 移动到代码提示中得下一个占位符 command + option + D： 显示 Open Quickly 窗口 command + option + 上箭头： 查看当前文件的配套文件 command + D： 添加书签 option + 双击某个符号： 查找该符号相关文档 command + R： 运行程序 command + Y： 调试程序 command + option + P： 继续（在调试器中） command + option + O： 跳过 command + option + I： 跳入 command + option + T： 跳出 Xcode 使用的调试器是 GDB。GDB 是GNU项目的一部分，它可以在很多不同平台上使用。 Foundation Kit数据类型NSRange1234567891011typedef struct _NSRange &#123; unsigned int location; unsigned int length;&#125; NSRange;/* 聚合结构赋值 */NSRange range = &#123;17, 4&#125;;/* NSMakeRange()赋值 */NSRange r = NSMakeRange(17, 4); 几何数据类型1234567891011121314151617typedef struct _NSPoint &#123; float x; float y;&#125; NSPoint;typedef struct _NSSize &#123; float width; float height;&#125; NSSize;typedef struct _NSRect &#123; NSPoint origin; NSSize size;&#125; NSRect;/* 创建这些数据类型的快捷函数：NSMakePoint()、NSMakeSize() 和 NSMakeRect() */ 这些数据类型是 C 的 struct，能提升性能。程序（尤其是 GUI 程序）会用到许多临时的点，大小和句型来完成它们的工作。所有的 Objective-C 对象都是动态分配的，而动态分配是一个代价较高得操作，它会消耗大量的时间。所以将这些结构创建成第一等级的对象都会在使用过程中增加大量的系统开销。 不可变字符串 NSString NSString 的 length 方法能够准确无误的处理国际字符串，如含有中文、俄文或日文字符的字符串，以及使用 Unicode 国际字符标准的字符串。 比较两个字符串内容是否相等时，应用 isEuqalToString:，而不能用 == 进行比较，后者仅进行指针（即是否是同一个对象）的比较。 NSString 是不可变的。它的子类 NSMutableString 是可变字符串。 集合家族不可变数组 NSArrayNSArray 是一个 Cocoa 类，用来存储对象的有序列表。它只能存储 Objective-C 对象，而不能存储 C 语言中的基本数据类型，如 int、float、enum、struct，或 NSArray 中的随机指针；同时，不能在 NSArray 中存储 nil（对象的零值或 NULL 值）。 可变数组 NSMutableArray枚举1234567891011NSArray *array;array = [NSArray arrayWithObjects: @&quot;one&quot;, @&quot;two&quot;, @&quot;three&quot;, nil];NSEnumerator *enumerator;enumerator = [array objectEnumerator];id thingie;while (thingie = [enumerator nextObject]) &#123; NSLog(@&quot;I found %@&quot;, thingie);&#125;/* 可变数组枚举时，不能添加或身处对象等方式改变数组容器，否则可能会得到未定义结果 */ 快速枚举12345/* Mac OS X 10.5（Leopard），Objective-C 2.0 版本之后，增加快速枚举 */for (NSString *string in array) &#123; NSLog(@&quot;I found %@&quot;, string);&#125; 不可变字典 NSDictionary 与 可变字典 NSMutableDictionary 字典（也被称为散列表或关联数组）使用的是键查询的优化存储方式，它可以立即找出要查询的数据，而不需要遍历整个数组，比普通数组的查询方式更为快速 使用，但不要扩展在 Cocoa 中，许多类实际上是以 类簇 的方式实现的，即它们是隐藏在通用接口下的与实现相关的类。创建 NSString 对象时，实际上获得的可能是 NSLiteralString、NSCFString、NSSimpleCString、NSBallofString 或者其他未写入文档的与实现相关的对象。通常，你可以将 NSString 或 NSArray 复合到你的某个类中或者使用类别来解决这种编程问题，而不用创建子类。 数值类型NSArray 和 NSDictionary 只能存储对象，而不能直接存储任何基本类型的数据，如 int、float 或 struct。但你可以用对象来封装基本类型（装箱，boxing），例如，将 int 数据封装在一个对象中，然后就可以存入 NSArray 或 NSDictionary 了。 NSNumber 通常将一个基本类型的数据封装成对象叫做 装箱（boxing），从对象中提取基本类型的数据叫做 取消装箱（unboxing）。有些语言有 自动装箱 功能。Objective-C 语言不支持自动装箱。 NSValueNSNumber 实际上是 NSValue 的子类，NSValue 可以包装任意值。你可以用 NSValue 将结构放入 NSArray 或 NSDictionary 中。 12345678910NSRect rect = NSMakeRect(1, 2, 30, 40);NSValue *value;value = [NSValue valueWithBytes: &amp;rect objCType: @encode(NSRect)];[array addObject: value];value = [array objectAtIndex: 0];[value getValue: &amp;rect]; NSNull使用NSNull值代表不存在的意义，它可以被加入到集合中。[NSNull null] 总是返回一样的数值，并且可以使用 == 运算符进行比较。 内存管理Objective-C 2.0 提供了垃圾回收机制。 对象生命周期引用计数（reference counting，也叫保留计数）对象所有权（object ownership）访问方法中的保留和释放1234567- (void) setEnging: (Engine *) newEngine&#123; [newEngine retain]; [engine release]; engine = newEngine;&#125; // setEngine 自动释放所有对象全部入池Cocoa 中有一个 自动释放池（autorelease pool） 的概念 1234567891011- (NSString *) description&#123; NSString *description; description = [[NSString alloc] initWithFormat: @&quot;I am %d years old.&quot;, 4]; return ([description autorelease]);&#125; // description// 你可以编写如下代码NSLog(@&quot;%@&quot;, [someObject description]); 自动释放池的销毁时间12345678// 创建池NSAutoreleasePool *pool;pool = [[NSAutoreleasePool alloc] init];// 其他代码// 释放池[pool release]; -drain 方法只是清空自动释放池而不销毁它。-drain 方法适用于Mac OS X 10.4（Tiger）及更高版本。 自动释放池的工作过程123456789101112131415161718int main (int argc, const char *argv[])&#123; NSAutoreleasePool *pool; pool = [[NSAutoreleasePool alloc] init]; RetainTracker *tracker; tracker = [RetainTracker new]; // count: 1 [tracker retain]; // count: 2 [tracker autorelease]; // count: still 2 [tracker release]; // count: 1 NSLog(@&quot;releasing pool&quot;); [pool release]; return (0);&#125; // main Cocoa 内存管理规则 当你使用 new、alloc 或 copy 方法创建一个对象时，该对象的保留计数器值为1。当不再使用该对象时，你需要负责向该对象发送一条 release 或 autorelease 消息。 当你通过任何其他方法获得一个对象时，则将设该对象的保留计数器值为1，而且已经被设置为自动释放，你不需要执行任何操作来确保该对象被清理。如果你打算在一段时间内拥有该对象，则需要保留它并确保在操作完成时释放它。 如果你保留了某个对象，你需要（最终）释放或自动释放该对象。必须保持 retain 方法和 release 方法的使用次数相等。 临时对象拥有对象通常，你可能希望在多个代码行中一直拥有某个对象。常见方法：在其他对象的实例变量中使用这些对象，将它们加入到诸如 NSArray 或 NSDictionary 等集合中，或者（更罕见的情况）将其作为全局变量使用。 如果你正在使用 new、alloc 或 copy 方法获得一个对象，则不需要执行任何其他操作。该对象的保留计数器值为1，因此它将一直保留，只是一定要在拥有该对象的对象的 dealloc 方法中释放该对象。 123456789101112- (void) doStuff&#123; // flonkArray is an instance variable flonkArray = [NSMutableArray new]; // count: 1&#125; // doStuff- (void) dealloc&#123; [flonkArray release]; // count: 0 [super dealloc];&#125; // dealloc 如果你使用除 alloc、new 或 copy 以外的方法获得一个对象，你需要保留该对象。考虑编写 GUI 应用程序时事件循环的情况。你希望保留自动释放的对象，使这些对象在当前的事件循环结束以后仍能继续存在。 为了降低程序的内存空间占用，Cocoa 在程序开始处理事件之前创建一个自动释放池，并在事件处理结束后销毁该自动释放池，这样可以使积累的临时对象的数量保持在最低程度。 123456789101112131415// 当使用自动释放对象时，前面的方法可以重写如下：- (void) doStuff&#123; // flonkArray is an instance variable flonkArray = [NSMutableArray arrayWithCapacity: 17]; // count: 1, autoreleased [flonkArray retain]; // count: 2, 1 autorelease&#125; // doStuff- (void) dealloc&#123; [flonkArray release]; // count: 0 [super dealloc];&#125; // dealloc 清理自动释放池 12345678910111213141516171819202122232425int i;for (i = 0; i &lt; 1000000; i++) &#123; id object = [someArray objectAtIndex: i]; NSString *desc = [object description]; // and do something with the description&#125;/* 上面这段代码执行一个循环，在大量的迭代中每次都会生成一个（或2个，10个）自动释放对象。请记住，自动释放池的销毁事件是完全确定的，它在循环执行的过程中不会被销毁。这个循环创建了100万个 description 字符串对象，所有这些对象都被放进当前的自动释放池中，因此就产生了100万个闲置的字符串，这100万个字符串对象一直存在，当自动释放池销毁时才最终获得释放。解决这类问题的方法是在循环中创建自己的释放池，每执行1000次左右，销毁当前自动释放池并创建一个新的自动释放池。代码如下 */NSAutoreleasePool *pool;pool = [[NSAutoreleasePool alloc] init];int i;for (i = 0; i &lt; 1000000; i++) &#123; id object = [someArray objectAtIndex: i]; NSString *desc = [object description]; // and do something with the description if (i % 1000 == 0) &#123; [pool release]; pool = [[NSAutoreleasePool alloc] init]; &#125;&#125;[pool release];/* 自动释放池以栈的形式实现：当你创建一个新的自动释放池时，它将被添加到栈顶，接收 autorelease 消息的对象将被放入最顶端的自动释放池中。如果将一个对象放入一个自动释放池中，然后创建一个新的自动释放池再销毁该新建的自动释放池，则这个自动释放对象仍将存在，因为容纳该对象的自动释放池仍然存在。 */ 垃圾回收Objective-C 2.0 引入了自动内存管理机制 “-fobjc-gc” 选项能使代码既支持垃圾回收机制又支持对象的保留和释放。 启用垃圾回收以后，通常的内存管理命令全都变成了空操作指令，不执行任何操作。 Objective-C 的垃圾回收是一种继承性的垃圾回收器。与那些存在了一段时间的对象相比，新创建的对象更可能被当成垃圾。如果在一个实例变量中指向某个对象，一定要在某个时候使该实例变量赋值为 nil，以取消对该对象的引用并使垃圾回收器知道该对象可以被清理。 对象初始化分配对象分配（allocation）对象，从操作系统中获得一块内存并将其指定为存放对象的实例变量的位置。alloc 方法将分配的内存初始化为0。所有的 BOOL 类型变量初始化为 NO，int 类型变量初始化为0，float 类型变量初始化为0.0，指针被初始化为 nil。 初始化对象初始化（initialization）从操作系统获取一块内存，准备用于存储对象。init 方法几乎总是返回他们正在初始化的对象。 12Car *car = [[Car alloc] init]; // 不能将分配及初始化分开写，避免初始化方法返回的对象与分配的对象不同 编写初始化方法1234567891011121314- (id) init&#123; if (self = [super init]) &#123; enging = [Engine new]; tires[0] = [Tire new]; tires[1] = [Tire new]; tires[2] = [Tire new]; tires[3] = [Tire new]; &#125; return (self);&#125; // init 指定初始化函数初始化函数规则 不需要为你自己的类创建初始化函数方法。如果不需要设置任何状态，或者只需要 alloc 方法将内存清零的默认行为，则不需要担心init。 如果构造了一个初始化函数，则一定要在你自己的指定初始化函数中调用超类的指定初始化函数。 如果初始化函数不止一个，则要选择一个作为指定初始化函数。被选定的方法应该调用超类的指定初始化函数。 特性Objective-C 2.0 中引入了特性（property），它组合了新的预编译指令和新的属性访问器语法。 修改特性值简化接口12345678910111213#import &lt;Foundation/Foundation.h&gt;#import &quot;Tire.h&quot;@interface AllWeatherRadial : Tire &#123; float rainHandling; float snowHandling;&#125;@property float rainHandling;@property float snowHandling;@end // AllWeatherRadial @property 预编译指令自动声明属性的 setter 和 getter方法 简化实现123456789101112131415161718192021222324252627#import &quot;AllWeatherRadial.h&quot;#implementtation AllWeatherRadial@synthesize rainHandling;@synthesize snowHandling;- (id) initWithPressure: (float) p treadDepth: (float) td&#123; if (self = [super initWithPressure: p treadDepth: td]) &#123; rainHandling = 23.7; snowHandling = 42.5; &#125; return (self);&#125; // initWithPressure: treadDepth- (NSString *) description&#123; NSString *desc; desc = [[NSString alloc] initWithFormat: @&quot;AllWeatherRadial: %.1f / %.1f / %.1f / %.1f&quot;, [self pressure], [self treadDepth], [self rainHandling], [self snowHandling]]; return (desc);&#125; // description@end // AllWeatherRadial @synthesize 表示：创建该属性的访问器 点表达式点表达式出现在等号左边，该属性名称的 setter 方法将被调用，如果点表达式出现在对象变量的右边，则该属性名称的 getter 方法将被调用。 特性扩展名称的使用12@synthesize name = appellcation 只读特性类别创建类别（category）声明类别1234567/* 类别的声明格式与类的声明格式相似，类别名称必须唯一 */@interface NSString (NumberConvenience)- (NSNumber) lengthAsNumber;@end // NumberConvenience 类别不能添加新的实例变量，因此类别的声明中没有实例变量部分。 实现类别1234567891011@implementation NSString (NumbreConvenience)- (NSNumber *) lengthAsNumber&#123; unsigned int length = [self length]; return ([NSNumber numberWithUnsignedInt: length]);&#125; // lengthAsNumber@end // NumberConvenience 类别的局限性 无法向类中添加新的实例变量。类别没有位置容纳实例变量。 名称冲突，即类别中的方法与现有的方法重名。当发生名称冲突时，类别具有更高的优先级，类别方法将取代初始方法，从而无法再使用初始方法。可加特定前缀以避免冲突。 也有一些技术可以克服类别无法增加新实例变量的局限，例如：全局字典存储对象与你想要关联的额外变量之间的映射。但此时需考虑，类别是否完成当前任务的最佳选择。 类别的作用 将类的实现分散到多个不同文件或多个不同框架中； 创建对私有方法的向前引用； 向对象添加非正式协议（informal protocol）。 利用类别分散实现使用类别创建向前引用如果能够先定义一个方法，然后再使用它，编译器将会找到你的方法定义，因而不产生警告。如果不方便这么做，或者你使用了另一个类尚未发布的方法，那么就需要采取其他措施。 通过在类别中声明该方法，编译器将不会产生警告。 非正式协议和委托类别委托强调类别的一种应用：被发送给委托对象的方法可以声明为一个 NSObject 的类别。 像这样创建 NSObject 的类别，任何类的对象都可以作为委托对象使用。 非正式协议是 NSObject 的一个类别，它可以列出对象能够响应的方法。非正式协议用于实现委托。 选择器：@selector，可以在代码中指定特定的 Objective-C 消息。 协议正式协议与非正式协议一样，正式协议也是一个命名的方法列表。但与非正式协议不同的是，正式协议要求显式的采用协议。采用协议的方法是在类的 @interface 声明中列出协议的名称。此时，你的类遵守该协议，并应该实现该协议的所有方法，否则，编译器会生成警告。Objective-C 2.0增加了一些良好的特性，以便更好使用协议。 正式协议类似 Java 接口 声明协议1234567// 声明正式协议@protocol NSCopying- (id) copyWithZone: (NSZone *) zone;@end @protocol 告诉编译器，这是一个正式协议。 协议名称必须唯一。 方法声明列表中的方法，在协议的每个采用者中都必须被实现。 使用协议不可引入新的实例变量。 采用协议要采用某个协议，必须在类声明中列出该协议的名称，并用尖括号括起。若存在多个协议，逗号隔开（顺序无关）。 12345678910// Car 采用协议 NSCopying 及 NSCoding@interface Car : NSObject &lt;NSCopying, NSCoding&gt;&#123; // instance variables&#125;// methods@end // Car 实现协议复制 浅层复制（Shallow Copy）、深层复制（Deep Copy） 123456789// 深层复制- (id) copyWithZone: (NSZone *) zone&#123; Tire * tireCopy; tireCopy = [[[self class] allocWithZone: zone] initWithPressure: pressure treadDepth: treadDepth]; return (tireCopy);&#125; // copyWithZone C 风格指针运算符直接访问实例变量tireCopy -&gt; pressure = pressure; tireCopy -&gt; treadDepth = treadDepth;。一般，设置属性不涉及额外工作时，尽量使用init方法和访问器方法。 Objective-C 2.0 新特性 新增协议修饰符：@optional（方法可选实现）、@required（方法必须实现，默认属性）。 非正式协议在 Objective-C 2.0 之后，主键被带有 @optional 方法的正式协议代替。 AppKit 简介构建项目 拖动连接的路径是从需要知道某些内容的对象到该对象需要了解的对象。类似 AppController 需要知道将哪个 NSTextField 用于用户输入，因此拖动方向从 AppController 到文本域。按钮需要知道告诉哪个对象，按钮被 click 了，此时需要从按钮拖到AppController。 文件加载与保存标准 C 函数库提供了函数调用来创建、读取和写入文件，例如 open()、read()、write()、fopen() 和 fread()等。Cocoa 提供了 Core Data。另外 Cocoa 提供了两个通用的文件处理类：属性列表和对象编码。 属性列表属性列表对象，常简写为 plist。属性列表类包括 NSArray、NSDictionary、NSString、NSNumber、NSDate、NSData，以及他们的变体（如果变体存在）。 NSDateNSData123456789101112// NSData 对象保存一个普通的 C 字符串（一个字节序列），然后输出数据const char *string = &quot;Hi there, this is a C string!&quot;;// length: strlen(string) + 1 用于包含 C 字符串所需的尾部的零字节。NSData *data = [NSData dataWithBytes: string length: strlen(string) + 1];NSLog(@&quot;data is %@&quot;, data);//输出结果：`data is &lt;48692074 68657265 2c207468 69732069 73206120 43207374 72696e67 2100&gt;`// 包含末尾00的零字节数据，可以使用 %s 格式输出字符串NSLog(@&quot;%d byte string is &apos;%s&apos;&quot;, [data length], [data bytes]);//输出结果：`30 byte string is &apos;Hi there, this is a C string!&apos;` NSMutableData 写入和读取属性列表 在操作系统中，有许多属性列表文件和系统配置文件，如主目录 Library/Preference 下的所有首选项文件和 /System/Library/LaunchDaemons 下的系统配置文件。有些属性列表文件（特别是首选项文件）是以二进制格式存储的。通过使用 plutil 命令：plutil -convert xml1 filename.plist，可以将这些文件转换成可读形式。 编码对象采用 NSCoding 协议和实现方法来编码和解码对象：将大量对象转换成 NSData 类，保存到磁盘中，并在以后读取它，通过 NSData 类，重新创建对象。 键/值编码键/值编码（KVC）是一种间接更改对象状态的方式，其实现方法是使用字符串描述要更改的对象状态部分。Cocoa 的一些特性，如 Core Data 或 Cocoa Bindings 在基础机制中包含了 KVC。 入门项目KVC 简介键/值编码中的基本调用包括 -valueForKey: 和 -setValue:forKey:。 1234[car setValue: @&quot;Haroid&quot; forKey: @&quot;name&quot;];NSString *name = [car valueForKey: @&quot;name&quot;];NSLog(@&quot;%@&quot;, name); -valueForKey: 首先查找以键 -key 或 -isKey 命名的 getter 方法，对于这类调用 valueForKey: 查找 -name。如果不存在 getter 方法，它将在对象内部查找名为 _key 或 key 的实例变量，如果没有通过 @synthesize 提供存取方法，valueForKey 将会查找实例变量 _name 和 name。 -valueForKey 在 Objective-C 运行时使用元数据打开对象并进入其中查找需要的信息，在 C 或 C++ 中不能执行这种操作。通过 KVC ，可以获取不存在 getter 方法的对象值，无需通过对象指针直接访问实例变量。 对于 KVC，Cocoa 自动放入和取出标量值。仅 KVC 具有这种自动包装功能。 -setValue:forKey: 工作方法同 -valueForKey: 类似，首先查找名称的 setter 方法，如果不存在 setter 方法，它将再类中查找 key 或 _key 的实例变量，然后为其赋值。 编译器和苹果公司都以下划线开头的形式保存实例变量名称，如果你尝试在其他地方使用下划线，可能会出现严重的错误。这条规则实际上不是强制的，但如果不遵守它，可能会遇到某些风险。 路径除了通过键设置值外，键/值编码还支持指定键路径，你可以遵循一定关系来指定该路径。路径可以指定以圆点分隔不同属性名称。例如：“engine.horsepower”。 整体操作关于 KVC 非常棒的一点是，如果向 NSArray 请求一个键值，它实际上会查询数组中的每个对象来查找这个键值，然后将查询结果打包到另一个数组中并返回给你。这种方法也适用于通过键路径访问的对象内部的数组。 在 KVC 中，通常认为嵌入到其他对象中的 NSArray 具有一对多的关系。 1234NSArray *pressures = [car valueForKeyPath: @&quot;tires.pressure&quot;];// 不能在键路径中为这些数组添加索引，例如，“tires[0].pressure” 是错误的。 键路径不仅能引用对象值，还可以引用一些运算符来进行一些计算，例如获取一组值的平均值或返回这组值中的最小值和最大值。 1234567891011121314151617NSNumber *count;// 计算汽车的数量，键路径 “cars.@count” 拆开，cars用于获取cars属性，它是 garage 的 NSArray 类型的值。@count 用于通知 KVC 机制计算键路径左侧的结果。count = [garage valueForKeyPath: @&quot;cars.@count&quot;];NSNumber *sum;// 计算某些特定值的总和，例如，车队行驶的总英里数sum = [garage valueForKeyPath: @&quot;cars.@sum.mileage&quot;];NSNumber *avgMileage;// 计算平均每辆汽车行驶的距离avgMileage = [garage valueForKeyPath: @&quot;cars.@avg.mileage&quot;];// @min、@maxNSNumber *min, *max;min = [garage valueForKeyPath: @&quot;cars.@min.mileage&quot;];max = [garage valueForKeyPath: @&quot;cars.@max.mileage&quot;]; KVC 能非常轻松的处理集合。但是 KVC 需要通过解析字符串来计算你所需要的答案，因此速度比较慢；编译器无法对它进行错误检查，当你使用错误的键路径时，会出现运行时错误。 nil值处理处理未定义的键如果 KVC 机制无法找到键路径的处理方式，默认实现会取消操作。但我们可以通过更改默认行为来处理这种情况。valueForUndefinedKey: 方法或 setValue:forUndefinedKey: 方法。 123456789101112131415161718192021@interface Garage : NSObject &#123; NSString *name; NSMutableArray *cars; NSMutableDictionary *stuff;&#125;// ... 其他代码@end // Garage// 在实现中添加 valueForUndefinedKey: 及 setValue:forUndefinedKey: 方法- (void) setValue: (id) value forUndefinedKey: (NSString *) key &#123; if (stuff == nil) &#123; stuff = [[NSMutableDictionary alloc] init]; &#125; [stuff setValue: value forKey: key];&#125; // setValueForUndefinedKey- (id) valueForUndefinedKey: (NSString *) key &#123; id value = [stuff valueForKey: key]; return (value);&#125; // valueForUndefinedKey NSPredicateCocoa 用 NSPredicate 类描述查询方式 创建谓词12345678// 创建谓词，NSPredicate *predicate;predicate = [NSPredicate predicateWithFormat: @&quot;name == &apos;Herbie&apos;&quot;];// 计算谓词BOOL match = [predicate evaluateWithObject: car];NSLog(@&quot;%s&quot;, (match) ? &quot;YES&quot; : &quot;NO&quot;); 燃料过滤器12345NSArray *results;// 返回符合条件的carresults = [cars filteredArrayUsingPredicate: predicate];NSLog(@&quot;%@&quot;, results); 使用谓词确实很便捷，但它的运行速度不会比你自己编写全部代码快。因为它无法避免在所有汽车之间使用循环和对每辆汽车进行某些操作。一般来说，这种循环不会带来很大的性能影响，因为当今的计算机运行速度非常快。可以继续编写尽可能简易的代码。如果你遇到速度问题，可以使用苹果公司的工具（如 Shark 或 Instruments）测试程序性能。 格式说明符可以在谓词中使用格式说明符 %d、%f、%@（指定值）或 %K（指定键路径）。或者直接将变量名放入字符串 $NAME 来指定值。 运算符比较和逻辑运算符谓词字符串语法支持 C 语言中的一些常用运算符。例如： ==、=、&gt;、&gt;= 或 =&gt;、&lt;、&lt;= 或 =&lt;、!= 或 &lt;&gt;、括号表达式、AND、OR、NOT 逻辑运算符或C样式的等效表达式 &amp;&amp;、|| 和 !。 谓词字符串中运算符不区分大小写。 数组运算符1234predicate = [NSPredicate predicateWithFormat: @&quot;engine.horsepower BETWEEN &#123;50, 200&#125;&quot;];predicate = [NSPredicate predicateWithFormat: @&quot;name IN &#123;&apos;Herbie&apos;, &apos;Snugs&apos;, &apos;Badger&apos;, &apos;Flap&apos;&#125;&quot;]; SELFSELF 可以引用用于谓词计算的对象 12predicate = [NSPredicate predicateWithFormat: @&quot;SELF.name IN &#123;&apos;Herbie&apos;, &apos;Snugs&apos;, &apos;Badger&apos;, &apos;Flap&apos;&#125;&quot;]; 字符串运算符BEGINSWITH：某个字符串是否以另外一个字符串开头；ENDSWITH：某个字符串是否以另外一个字符串结尾；CONTAINS：某个字符串是否在另一个字符串内部。 以上运算符可增加 [c] 不区分大小写、[d] 不区分发音符号、[cd] 既不区分大小写又不区分发音符号 等修饰符 LIKE 运算符MATCHES 正则运算符相关术语 类 是一种结构，它表示对象的类型。对象引用类来获取和自身相关的各种信息。Objective-C 编程风格建议开发人员使用首字母大写的类名。 对象 是一种结构，它包含值和指向其类的隐藏指针。引用对象的 Objective-C 变量通常不需要首字母大写。 消息 是对象可以执行的操作，用于通知对象去做什么。在 [shape draw] 代码中，通过向 shape 对象发送 draw 消息来通知对象绘制自身。对象接收消息后，将查询对应的类，以便查找正确的代码来运行。 方法 是为响应消息而运行的代码。根据对象的类，消息（例如 draw）可以调用不同的方法。 方法调度程序 是 Objective-C 使用的一种机制，用于推测执行什么方法以响应某个特定得消息。 接口 是对象的类应该提供的特性的描述。接口不提供具体的实现细节。 实现 是使接口正常工作的代码。 实例化（instantiation） 根据类信息进行内存分配和初始化，创建一个新的对象实例。 继承 定义一个具有父类所有功能的新类，它继承了父类的这些功能。 复合 在复合中，对象可以引用其他对象。例如汽车对象可以引用轮胎对象。 重构。 超类（superclass）、父类（parentclass）、子类（subclass）、子类（childclass）。 委托（delegate） 是一种对象，另一个类的对象会要求委托对象执行它的某些操作。 非正式协议。 正式协议（formal protocol）。 .xib 文件 .xib 文件是 XML 格式的 nib 文件。在编译时，.xib文件将编译为nib格式。 编码（序列化）、解码（反序列化）。 书名《Learn Objective-C on the Mac》Objective-C 基础教程 高朝勤 杨越 刘霞 等译，人民邮电出版社 2009年8月第一版 这本书写得或者是翻译得很差。]]></content>
      <categories>
        <category>Objective-C</category>
      </categories>
      <tags>
        <tag>Objective-C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本博客 Markdown 语法测试]]></title>
    <url>%2F2014%2F03%2F23%2F6817%2F</url>
    <content type="text"><![CDATA[12345678910111213&gt;&gt; 仅支持六级标题（pre code效果）# 1. 一级标题## 1.1. 二级标题### 1.1.1. 三级标题#### 1.1.1.1. 四级标题##### 1.1.1.1.1. 五级标题###### 1.1.1.1.1.1. 六级标题 1. 一级标题1.1. 二级标题1.1.1. 三级标题1.1.1.1. 四级标题1.1.1.1.1. 五级标题1.1.1.1.1.1. 六级标题1234567891011121314151617181920212223242526272829303132333435363738&gt;&gt; 列表无序列表可以用 - + * 三种写法- 减号1- 减号2+ 加号1+ 加号2* 星号1* 星号2有序列表用数字表示，序号错了会被自动识别，输出会纠正1. 数字12. 数字24. 数字43. 数字3 /* 列表中两次缩进形成的代码块 */ var a = 2; var b = 4;列表之间可以有空行，不过 html 等处理稍有不同列表中得文字可以断行，建议换缩进更美观，不缩进也可以列表中的文字还允许有空行，至少段首要一个缩进列表中也可以放代码块，需要两个缩进 无序列表可以用 - + * 三种写法 减号1 减号2 加号1 加号2 星号1 星号2 有序列表用数字表示，序号错了会被自动识别，输出会纠正 数字1 数字2 数字4 数字3 /* 列表中两次缩进形成的代码块 */ var a = 2; var b = 4; 12345&gt;&gt; 分割线用三个以上的减号或分割线表示，行内不能有空格以外的其他字符---*** 123456789&gt;&gt; 强调*em 效果***strong 效果**_em 效果___strong 效果__ em 效果 strong 效果 em 效果 strong 效果 123456789101112131415161718&gt;&gt; 代码效果行内代码`var a = 1`要在代码里包含反引号，你可以使用多个反引号引起来这段代码：``There is a literal backtick (`) here.`````javascript /* 代码块 */ var a = 1; var b = 2; var c = function(a, b)&#123; return a + b; &#125;; c(a, b); 1234567891011121314151617行内代码`var a = 1`要在代码里包含反引号，你可以使用多个反引号引起来这段代码：``There is a literal backtick (`) here.`````javascript/* 代码块 */var a = 1;var b = 2;var c = function(a, b)&#123; return a + b;&#125;;c(a, b); 12345678910111213141516&gt;&gt; Markdown 用表示链接相同的语法来表示图片，有两种方式：内联和参考。内联语法这是 Google+ 的图标![Google+](http://www.google.com/images/icons/ui/gprofile_button-32.png)![Google+](http://www.google.com/images/icons/ui/gprofile_button-32.png &apos;标题&apos;)参考语法这是 Google+ 的图标![Google+][1]![Google+][2][1]: http://www.google.com/images/icons/ui/gprofile_button-32.png[2]: http://www.google.com/images/icons/ui/gprofile_button-32.png &apos;标题&apos; 内联语法 这是 Google+ 的图标 参考语法 这是 Google+ 的图标 ![Google+][2] [2]: http://www.google.com/images/icons/ui/gprofile_button-32.png ‘标题’ 12345&gt;&gt; 链接及邮件&lt;http://example.com/&gt;&lt;address@example.com&gt; http://example.com/ &#x61;&#x64;&#100;&#x72;&#101;&#115;&#x73;&#64;&#101;&#120;&#97;&#109;&#112;&#x6c;&#101;&#46;&#99;&#111;&#109; 1234567891011121314151617181920212223242526272829&gt;&gt; 反斜线转义 Markdown 中的特殊字符\as 普通字符不转义\*literal asterisks\*\\ backslash\` backtick\* asterisk\_ underscore\&#123;\&#125; curly braces\[\] square brackets\(\) parentheses\# hash mark\+ plus sign\- minus sign (hyphen)\. dot\! exclamation mark \as 普通字符不转义 *literal asterisks* \ backslash ` backtick * asterisk _ underscore {} curly braces [] square brackets () parentheses - minus sign (hyphen) + plus sign # hash mark . dot ! exclamation mark]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac OS X 下 Octopress + GitHub Pages 发布博客]]></title>
    <url>%2F2014%2F03%2F19%2F37037%2F</url>
    <content type="text"><![CDATA[前言Octopress 已经比较久不维护, 不建议继续使用. 大家可以考虑使用 Hexo. (2017-05) 优点 广泛的使用者及相关文档 Octopress 整合了丰富的第三方插件 内置支持 Gitub、Twitter、Google Plus One、Pinboard、Delicious、Disqus Comments、Google Analytics、Facebook 源码版本信息完全自己通过 github 控制，可定制高度个性化的个人博客 官方文档相关资源安装及配置Git 安装Ruby 安装，版本号要求大于1.9.3 通过 rbenv 或者 RVM 安装。 设置 Octopress 从 git 复制 Octopress 12git clone git://github.com/imathis/octopress.git octopresscd octopress 下一步，安装依赖 123gem install bundler # 若报权限错误，加 sudo 执行相关命令rbenv rehash # If you use rbenv, rehash to be able to run the bundle commandbundle install 安装 Octopress 默认主题 1rake install # 由于默认主题名为“classic” 该命令等效于：rake install['classic‘] 或者安装第三方主题 1234cd octopressgit clone GIT_URL .themes/THEME_NAMErake install['THEME_NAME']rake generate Octopress发布在Github Pages上 1234rake setup_github_pages # 该命令将进行一系列的 github 相关配置rake generate # This will generate your blog, copy the generated files into _deploy/rake preview # 本地预览页面，页面默认发布在 localhost:4000rake deploy # dd them to git, commit and push them up to the master branch 将 octopress 目录下所有代码提交到 source 分支 123git add .git commit -m '源码提交'git push origin source 自定义域名 12345echo 'your-domain.com' &gt;&gt; source/CNAME# 或者echo 'www.your-domain.com' &gt;&gt; source/CNAME# 然后，你必须访问你得域名注册商或者 DNS 主机，为你的域名增加一个 record# 注意最好不要使用顶级域名作为 CNAME，另外，DNS 解析生效需要比较长的时间 按规范发布文章，新发布文章的默认扩展名是 markdown，你可以在 Rakefile 文件中更改扩展名 123rake new_post["title"] # 按规范发布文章，并且为文章自动生成 yaml metadatarake new_page[super-awesome] # 创建 /source/super-awesome/index.markdownrake new_page[super-awesome/page.html] # 创建 /source/super-awesome/page.html 远程更新至本地 12345git pull octopress master # Get the latest Octopressbundle install # Keep gems updatedrake update_source # update the template's sourcerake update_style # update the template's style# rake update命令相当于以上rake update_source和rake update_style 两个命令合并执行(该命令无效？？？)]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Jekyll</tag>
        <tag>Octopress</tag>
        <tag>Github</tag>
        <tag>Pages</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
</search>
